#!/usr/bin/env python3

# Bump the minor PROVISION_VERSION to indicate that folks should provision

# only when going from an old version of the code to a newer version. Bump

# the major version to indicate that folks should provision in both

# directions.

# Typically, adding a dependency only requires a minor version bump, and

# removing a dependency requires a major version bump.

# The earliest/starting end_time in FillState

# We assume there is at least one realm

# These endpoints are a part of the API (V1), which uses:

# * REST verbs

# * Basic auth (username:password is email:apiKey)

# * Takes and returns json-formatted data

#

# See rest_dispatch in zerver.lib.rest for an explanation of auth methods used

#

# All of these paths are accessed by either a /json or /api prefix

# For any given user, we want to show a fixed set of clients in the chart,

# regardless of the time aggregation or whether we're looking at realm or

# user data. This fixed set ideally includes the clients most important in

# understanding the realm's traffic and the user's traffic. This function

# tries to rank the clients so that taking the first N elements of the

# sorted list has a reasonable chance of doing so.

## Logging setup ##

# You can't subtract timedelta.max from a datetime, so use this instead

## Class definitions ##

## CountStat-level operations ##

# We assume end_time is valid (e.g. is on a day or hour boundary as appropriate)

# and is timezone aware. It is the caller's responsibility to enforce this!

## Utility functions called from outside counts.py ##

# called from zerver/lib/actions.py; should not throw any errors

## DataCollector-level operations ##

# Note: ignores the group_by / group_by_clause.

# This query joins to the UserProfile table since all current queries that

# use this also subgroup on UserProfile.is_bot. If in the future there is a

# stat that counts messages by stream and doesn't need the UserProfile

# table, consider writing a new query for efficiency.

# Hardcodes the query needed by active_users:is_bot:day, since that is

# currently the only stat that uses this.

# Currently hardcodes the query needed for active_users_audit:is_bot:day.

# Assumes that a user cannot have two RealmAuditLog entries with the same event_time and

# event_type in ['user_created', 'user_deactivated', etc].

# In particular, it's important to ensure that migrations don't cause that to happen.

# Currently unused and untested

## CountStat declarations ##

"""
            INSERT INTO analytics_realmcount
                (realm_id, value, property, subgroup, end_time)
            SELECT
                zerver_realm.id, COALESCE(sum(%(output_table)s.value), 0), '%(property)s',
                %(output_table)s.subgroup, %%(end_time)s
            FROM zerver_realm
            JOIN %(output_table)s
            ON
                zerver_realm.id = %(output_table)s.realm_id
            WHERE
                %(output_table)s.property = '%(property)s' AND
                %(output_table)s.end_time = %%(end_time)s
            GROUP BY zerver_realm.id, %(output_table)s.subgroup
        """
"""
        INSERT INTO analytics_installationcount
            (value, property, subgroup, end_time)
        SELECT
            sum(value), '%(property)s', analytics_realmcount.subgroup, %%(end_time)s
        FROM analytics_realmcount
        WHERE
            property = '%(property)s' AND
            end_time = %%(end_time)s
        GROUP BY analytics_realmcount.subgroup
    """
"""
    INSERT INTO analytics_usercount
        (user_id, realm_id, value, property, subgroup, end_time)
    SELECT
        zerver_userprofile.id, zerver_userprofile.realm_id, count(*),
        '%(property)s', %(subgroup)s, %%(time_end)s
    FROM zerver_userprofile
    JOIN zerver_message
    ON
        zerver_userprofile.id = zerver_message.sender_id
    WHERE
        zerver_userprofile.date_joined < %%(time_end)s AND
        zerver_message.pub_date >= %%(time_start)s AND
        zerver_message.pub_date < %%(time_end)s
    GROUP BY zerver_userprofile.id %(group_by_clause)s
"""
"""
    INSERT INTO analytics_usercount
            (realm_id, user_id, value, property, subgroup, end_time)
    SELECT realm_id, id, SUM(count) AS value, '%(property)s', message_type, %%(time_end)s
    FROM
    (
        SELECT zerver_userprofile.realm_id, zerver_userprofile.id, count(*),
        CASE WHEN
                  zerver_recipient.type = 1 THEN 'private_message'
             WHEN
                  zerver_recipient.type = 3 THEN 'huddle_message'
             WHEN
                  zerver_stream.invite_only = TRUE THEN 'private_stream'
             ELSE 'public_stream'
        END
        message_type

        FROM zerver_userprofile
        JOIN zerver_message
        ON
            zerver_userprofile.id = zerver_message.sender_id AND
            zerver_message.pub_date >= %%(time_start)s AND
            zerver_message.pub_date < %%(time_end)s
        JOIN zerver_recipient
        ON
            zerver_message.recipient_id = zerver_recipient.id
        LEFT JOIN zerver_stream
        ON
            zerver_recipient.type_id = zerver_stream.id
        GROUP BY
            zerver_userprofile.realm_id, zerver_userprofile.id,
            zerver_recipient.type, zerver_stream.invite_only
    ) AS subquery
    GROUP BY realm_id, id, message_type
"""
"""
    INSERT INTO analytics_streamcount
        (stream_id, realm_id, value, property, subgroup, end_time)
    SELECT
        zerver_stream.id, zerver_stream.realm_id, count(*), '%(property)s', %(subgroup)s, %%(time_end)s
    FROM zerver_stream
    JOIN zerver_recipient
    ON
        zerver_stream.id = zerver_recipient.type_id
    JOIN zerver_message
    ON
        zerver_recipient.id = zerver_message.recipient_id
    JOIN zerver_userprofile
    ON
        zerver_message.sender_id = zerver_userprofile.id
    WHERE
        zerver_stream.date_created < %%(time_end)s AND
        zerver_recipient.type = 2 AND
        zerver_message.pub_date >= %%(time_start)s AND
        zerver_message.pub_date < %%(time_end)s
    GROUP BY zerver_stream.id %(group_by_clause)s
"""
"""
    INSERT INTO analytics_realmcount
        (realm_id, value, property, subgroup, end_time)
    SELECT
        zerver_realm.id, count(*),'%(property)s', %(subgroup)s, %%(time_end)s
    FROM zerver_realm
    JOIN zerver_userprofile
    ON
        zerver_realm.id = zerver_userprofile.realm_id
    WHERE
        zerver_realm.date_created < %%(time_end)s AND
        zerver_userprofile.date_joined >= %%(time_start)s AND
        zerver_userprofile.date_joined < %%(time_end)s AND
        zerver_userprofile.is_active = TRUE
    GROUP BY zerver_realm.id %(group_by_clause)s
"""
"""
    INSERT INTO analytics_usercount
        (user_id, realm_id, value, property, subgroup, end_time)
    SELECT
        ral1.modified_user_id, ral1.realm_id, 1, '%(property)s', %(subgroup)s, %%(time_end)s
    FROM zerver_realmauditlog ral1
    JOIN (
        SELECT modified_user_id, max(event_time) AS max_event_time
        FROM zerver_realmauditlog
        WHERE
            event_type in ('user_created', 'user_deactivated', 'user_activated', 'user_reactivated') AND
            event_time < %%(time_end)s
        GROUP BY modified_user_id
    ) ral2
    ON
        ral1.event_time = max_event_time AND
        ral1.modified_user_id = ral2.modified_user_id
    JOIN zerver_userprofile
    ON
        ral1.modified_user_id = zerver_userprofile.id
    WHERE
        ral1.event_type in ('user_created', 'user_activated', 'user_reactivated')
"""
"""
    INSERT INTO analytics_usercount
        (user_id, realm_id, value, property, subgroup, end_time)
    SELECT
        zerver_userprofile.id, zerver_userprofile.realm_id, 1, '%(property)s', %(subgroup)s, %%(time_end)s
    FROM zerver_userprofile
    JOIN zerver_useractivityinterval
    ON
        zerver_userprofile.id = zerver_useractivityinterval.user_profile_id
    WHERE
        zerver_useractivityinterval.end >= %%(time_start)s AND
        zerver_useractivityinterval.start < %%(time_end)s
    GROUP BY zerver_userprofile.id %(group_by_clause)s
"""
"""
    INSERT INTO analytics_realmcount
        (realm_id, value, property, subgroup, end_time)
    SELECT
        usercount1.realm_id, count(*), '%(property)s', NULL, %%(time_end)s
    FROM (
        SELECT realm_id, user_id
        FROM analytics_usercount
        WHERE
            property = 'active_users_audit:is_bot:day' AND
            subgroup = 'false' AND
            end_time = %%(time_end)s
    ) usercount1
    JOIN (
        SELECT realm_id, user_id
        FROM analytics_usercount
        WHERE
            property = '15day_actives::day' AND
            end_time = %%(time_end)s
    ) usercount2
    ON
        usercount1.user_id = usercount2.user_id
    GROUP BY usercount1.realm_id
"""
"""
    INSERT INTO analytics_realmcount
        (realm_id, value, property, subgroup, end_time)
    SELECT
        zerver_realm.id, count(*), '%(property)s', %(subgroup)s, %%(time_end)s
    FROM zerver_realm
    JOIN zerver_stream
    ON
        zerver_realm.id = zerver_stream.realm_id AND
    WHERE
        zerver_realm.date_created < %%(time_end)s AND
        zerver_stream.date_created >= %%(time_start)s AND
        zerver_stream.date_created < %%(time_end)s
    GROUP BY zerver_realm.id %(group_by_clause)s
"""
"""
    Generate semi-realistic looking time series data for testing analytics graphs.

    days -- Number of days of data. Is the number of data points generated if
        frequency is CountStat.DAY.
    business_hours_base -- Average value during a business hour (or day) at beginning of
        time series, if frequency is CountStat.HOUR (CountStat.DAY, respectively).
    non_business_hours_base -- The above, for non-business hours/days.
    growth -- Ratio between average values at end of time series and beginning of time series.
    autocorrelation -- Makes neighboring data points look more like each other. At 0 each
        point is unaffected by the previous point, and at 1 each point is a deterministic
        function of the previous point.
    spikiness -- 0 means no randomness (other than holiday_rate), higher values increase
        the variance.
    holiday_rate -- Fraction of days randomly set to 0, largely for testing how we handle 0s.
    frequency -- Should be CountStat.HOUR or CountStat.DAY.
    partial_sum -- If True, return partial sum of the series.
    random_seed -- Seed for random number generator.
    """
# If min_length is None, returns end_times from ceiling(start) to floor(end), inclusive.

# If min_length is greater than 0, pads the list to the left.

# So informally, time_range(Sep 20, Sep 22, day, None) returns [Sep 20, Sep 21, Sep 22],

# and time_range(Sep 20, Sep 22, day, 5) returns [Sep 18, Sep 19, Sep 20, Sep 21, Sep 22]

"""Report analytics of user activity on a per-user and realm basis.

This command aggregates user activity data that is collected by each user using Zulip. It attempts
to approximate how much each user has been using Zulip per day, measured by recording each 15 minute
period where some activity has occurred (mouse move or keyboard activity).

It will correctly not count server-initiated reloads in the activity statistics.

The duration flag can be used to control how many days to show usage duration for

Usage: ./manage.py analyze_user_activity [--realm=zulip] [--date=2013-09-10] [--duration=1]

By default, if no date is selected 2013-09-10 is used. If no realm is provided, information
is shown for all realms"""
"""Checks FillState table.

    Run as a cron job that runs every hour."""
"""Clear analytics tables."""
"""Clear analytics tables."""
"""Report rough client activity globally, for a realm, or for a user

Usage examples:

./manage.py client_activity --target server
./manage.py client_activity --target realm --realm zulip
./manage.py client_activity --target user --user hamlet@zulip.com --realm zulip"""
"""Populates analytics tables with randomly generated data."""
"""Fills Analytics tables.

    Run as a cron job that runs every hour."""
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.10.4 on 2017-01-16 20:50

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-02-01 22:28

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-01-29 08:14

# -*- coding: utf-8 -*-

# Generated by Django 1.11.18 on 2019-02-02 02:47

"""Assert that the state of a *Count table is what it should be.

        Example usage:
            self.assertTableState(RealmCount, ['property', 'subgroup', 'realm'],
                                  [['p1', 4], ['p2', 10, self.alt_realm]])

        table -- A *Count table.
        arg_keys -- List of columns of <table>.
        arg_values -- List of "rows" of <table>.
            Each entry of arg_values (e.g. ['p1', 4]) represents a row of <table>.
            The i'th value of the entry corresponds to the i'th arg_key, so e.g.
            the first arg_values entry here corresponds to a row of RealmCount
            with property='p1' and subgroup=10.
            Any columns not specified (in this case, every column of RealmCount
            other than property and subgroup) are either set to default values,
            or are ignored.

        The function checks that every entry of arg_values matches exactly one
        row of <table>, and that no additional rows exist. Note that this means
        checking a table with duplicate rows is not supported.
        """
"""INSERT INTO analytics_realmcount (realm_id, value, property, end_time)
                   VALUES (%s, 1, '%s', %%%%(time_end)s)"""
"""INSERT INTO analytics_realmcount (realm_id, value, property, end_time)
                   VALUES (%s, 1, '%s', %%%%(time_end)s)"""
"""INSERT INTO analytics_realmcount (realm_id, value, property, end_time)
                   VALUES (%s, 1, '%s', %%%%(time_end)s)"""
# A very light test suite; the code being tested is not run in production.

# -*- coding: utf-8 -*-

# Copyright: (c) 2008, Jarek Zgoda <jarek.zgoda@gmail.com>

# Functions related to links generated by the generate_realm_creation_link.py

# management command.

# Note that being validated here will just allow the user to access the create_realm

# form, where they will enter their email and go through the regular

# Confirmation.REALM_CREATION pathway.

# Arguably RealmCreationKey should just be another ConfirmationObjT and we should

# add another Confirmation.type for this; it's this way for historical reasons.

"""
    Generate a unique link that a logged-out user can visit to unsubscribe from
    Zulip e-mails without having to first log in.
    """
"""Get the record for this key, raising InvalidCreationKey if non-None but invalid."""
# -*- coding: utf-8 -*-

# Copyright: (c) 2008, Jarek Zgoda <jarek.zgoda@gmail.com>

# -*- coding: utf-8 -*-

# Copyright: (c) 2008, Jarek Zgoda <jarek.zgoda@gmail.com>

# Permission is hereby granted, free of charge, to any person obtaining a

# copy of this software and associated documentation files (the

# "Software"), to deal in the Software without restriction, including

# without limitation the rights to use, copy, modify, merge, publish, dis-

# tribute, sublicense, and/or sell copies of the Software, and to permit

# persons to whom the Software is furnished to do so, subject to the fol-

# lowing conditions:

#

# The above copyright notice and this permission notice shall be included

# in all copies or substantial portions of the Software.

#

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS

# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABIL-

# ITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT

# SHALL THE AUTHOR BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,

# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,

# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

# IN THE SOFTWARE.

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.10.4 on 2017-01-17 09:16

# -*- coding: utf-8 -*-

# Generated by Django 1.11.2 on 2017-07-08 04:23

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2017-11-30 00:13

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-01-29 18:39

# Make a copy of i18n_urlpatterns so that they appear without prefix for English

# Should only be called if the customer is being charged automatically

# Be extremely careful changing this function. Historical billing periods

# are not stored anywhere, and are just computed on the fly using this

# function. Any change you make here should return the same value (or be

# within a few seconds) for basically any value from when the billing system

# went online to within a year from now.

# TODO take downgrade into account

# TODO take downgrade into account

# event_time should roughly be timezone_now(). Not designed to handle

# event_times in the past or future

# TODO handle downgrade

# Returns Customer instead of stripe_customer so that we don't make a Stripe

# API call if there's nothing to update

# Only used for cloud signups

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-09-25 12:02

# -*- coding: utf-8 -*-

# Generated by Django 1.11.16 on 2018-12-12 20:19

# -*- coding: utf-8 -*-

# Generated by Django 1.11.16 on 2018-12-22 21:05

# -*- coding: utf-8 -*-

# Generated by Django 1.11.18 on 2019-01-19 05:01

# -*- coding: utf-8 -*-

# Generated by Django 1.11.18 on 2019-01-28 13:04

# -*- coding: utf-8 -*-

# Generated by Django 1.11.18 on 2019-01-29 01:46

# -*- coding: utf-8 -*-

# Generated by Django 1.11.18 on 2019-01-31 22:16

# TODO: check that this creates a token similar to what is created by our

# actual Stripe Checkout flows

# A Kandra is a fictional character that can become anything. Used as a

# wildcard when testing for equality.

# -*- coding: utf-8 -*-

#

# zulip-contributor-docs documentation build configuration file, created by

# sphinx-quickstart on Mon Aug 17 16:24:04 2015.

#

# This file is execfile()d with the current directory set to its

# containing dir.

#

# Note that not all possible configuration values are present in this

# autogenerated file.

#

# All configuration values have a default; values that are commented out

# serve to show the default.

# If extensions (or modules to document with autodoc) are in another directory,

# add these directories to sys.path here. If the directory is relative to the

# documentation root, use os.path.abspath to make it absolute, like shown here.

#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration ------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.

#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be

# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom

# ones.

# Add any paths that contain templates here, relative to this directory.

# The encoding of source files.

#source_encoding = 'utf-8-sig'

# The master toctree document.

# General information about the project.

# The version info for the project you're documenting, acts as replacement for

# |version| and |release|, also used in various other places throughout the

# built documents.

#

# The short X.Y version.

# The full version, including alpha/beta/rc tags.

# This allows us to insert a warning that appears only on an unreleased

# version, e.g. to say that something is likely to have changed.

# The language for content autogenerated by Sphinx. Refer to documentation

# for a list of supported languages.

#

# This is also used if you do content translation via gettext catalogs.

# Usually you set "language" from the command line for these cases.

# There are two options for replacing |today|: either, you set today to some

# non-false value, then it is used:

#today = ''

# Else, today_fmt is used as the format for a strftime call.

#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and

# directories to ignore when looking for source files.

# The reST default role (used for this markup: `text`) to use for all

# documents.

#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.

#add_function_parentheses = True

# If true, the current module name will be prepended to all description

# unit titles (such as .. function::).

#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the

# output. They are ignored by default.

#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.

# A list of ignored prefixes for module index sorting.

#modindex_common_prefix = []

# If true, keep warnings as "system message" paragraphs in the built documents.

#keep_warnings = False

# If true, `todo` and `todoList` produce output, else they produce nothing.

# -- Options for HTML output ----------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for

# a list of builtin themes.

# Read The Docs can't import sphinx_rtd_theme, so don't import it there.

# Theme options are theme-specific and customize the look and feel of a theme

# further.  For a list of options available for each theme, see the

# documentation.

# Add any paths that contain custom themes here, relative to this directory.

#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to

# "<project> v<release> documentation".

#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.

#html_short_title = None

# The name of an image file (relative to this directory) to place at the top

# of the sidebar.

#html_logo = None

# The name of an image file (within the static path) to use as favicon of the

# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32

# pixels large.

#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,

# relative to this directory. They are copied after the builtin static files,

# so a file named "default.css" will overwrite the builtin "default.css".

# Add any extra paths that contain custom files (such as robots.txt or

# .htaccess) here, relative to this directory. These files are copied

# directly to the root of the documentation.

#html_extra_path = []

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,

# using the given strftime format.

#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to

# typographically correct entities.

#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.

#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to

# template names.

#html_additional_pages = {}

# If false, no module index is generated.

#html_domain_indices = True

# If false, no index is generated.

#html_use_index = True

# If true, the index is split into individual pages for each letter.

#html_split_index = False

# If true, links to the reST sources are added to the pages.

#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.

#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.

#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will

# contain a <link> tag referring to it.  The value of this option must be the

# base URL from which the finished HTML is served.

#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").

#html_file_suffix = None

# Language to be used for generating the HTML full-text search index.

# Sphinx supports the following languages:

#   'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'

#   'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'

#html_search_language = 'en'

# A dictionary with options for the search language support, empty by default.

# Now only 'ja' uses this config value

#html_search_options = {'type': 'default'}

# The name of a javascript file (relative to the configuration directory) that

# implements a search results scorer. If empty, the default will be used.

#html_search_scorer = 'scorer.js'

# Output file base name for HTML help builder.

# -- Options for LaTeX output ---------------------------------------------

# Grouping the document tree into LaTeX files. List of tuples

# (source start file, target name, title,

#  author, documentclass [howto, manual, or own class]).

# The name of an image file (relative to this directory) to place at the top of

# the title page.

#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,

# not chapters.

#latex_use_parts = False

# If true, show page references after internal links.

#latex_show_pagerefs = False

# If true, show URL addresses after external links.

#latex_show_urls = False

# Documents to append as an appendix to all manuals.

#latex_appendices = []

# If false, no module index is generated.

#latex_domain_indices = True

# -- Options for manual page output ---------------------------------------

# One entry per manual page. List of tuples

# (source start file, name, description, authors, manual section).

# If true, show URL addresses after external links.

#man_show_urls = False

# -- Options for Texinfo output -------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples

# (source start file, target name, title, author,

#  dir menu entry, description, category)

# Documents to append as an appendix to all manuals.

#texinfo_appendices = []

# If false, no module index is generated.

#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.

#texinfo_show_urls = 'footnote'

# If true, do not generate a @detailmenu in the "Top" node's menu.

#texinfo_no_detailmenu = False

# The suffix(es) of source filenames.

# You can specify multiple suffix as a list of string:

# -*- coding: utf-8 -*-

"""
ALTER ROLE %(USER)s SET search_path TO %(SCHEMA)s,public,pgroonga,pg_catalog;

SET search_path = %(SCHEMA)s,public,pgroonga,pg_catalog;

ALTER TABLE zerver_message ADD COLUMN search_pgroonga text;

-- TODO: We want to use CREATE INDEX CONCURRENTLY but it can't be used in
-- transaction. Django uses transaction implicitly.
-- Django 1.10 may solve the problem.
CREATE INDEX zerver_message_search_pgroonga ON zerver_message
  USING pgroonga(search_pgroonga pgroonga.text_full_text_search_ops);
"""
"""
SET search_path = %(SCHEMA)s,public,pgroonga,pg_catalog;

DROP INDEX zerver_message_search_pgroonga;
ALTER TABLE zerver_message DROP COLUMN search_pgroonga;

SET search_path = %(SCHEMA)s,public;

ALTER ROLE %(USER)s SET search_path TO %(SCHEMA)s,public;
"""
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

"""
ALTER ROLE %(USER)s SET search_path TO %(SCHEMA)s,public;

SET search_path = %(SCHEMA)s,public;

DROP INDEX zerver_message_search_pgroonga;
"""
"""

CREATE INDEX CONCURRENTLY zerver_message_search_pgroonga ON zerver_message
  USING pgroonga(search_pgroonga pgroonga_text_full_text_search_ops_v2);
"""
"""
ALTER ROLE %(USER)s SET search_path TO %(SCHEMA)s,public,pgroonga,pg_catalog;

SET search_path = %(SCHEMA)s,public,pgroonga,pg_catalog;

DROP INDEX zerver_message_search_pgroonga;
"""
"""

CREATE INDEX CONCURRENTLY zerver_message_search_pgroonga ON zerver_message
  USING pgroonga(search_pgroonga pgroonga.text_full_text_search_ops);
        """
#!/usr/bin/env python3

#!/usr/bin/env python3

#!/usr/bin/env python3

#!/usr/bin/env python3

"""
    Returns a sorted list of unique dependencies specified by the requirements file `fpath`.
    Removes comments from the output and recursively visits files specified inside `fpath`.
    `fpath` can be either an absolute path or a relative path.
    """
#!/usr/bin/env python3

"""
Use libraries from a virtualenv (by modifying sys.path) in production.
"""
"""
    Creates a file, called package_index, in the virtual environment
    directory that contains all the PIP packages installed in the
    virtual environment. This file is used to determine the packages
    that can be copied to a new virtual environment.
    """
"""
    Returns the packages installed in the virtual environment using the
    package index file.
    """
"""
    Tries to copy packages from an old virtual environment in the cache
    to the new virtual environment. The algorithm works as follows:
        1. Find a virtual environment, v, from the cache that has the
        highest overlap with the new requirements such that:
            a. The new requirements only add to the packages of v.
            b. The new requirements only upgrade packages of v.
        2. Copy the contents of v to the new virtual environment using
        virtualenv-clone.
        3. Delete all .pyc files in the new virtual environment.
    """
"""
    Patches the bin/activate script so that the value of the environment variable VIRTUAL_ENV
    is set to venv_path during the script's execution whenever it is sourced.
    """
#!/usr/bin/env python3

# Color codes

"""Warning: su_to_zulip assumes that the zulip checkout is owned by
    the zulip user (or whatever normal user is running the Zulip
    installation).  It should never be run from the installer or other
    production contexts before /home/zulip/deployments/current is
    created."""
"""Returns a nagios-appropriate string and return code obtained by
    parsing the desired file on disk. The file on disk should be of format

    %s|%s % (timestamp, nagios_string)

    This file is created by various nagios checking cron jobs such as
    check-rabbitmq-queues and check-rabbitmq-consumers"""
#!/usr/bin/env python3

# This tools generates /etc/zulip/zulip-secrets.conf

# Standard, 64-bit tokens

# TODO: We can eliminate this function if we refactor the install

# script to run generate_secrets before zulip-puppet-apply.

"""ENABLED=yes
PORT=9292
CAMO_KEY=%s
"""
"""Secret key generation taken from Django's startproject.py"""
#!/usr/bin/env python3

"""
$ ./tools/js-dep-visualizer.py
$ dot -Tpng var/zulip-deps.dot -o var/zulip-deps.png
"""
#!/usr/bin/env python3

# check for the venv

# Clean up stale .pyc files etc.

# Set up a new process group, so that we can later kill run{server,tornado}

# and all of the processes they spawn.

# Save pid of parent process to the pid file. It can be used later by

# tools/stop-run-dev to kill the server without having to find the

# terminal in question.

# Required for compatibility python versions.

# Pass --nostatic because we configure static serving ourselves in

# zulip/urls.py.

# log which services/ports will be started

"""

Starts the app listening on localhost, for local development.

This script launches the Django and Tornado servers, then runs a reverse proxy
which serves to both of them.  After it's all up and running, browse to

    http://localhost:9991/

Note that, while runserver and runtornado have the usual auto-restarting
behavior, the reverse proxy itself does *not* automatically restart on changes
to this file.
"""
#!/usr/bin/env python3

# Use zulip-py3-venv's mypy if it's available.

# find all non-excluded files in current directory

"""
stubs/
"""
# -*- coding: utf-8 -*-

# Scrapy settings for documentation_crawler project

#

# For simplicity, this file contains only settings considered important or

# commonly used. You can find more settings consulting the documentation:

#

#     http://doc.scrapy.org/en/latest/topics/settings.html

#     http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html

#     http://scrapy.readthedocs.org/en/latest/topics/spider-middleware.html

# Crawl responsibly by identifying yourself (and your website) on the user-agent

# Obey robots.txt rules

# Configure maximum concurrent requests performed by Scrapy (default: 16)

#CONCURRENT_REQUESTS = 32

# Configure a delay for requests for the same website (default: 0)

# See http://scrapy.readthedocs.org/en/latest/topics/settings.html#download-delay

# See also autothrottle settings and docs

#DOWNLOAD_DELAY = 3

# The download delay setting will honor only one of:

#CONCURRENT_REQUESTS_PER_DOMAIN = 16

#CONCURRENT_REQUESTS_PER_IP = 16

# Disable cookies (enabled by default)

#COOKIES_ENABLED = False

# Disable Telnet Console (enabled by default)

#TELNETCONSOLE_ENABLED = False

# Override the default request headers:

#DEFAULT_REQUEST_HEADERS = {

#   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',

#   'Accept-Language': 'en',

#}

# Enable or disable spider middlewares

# See http://scrapy.readthedocs.org/en/latest/topics/spider-middleware.html

#SPIDER_MIDDLEWARES = {

#    'documentation_crawler.middlewares.MyCustomSpiderMiddleware': 543,

#}

# Enable or disable downloader middlewares

# See http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html

#DOWNLOADER_MIDDLEWARES = {

#    'documentation_crawler.middlewares.MyCustomDownloaderMiddleware': 543,

#}

# Enable or disable extensions

# See http://scrapy.readthedocs.org/en/latest/topics/extensions.html

#EXTENSIONS = {

#    'scrapy.extensions.telnet.TelnetConsole': None,

#}

# Configure item pipelines

# See http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.html

#ITEM_PIPELINES = {

#    'documentation_crawler.pipelines.SomePipeline': 300,

#}

# Enable and configure the AutoThrottle extension (disabled by default)

# See http://doc.scrapy.org/en/latest/topics/autothrottle.html

#AUTOTHROTTLE_ENABLED = True

# The initial download delay

#AUTOTHROTTLE_START_DELAY = 5

# The maximum download delay to be set in case of high latencies

#AUTOTHROTTLE_MAX_DELAY = 60

# The average number of requests Scrapy should be sending in parallel to

# each remote server

#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0

# Enable showing throttling stats for every response received:

#AUTOTHROTTLE_DEBUG = False

# Enable and configure HTTP caching (disabled by default)

# See http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings

#HTTPCACHE_ENABLED = True

#HTTPCACHE_EXPIRATION_SECS = 0

#HTTPCACHE_DIR = 'httpcache'

#HTTPCACHE_IGNORE_HTTP_CODES = []

#HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'

# This package will contain the spiders of your Scrapy project

#

# Please refer to the documentation for information on how to create and manage

# your spiders.

# Allows a mentor to ssh into a Digital Ocean droplet. This is designed to be

# executed on the target machine.

#

# This script takes the username of the mentor as an argument:

#

# $ python3 add_mentor.py <mentor's username>

#

# Alternatively you can pass in --remove to remove their ssh key from the

# machine:

#

# $ python3 add_mentor.py --remove <mentor's username>

# Wrap keys with line comments for easier key removal.

#<{username}>{{{{

#}}}}<{username}>

"""\
#<{username}>{{{{
{key}
#}}}}<{username}>
"""
# Creates a Droplet on Digital Ocean for remote Zulip development.

# Particularly useful for sprints/hackathons, interns, and other

# situation where one wants to quickly onboard new contributors.

#

# This script takes one argument: the name of the GitHub user for whom you want

# to create a Zulip developer environment. Requires Python 3.

#

# Requires python-digitalocean library:

# https://github.com/koalalorenzo/python-digitalocean

#

# Also requires Digital Ocean team membership for Zulip and api token:

# https://cloud.digitalocean.com/settings/api/tokens

#

# Copy conf.ini-template to conf.ini and populate with your api token.

#

# usage: python3 create.py <username>

# initiation argument parser

"""\
cd /home/zulipdev/{1} && git remote add origin https://github.com/{0}/{1}.git && git fetch origin"""
"""
    #cloud-config
    users:
      - name: zulipdev
        ssh_authorized_keys:{0}
    runcmd:
      - su -c '{1}' zulipdev
      - su -c 'git clean -f' zulipdev
      - su -c '{2}' zulipdev
      - su -c 'git clean -f' zulipdev
      - su -c 'git config --global core.editor nano' zulipdev
      - su -c 'git config --global pull.rebase true' zulipdev
    power_state:
     mode: reboot
     condition: True
    """
"""
COMPLETE! Droplet for GitHub user {0} is available at {0}.zulipdev.org.

Instructions for use are below. (copy and paste to the user)

------
Your remote Zulip dev server has been created!

- Connect to your server by running
  `ssh zulipdev@{0}.zulipdev.org` on the command line
  (Terminal for macOS and Linux, Bash for Git on Windows).
- There is no password; your account is configured to use your ssh keys.
- Once you log in, you should see `(zulip-py3-venv) ~$`.
- To start the dev server, `cd zulip` and then run `./tools/run-dev.py`.
- While the dev server is running, you can see the Zulip server in your browser at
  http://{0}.zulipdev.org:9991.
"""
# The phrases in this list will be ignored. The longest phrase is

# tried first; this removes the chance of smaller phrases changing

# the text before longer phrases are tried.

# The errors shown by `tools/check-capitalization` can be added to

# this list without any modification.

# Sort regexes in descending order of their lengths. As a result, the

# longer phrases will be ignored first.

# Compile regexes to improve performance. This also extracts the

# text using BeautifulSoup and then removes extra whitespaces from

# it. This step enables us to add HTML in our regexes directly.

# Regexes which check capitalization in sentences.

"""
    Safe phrase is in lower case and doesn't contain characters which can
    conflict with split boundaries. All conflicting characters are replaced
    with low dash (_).
    """
"""
    The idea is to convert IGNORED_PHRASES into safe phrases, see
    `get_safe_phrase()` function. The only exception is when the
    IGNORED_PHRASE is at the start of the text or after a split
    boundary; in this case, we change the first letter of the phrase
    to upper case.
    """
"""
    This returns text which is rendered by BeautifulSoup and is in the
    form that can be split easily and has all IGNORED_PHRASES processed.
    """
# Word list from https://github.com/m1foley/fit-commit

# Copyright (c) 2015 Mike Foley

# License: MIT

# Ref: fit_commit/validators/tense.rb

""" Find the imperative mood version of `word` by looking at the first
    3 characters. """
""" This rule will enforce that the commit message title uses imperative
    mood. This is done by checking if the first word is in `WORD_SET`, if so
    show the word in the correct mood. """
"""Allows revert commits contrary to the built-in title-match-regex rule"""
"""
    For <p><div id='yo'>bla<span class='bar'></span></div></p>, store a
    representation of the tags all the way down to the leaf, which would
    conceptually be something like "p div(#yo) span(.bar)".
    """
"""
        produces representation of a node in staircase-like format:

            html
                body.main-section
                    p#intro

        """
"""
        produces one-line representation of branch:

        html body.main-section p#intro
        """
#!/usr/bin/env python3

# TODO: De-duplicate this with emoji_dump.py

# Check the RAM on the user's system, and throw an effort if <1.5GB.

# This avoids users getting segfaults running `pip install` that are

# generally more annoying to debug.

# Ideally we wouldn't need to install a dependency here, before we

# know the codename.

# Verify the Zulip venv is available.

"""Get the exit code of the server, or None if it is still running."""
# -*- coding: utf-8 -*-

# Exclude some directories and files from lint checking

#!/usr/bin/env python3

#!/usr/bin/env python3

# This file contains various helper functions used by `build_emoji` tool.

# See docs/subsystems/emoji.md for details on how this system works.

# Emojisets that we currently support.

# Some image files in the old emoji farm had a different name than in the new emoji

# farm. `remapped_emojis` is a map that contains a mapping of their name in the old

# emoji farm to their name in the new emoji farm.

# Emoticons and which emoji they should become. Duplicate emoji are allowed.

# Changes here should be mimicked in `templates/zerver/help/enable-emoticon-translations.md`.

# Returns a dict from categories to list of codepoints. The list of

# codepoints are sorted according to the `sort_order` as defined in

# `emoji_data`.

# Use only those names for which images are present in all

# the emoji sets so that we can switch emoji sets seemlessly.

"""
        <p>Please re-enter your password to confirm your identity.
                (<a href="/accounts/password/reset/" target="_blank">Forgotten it?</a>)</p>
                """
"""
            <p id="test" class="test1 test2">foo</p>
        """
"""
            <!-- test -->
            <!DOCTYPE html>
            <html>
            <!-- test -->
            <head>
                <title>Test</title>
                <meta charset="utf-8" />
                <link rel="stylesheet" href="style.css" />
            </head>
            <body>
                <p>Hello<br />world!</p>
                <p>Goodbye<!-- test -->world!</p>
            </body>
            </html>
            <!-- test -->
        """
"""
            <!-- test -->
            <!DOCTYPE html>
            <html>
            <!-- test -->
            <head>
                <title>Test</title>
                <meta charset="utf-8" />
                <link rel="stylesheet" href="style.css" />
            </head>
            <body>
                <p>Hello<br />world!</p>
                <p>Goodbye<!-- test -->world!</p>
            </body>
            </html>
            <!-- test -->
        """
"""Verifies that the paths mentioned in linter rules actually exist"""
"""Verifies that the search regex specified in a custom rule actually matches
           the expectation and doesn't throw false positives."""
# Note that GOOD_HTML isn't necessarily beautiful HTML.  Apart

# from adjusting indentation, we mostly leave things alone to

# respect whatever line-wrapping styles were in place before.

"""
<!-- test -->
<!DOCTYPE html>



<html>
    <!-- test -->
    <head>
        <title>Test</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="style.css" />
    </head>
    <body>
      <div><p>Hello<br />world!</p></div>
        <p>Goodbye<!-- test -->world!</p>
        <table>
           <tr>
                       <td>5</td>
           </tr>
        </table>
    <pre>
            print 'hello world'
    </pre>
         <div class = "foo"
              id = "bar"
              role = "whatever">{{ bla }}</div>
    </body>
</html>
<!-- test -->
"""
"""
<!-- test -->
<!DOCTYPE html>



<html>
    <!-- test -->
    <head>
        <title>Test</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="style.css" />
    </head>
    <body>
        <div><p>Hello<br />world!</p></div>
        <p>Goodbye<!-- test -->world!</p>
        <table>
            <tr>
                <td>5</td>
            </tr>
        </table>
    <pre>
            print 'hello world'
    </pre>
        <div class = "foo"
          id = "bar"
          role = "whatever">{{ bla }}</div>
    </body>
</html>
<!-- test -->
"""
"""
<html>
  <body>
    foobarfoobarfoo<b>bar</b>
  </body>
</html>
"""
"""
<html>
    <body>
        foobarfoobarfoo<b>bar</b>
    </body>
</html>
"""
"""
<html>
  <body>
    {{# foobar area}}
    foobarfoobarfoo<b>bar</b>
    {{/ foobar area}}
  </body>
</html>
"""
"""
<html>
    <body>
        {{# foobar area}}
        foobarfoobarfoo<b>bar</b>
        {{/ foobar area}}
    </body>
</html>
"""
"""
<html>
  <body>
    {{# foobar area}}
    foobarfoobar<blockquote>
    <p>
        FOOBAR
    </p>
                </blockquote>
    {{/ foobar area}}
  </body>
</html>
"""
"""
<html>
    <body>
        {{# foobar area}}
        foobarfoobar<blockquote>
                        <p>
                            FOOBAR
                        </p>
                    </blockquote>
        {{/ foobar area}}
    </body>
</html>
"""
"""
<div>
  foo
  <p>hello</p>
  bar
</div>
"""
"""
<div>
    foo
    <p>hello</p>
    bar
</div>
"""
"""
<div>
  foo
  {{#if foobar}}
  hello
  {{else}}
  bye
  {{/if}}
  bar
</div>
"""
"""
<div>
    foo
    {{#if foobar}}
    hello
    {{else}}
    bye
    {{/if}}
    bar
</div>
"""
"""
<div>
  <p> <strong> <span class = "whatever">foobar </span> </strong></p>
</div>
"""
"""
<div>
    <p> <strong> <span class = "whatever">foobar </span> </strong></p>
</div>
"""
"""
<div class="foobar">
<input type="foobar" name="temp" value="{{dyn_name}}"
       {{#unless invite_only}}checked="checked"{{/unless}} /> {{dyn_name}}
{{#if invite_only}}<i class="fa fa-lock"></i>{{/if}}
</div>
"""
"""
<div class="foobar">
    <input type="foobar" name="temp" value="{{dyn_name}}"
      {{#unless invite_only}}checked="checked"{{/unless}} /> {{dyn_name}}
    {{#if invite_only}}<i class="fa fa-lock"></i>{{/if}}
</div>
"""
"""
{{#each test}}
  {{#with this}}
  {{#if foobar}}
    <div class="anything">{{{test}}}</div>
  {{/if}}
  {{#if foobar2}}
  {{partial "teststuff"}}
  {{/if}}
  {{/with}}
{{/each}}
"""
"""
{{#each test}}
    {{#with this}}
        {{#if foobar}}
        <div class="anything">{{{test}}}</div>
        {{/if}}
        {{#if foobar2}}
        {{partial "teststuff"}}
        {{/if}}
    {{/with}}
{{/each}}
"""
"""
<form id="foobar" class="whatever">
    {{!        <div class="anothertest"> }}
    <input value="test" />
    <button type="button"><i class="test"></i></button>
    <button type="button"><i class="test"></i></button>
    {{!        </div> }}
    <div class="test"></div>
</form>
"""
"""
<form id="foobar" class="whatever">
    {{!        <div class="anothertest"> }}
    <input value="test" />
    <button type="button"><i class="test"></i></button>
    <button type="button"><i class="test"></i></button>
    {{!        </div> }}
    <div class="test"></div>
</form>
"""
"""
{% block portico_content %}
<div class="test">
<i class='test'></i> foobar
</div>
<div class="test1">
{% for row in data %}
<div class="test2">
    {% for group in (row[0:2], row[2:4]) %}
    <div class="test2">
    </div>
    {% endfor %}
</div>
{% endfor %}
</div>
{% endblock %}
"""
"""
{% block portico_content %}
<div class="test">
    <i class='test'></i> foobar
</div>
<div class="test1">
    {% for row in data %}
    <div class="test2">
        {% for group in (row[0:2], row[2:4]) %}
        <div class="test2">
        </div>
        {% endfor %}
    </div>
    {% endfor %}
</div>
{% endblock %}
"""
"""
<div class="test1">
  <div class="test2">
    foobar
    <div class="test2">
        </div>
</div>
</div>
"""
"""
<div class="test1">
    <div class="test2">
        foobar
        <div class="test2">
        </div>
    </div>
</div>
"""
"""
<div class="test1">
<pre>
  <div class="test2">
    foobar
    <div class="test2">
        </div>
</div>
</pre>
</div>
"""
"""
<div class="test1">
<pre>
  <div class="test2">
    foobar
    <div class="test2">
        </div>
</div>
</pre>
</div>
"""
"""
<div>
  {{#if this.code}}
    <div>&nbsp:{{this.name}}:</div>
  {{else}}
    {{#if this.is_realm_emoji}}
      <img src="{{this.url}}" class="emoji" />
    {{else}}
      <div/>
    {{/if}}
  {{/if}}
  <div>{{this.count}}</div>
</div>
"""
"""
<div>
    {{#if this.code}}
        <div>&nbsp:{{this.name}}:</div>
    {{else}}
        {{#if this.is_realm_emoji}}
        <img src="{{this.url}}" class="emoji" />
        {{else}}
        <div/>
        {{/if}}
    {{/if}}
    <div>{{this.count}}</div>
</div>
"""
"""
<div>
  {{#if this.code}}
    <pre>Here goes some cool code.</pre>
  {{else}}
    <div>
    content of first div
    <div>
    content of second div.
    </div>
    </div>
  {{/if}}
</div>
"""
"""
<div>
    {{#if this.code}}
    <pre>Here goes some cool code.</pre>
    {{else}}
    <div>
        content of first div
        <div>
            content of second div.
        </div>
    </div>
    {{/if}}
</div>
"""
"""
<div>
  <img alt=":thumbs_up:"
    class="emoji"
    src="/path/to/png"
title=":thumbs_up:"/>
    <img alt=":thumbs_up:"
        class="emoji"
        src="/path/to/png"
    title=":thumbs_up:"/>
    <img alt=":thumbs_up:"
    title=":thumbs_up:"/>
</div>
"""
"""
<div>
    <img alt=":thumbs_up:"
      class="emoji"
      src="/path/to/png"
      title=":thumbs_up:"/>
    <img alt=":thumbs_up:"
      class="emoji"
      src="/path/to/png"
      title=":thumbs_up:"/>
    <img alt=":thumbs_up:"
      title=":thumbs_up:"/>
</div>
"""
"""
<div>
  {{partial "settings_checkbox"
  "setting_name" "realm_name_in_notifications"
  "is_checked" page_params.realm_name_in_notifications
  "label" settings_label.realm_name_in_notifications}}
</div>
"""
"""
<div>
    {{partial "settings_checkbox"
      "setting_name" "realm_name_in_notifications"
      "is_checked" page_params.realm_name_in_notifications
      "label" settings_label.realm_name_in_notifications}}
</div>
"""
"""
<div>
  <button type="button"
class="btn btn-primary btn-small">{{t "Yes" }}</button>
<button type="button"
id="confirm_btn"
class="btn btn-primary btn-small">{{t "Yes" }}</button>
<div class = "foo"
     id = "bar"
     role = "whatever">
     {{ bla }}
</div>
</div>
"""
"""
<div>
    <button type="button"
      class="btn btn-primary btn-small">{{t "Yes" }}</button>
    <button type="button"
      id="confirm_btn"
      class="btn btn-primary btn-small">{{t "Yes" }}</button>
    <div class = "foo"
      id = "bar"
      role = "whatever">
        {{ bla }}
    </div>
</div>
"""
# -*- coding: utf-8 -*-

"""Registers an external linter program to be run as part of the
        linter.  This program will be passed the subset of files being
        linted that have extensions in target_langs.  If there are no
        such files, exits without doing anything.

        If target_langs is empty, just runs the linter unconditionally.
        """
#!/usr/bin/env python3

"""
    List files tracked by git.

    Returns a list of files which are either in targets or in directories in targets.
    If targets is [], list of all tracked files in current directory is returned.

    Other arguments:
    ftypes - List of file types on which to filter the search.
        If ftypes is [], all files are included.
    use_shebang - Determine file type of extensionless files from their shebang.
    modified_only - Only include files which have been modified.
    exclude - List of files or directories to be excluded, relative to repository root.
    group_by_ftype - If True, returns a dict of lists keyed by file type.
        If False, returns a flat list of files.
    extless_only - Only include extensionless files in output.
    """
# Terminal Color codes for use in differentiatng linters

"""Common context used for things like outgoing emails that don't
    have a request.
    """
"""Context available to all Zulip Jinja2 templates that have a request
    passed in.  Designed to provide the long list of variables at the
    bottom of this function in a wide range of situations: logged-in
    or logged-out, subdomains or not, etc.

    The main variable in the below is whether we know what realm the
    user is trying to interact with.
    """
# This is a hack to ensure that RemoteZulipServer always exists even

# if Zilencer isn't enabled.

# Return RespondAsynchronously from an @asynchronous view if the

# response will be provided later by calling handler.zulip_finish(),

# or has already been provided this way. We use this for longpolling

# mode.

# Based on django.views.decorators.http.require_http_methods

# Use this for webhook views that don't get an email passed in.

# From Django 1.8, modified to leave off ?next=/

# From Django 1.8

# Based on Django 1.8's @login_required

# authenticated_api_view will add the authenticated user's

# user_profile to the view function's arguments list, since we have to

# look it up anyway.  It is deprecated in favor on the REST API

# versions.

# This API endpoint is used only for the mobile apps.  It is part of a

# workaround for the fact that React Native doesn't support setting

# HTTP basic authentication headers.

# A more REST-y authentication decorator, using, in particular, HTTP Basic

# authentication.

#

# If webhook_client_name is specific, the request is a webhook view

# with that string as the basis for the client string.

# Checks if the request is a POST request and that the user is logged

# in.  If not, return an error (the @login_required behavior of

# redirecting to a login page doesn't make sense for json views)

# These views are used by the main Django server to notify the Tornado server

# of events.  We protect them from the outside world by checking a shared

# secret, and also the originating IP (for now).

"""
user: {email} ({realm})
client: {client_name}
URL: {path_info}
content_type: {content_type}
custom_http_headers:
{custom_headers}
body:

{body}
    """
"""
    Redirects the user to the login page, passing the given 'next' page
    """
"""
    Decorator for views that checks that the user passes the given test,
    redirecting to the log-in page if necessary. The test should be a callable
    that takes the user object and returns True if the user passes.
    """
"""Creates a session, logging in the user, using the Django method,
    and also adds helpful data needed by our server logs.
    """
"""Used for situations where something running on the Zulip server
    needs to make a request to the (other) Django/Tornado processes running on
    the server."""
"""Increments a statsd counter on completion of the
    decorated function.

    Pass the name of the counter to this decorator-returning function."""
"""Returns whether or not a user was rate limited. Will raise a RateLimited exception
    if the user has been rate limited, otherwise returns and modifies request to contain
    the rate limit information"""
"""Rate-limits a view. Takes an optional 'domain' param if you wish to
    rate limit different types of API calls independently.

    Returns a decorator"""
"""
    The reason we need to create this function is that the stock
    otp_required decorator doesn't play well with tests. We cannot
    enable/disable if_configured parameter during tests since the decorator
    retains its value due to closure.

    Similar to :func:`~django.contrib.auth.decorators.login_required`, but
    requires the user to be :term:`verified`. By default, this redirects users
    to :setting:`OTP_LOGIN_URL`.
    """
"""
        :if_configured: If ``True``, an authenticated user with no confirmed
        OTP devices will be allowed. Default is ``False``. If ``False``,
        2FA will not do any authentication.
        """
"""Prevent MIT mailing lists from signing up for Zulip"""
"""Returns the email if and only if the user's email address is
        allowed to join the realm they are trying to join."""
"""
        If the email address has an account in the target realm,
        generates a one-use only link for resetting password and sends
        to the user.

        We send a different email if an associated account does not exist in the
        database, or an account does exist, but not in the realm.

        Note: We ignore protocol and the various email template arguments (those
        are an artifact of using Django's password reset framework).
        """
"""Disable prefix, since Zulip doesn't use this Django forms feature
        (and django-two-factor does use it), and we'd like both to be
        happy with this form.
        """
"""
    We add this form to update the widget of otp_token. The default
    widget is an input element whose type is a number, which doesn't
    stylistically match our theme.
    """
"""Normalize data to a list of strings."""
"""Check if value consists only of valid emails."""
# System documented in https://zulip.readthedocs.io/en/latest/subsystems/logging.html

"""An logging handler that sends the log/exception to the queue to be
       turned into an email and/or a Zulip message for the server admins.
    """
"""
        If request.session was modified, or if the configuration is to save the
        session every time, save the changes and set a session cookie or delete
        the session cookie if the session has been emptied.
        """
"""
    Middleware that sets REMOTE_ADDR based on the HTTP_X_FORWARDED_FOR.

    This middleware replicates Django's former SetRemoteAddrFromForwardedFor middleware.
    Because Zulip sits behind a NGINX reverse proxy, if the HTTP_X_FORWARDED_FOR
    is set in the request, then it has properly been set by NGINX.
    Therefore HTTP_X_FORWARDED_FOR's value is trusted.
    """
# Doing 1000 remote cache requests to get_display_recipient is quite slow,

# so add a local cache as well as the remote cache cache.

# This simple call-once caching saves ~500us in auth_enabled_helper,

# which is a significant optimization for common_context.  Note that

# these values cannot change in a running production system, but do

# regularly change within unit tests; we address the latter by calling

# clear_supported_auth_backends_cache in our standard tearDown code.

# These functions should only be used on email addresses that have

# been validated via django.core.validators.validate_email

#

# Note that we need to use some care, since can you have multiple @-signs; e.g.

# "tabbott@test"@zulip.com

# is valid email address

# Returns the raw domain portion of the desired email address

# Is a user with the given email address allowed to be in the given realm?

# (This function does not check whether the user has been invited to the realm.

# So for invite-only realms, this is the test for whether a user can be invited,

# not whether the user can sign up currently.)

# We have a per-process cache to avoid doing 1000 remote cache queries during page load

# Make sure we flush the UserProfile object from our remote cache

# whenever we save it.

# The Recipient table is used to map Messages to the set of users who

# received the message.  It is implemented as a set of triples (id,

# type_id, type). We have 3 types of recipients: Huddles (for group

# private messages), UserProfiles (for 1:1 private messages), and

# Streams. The recipient table maps a globally unique recipient id

# (used by the Message table) to the type-specific unique id (the

# stream id, user_profile id, or huddle id).

# Whenever a message is sent, for each user subscribed to the

# corresponding Recipient object, we add a row to the UserMessage

# table indicating that that user received that message.  This table

# allows us to quickly query any user's last 1000 messages to generate

# the home view.

#

# Additionally, the flags field stores metadata like whether the user

# has read the message, starred or collapsed the message, was

# mentioned in the message, etc.

#

# UserMessage is the largest table in a Zulip installation, even

# though each row is only 4 integers.

# The Huddle class represents a group of individuals who have had a

# Group Private Message conversation together.  The actual membership

# of the Huddle is stored in the Subscription table just like with

# Streams, and a hash of that list is stored in the huddle_hash field

# below, to support efficiently mapping from a set of users to the

# corresponding Huddle object.

# Interfaces for services

# They provide additional functionality like parsing message to obtain query url, data to be sent to url,

# and parsing the response.

# A Service corresponds to either an outgoing webhook bot or an embedded bot.

# The type of Service is determined by the bot_type field of the referenced

# UserProfile.

#

# If the Service is an outgoing webhook bot:

# - name is any human-readable identifier for the Service

# - base_url is the address of the third-party site

# - token is used for authentication with the third-party site

#

# If the Service is an embedded bot:

# - name is the canonical name for the type of bot (e.g. 'xkcd' for an instance

#   of the xkcd bot); multiple embedded bots can have the same name, but all

#   embedded bots with the same name will run the same code

# - base_url and token are currently unused

"""
    returns: an object describing the recipient (using a cache).
    If the type is a stream, the type_id must be an int; a string is returned.
    Otherwise, type_id may be None; an array of recipient dicts is returned.
    """
"""
    returns: an appropriate object describing the recipient.  For a
    stream this will be the stream name as a string.  For a huddle or
    personal, it will be an array of dicts about each recipient.
    """
"""Returns the a mapping from authentication flags to their status,
        showing only those authentication flags that are supported on
        the current server (i.e. if EmailAuthBackend is not configured
        on the server, this will not return an entry for "Email")."""
"""Likely to be temporary function to avoid signup messages being sent
        to an empty topic"""
"""For an organization with emails_restricted_to_domains enabled, the list of
    allowed domains"""
"""Realm-specific regular expressions to automatically linkify certain
    strings inside the markdown processor.  See "Custom filters" in the settings UI.
    """
"""
    Incoming webhook bots are limited to only sending messages via webhooks.
    Thus, it is less of a security risk to expose their API keys to third-party services,
    since they can't be used to read messages.
    """
"""
    Embedded bots run within the Zulip server itself; events are added to the
    embedded_bots queue and then handled by a QueueProcessingWorker.
    """
"""Returns whether this user has permission to modify target_user"""
"""
    Return all streams (including invite-only streams) that have not been deactivated.
    """
"""Used as a temporary holding place for deleted messages before they
    are permanently deleted.  This is an important part of a robust
    'message retention' feature.
    """
"""
        Please start using this helper to facilitate an
        eventual switch over to a separate topic table.
        """
"""Used to determine whether a message was sent by a full Zulip UI
        style client (and thus whether the message should be treated
        as sent by a human and automatically marked as read for the
        sender).  The purpose of this distinction is to ensure that
        message sent to the user by e.g. a Google Calendar integration
        using the user's own API key don't get marked as read
        automatically.
        """
"""
        Returns True if content and rendered_content are from 'me_message'
        """
"""For emoji reactions to messages (and potentially future reaction types).

    Emoji are surprisingly complicated to implement correctly.  For details
    on how this subsystem works, see:
      https://zulip.readthedocs.io/en/latest/subsystems/emoji.html
    """
"""Used as a temporary holding place for deleted UserMessages objects
    before they are permanently deleted.  This is an important part of
    a robust 'message retention' feature.
    """
"""Used as a temporary holding place for deleted Attachment objects
    before they are permanently deleted.  This is an important part of
    a robust 'message retention' feature.
    """
"""A record from the last time we heard from a given user on a given client.

    This is a tricky subsystem, because it is highly optimized.  See the docs:
      https://zulip.readthedocs.io/en/latest/subsystems/presence.html
    """
"""
    RealmAuditLog tracks important changes to users, streams, and
    realms in Zulip.  It is intended to support both
    debugging/introspection (e.g. determining when a user's left a
    given stream?) as well as help with some database migrations where
    we might be able to do a better data backfill with it.  Here are a
    few key details about how this works:

    * acting_user is the user who initiated the state change
    * modified_user (if present) is the user being modified
    * modified_stream (if present) is the stream being modified

    For example:
    * When a user subscribes another user to a stream, modified_user,
      acting_user, and modified_stream will all be present and different.
    * When an administrator changes an organization's realm icon,
      acting_user is that administrator and both modified_user and
      modified_stream will be None.
    """
"""Defines a form field for the per-realm custom profile fields feature.

    See CustomProfileFieldValue for an individual user's values for one of
    these fields.
    """
# Load AppConfig app subclass by default on django applications initialization

# stubs

"""
    Returns:
    1. realm, Converted Realm data
    2. avatars, which is list to map avatars to zulip avatar records.json
    3. user_map, which is a dictionary to map from gitter user id to zulip user id
    """
"""
    Returns:
    1. zerver_userprofile, which is a list of user profile
    2. avatar_list, which is list to map avatars to zulip avatars records.json
    3. added_users, which is a dictionary to map from gitter user id to zulip id
    """
"""
    Returns:
    1. zerver_recipient, which is a list of mapped recipient
    2. zerver_subscription, which is a list of mapped subscription
    """
"""
    Messages are stored in batches
    """
# stubs

# stubs

"""
    This function should be passed a 'fileinfo' dictionary, which contains
    information about 'size', 'created' (created time) and ['name'] (filename).
    """
"""
    This function gets the avatar of the user and saves it in the
    user's avatar directory with both the extensions '.png' and '.original'
    Required parameters:

    1. avatar_list: List of avatars to be mapped in avatars records.json file
    2. avatar_dir: Folder where the downloaded avatars are saved
    3. realm_id: Realm ID.

    We use this for Slack and Gitter conversions, where avatars need to be
    downloaded.  For simpler conversions see write_avatar_png.
    """
"""
    This function downloads the uploads and saves it in the realm's upload directory.
    Required parameters:

    1. upload_list: List of uploads to be mapped in uploads records.json file
    2. upload_dir: Folder where the downloaded uploads are saved
    """
"""
    This function downloads the custom emojis and saves in the output emoji folder.
    Required parameters:

    1. zerver_realmemoji: List of all RealmEmoji objects to be imported
    2. emoji_dir: Folder where the downloaded emojis are saved
    3. emoji_url_map: Maps emoji name to its url
    """
# stubs

"""
    Returns:
    1. realm, Converted Realm data
    2. added_users, which is a dictionary to map from slack user id to zulip user id
    3. added_recipient, which is a dictionary to map from channel name to zulip recipient_id
    4. added_channels, which is a dictionary to map from channel name to channel id, zulip stream_id
    5. avatars, which is list to map avatars to zulip avatar records.json
    6. emoji_url_map, which is maps emoji name to its slack url
    """
"""
    Returns:
    1. zerver_userprofile, which is a list of user profile
    2. avatar_list, which is list to map avatars to zulip avatard records.json
    3. added_users, which is a dictionary to map from slack user id to zulip
       user id
    4. zerver_customprofilefield, which is a list of all custom profile fields
    5. zerver_customprofilefield_values, which is a list of user profile fields
    """
"""
    Returns:
    1. zerver_defaultstream, which is a list of the default streams
    2. zerver_stream, while is a list of all streams
    3. added_channels, which is a dictionary to map from channel name to channel id, zulip stream_id
    4. zerver_subscription, which is a list of the subscriptions
    5. zerver_recipient, which is a list of the recipients
    6. added_recipient, which is a dictionary to map from channel name to zulip recipient_id
    """
"""Algorithmically, we treat users who have sent at least 10 messages
    or have sent a message within the last 60 days as active.
    Everyone else is treated as long-term idle, which means they will
    have a slighly slower first page load when coming back to
    Zulip.
    """
"""
    Returns:
    1. reactions, which is a list of the reactions
    2. uploads, which is a list of uploads to be mapped in uploads records.json
    3. attachment, which is a list of the attachments
    """
"""This function is an iterator that returns all the messages across
       all Slack channels, in order by timestamp.  It's important to
       not read all the messages into memory at once, because for
       large imports that can OOM kill."""
"""
    Returns:
    1. zerver_message, which is a list of the messages
    2. zerver_usermessage, which is a list of the usermessages
    3. zerver_attachment, which is a list of the attachments
    4. uploads_list, which is a list of uploads to be mapped in uploads records.json
    5. reaction_list, which is a list of all user reactions
    """
# stubs

# Slack link can be in the format <http://www.foo.com|www.foo.com> and <http://foo.com/>

# Slack doesn't have mid-word message-formatting like Zulip.

# Hence, ~stri~ke doesn't format the word in slack, but ~~stri~~ke

# formats the word in Zulip

# Markdown mapping

# Map italic, bold and strikethrough markdown

"""
              (<)                                                              # match '>'
              (http:\/\/www\.|https:\/\/www\.|http:\/\/|https:\/\/|ftp:\/\/)?  # protocol and www
                  ([a-z0-9]+([\-\.]{1}[a-z0-9]+)*)(\.)                         # domain name
                      ([a-z]{2,63}(:[0-9]{1,5})?)                              # domain
                  (\/[^>]*)?                                                   # path
              (\|)?(?:\|([^>]+))?                                # char after pipe (for slack links)
              (>)
              """
"""
                      <((mailto:)?                     # match  `<mailto:`
                      ([\w\.-]+@[\w\.-]+(\.[\w]+)+))   # match email
                          (\|)?                        # match pipe
                      ([\w\.-]+@[\w\.-]+(\.[\w]+)+)?>  # match email
                      """
"""
                           (<@)                  # Start with '<@'
                               ([a-zA-Z0-9]+)    # Here we have the Slack id
                           (\|)?                 # We not always have a Vertical line in mention
                               ([a-zA-Z0-9]+)?   # If Vertical line is present, this is short name
                           (>)                   # ends with '>'
                           """
"""
                             (^|[ -(]|[+-/]|\*|\_|[:-?]|\{|\[|\||\^)     # Start after specified characters
                             (\~)                                  # followed by an asterisk
                                 ([ -)+-}—]*)([ -}]+)              # any character except asterisk
                             (\~)                                  # followed by an asterisk
                             ($|[ -']|[+-/]|[:-?]|\*|\_|\}|\)|\]|\||\^)  # ends with specified characters
                             """
"""
                      (^|[ -*]|[+-/]|[:-?]|\{|\[|\||\^|~)
                      (\_)
                          ([ -^`~—]*)([ -^`-~]+)                  # any character
                      (\_)
                      ($|[ -']|[+-/]|[:-?]|\}|\)|\]|\*|\||\^|~)
                      """
"""
                    (^|[ -(]|[+-/]|[:-?]|\{|\[|\_|\||\^|~)
                    (\*)
                        ([ -)+-~—]*)([ -)+-~]+)                   # any character
                    (\*)
                    ($|[ -']|[+-/]|[:-?]|\}|\)|\]|\_|\||\^|~)
                    """
"""
    Returns:
    1. For strikethrough formatting: This maps Slack's '~strike~' to Zulip's '~~strike~~'
    2. For bold formatting: This maps Slack's '*bold*' to Zulip's '**bold**'
    3. For italic formatting: This maps Slack's '_italic_' to Zulip's '*italic*'
    """
"""
    1. Converts '<https://foo.com>' to 'https://foo.com'
    2. Converts '<https://foo.com|foo>' to 'https://foo.com|foo'
    """
"""
    1. Converts '<mailto:foo@foo.com>' to 'mailto:foo@foo.com'
    2. Converts '<mailto:foo@foo.com|foo@foo.com>' to 'mailto:foo@foo.com'
    """
# This will be used to type annotate parameters in a function if the function

# works on both str and unicode in python 2 but in python 3 it only works on str.

# Store an event in the log for re-importing messages

# Does the processing for a new user account:

# * Subscribes to default/invitation streams

# * Fills in some recent historical messages

# * Notifies other users in realm and Zulip about the signup

# * Deactivates PreregistrationUser objects

# * subscribe the user to newsletter if newsletter_data is specified

# check_send_typing_notification:

# Checks the typing notification and sends it

# check_typing_notification:

# Returns typing notification ready for sending with do_send_typing_notification on success

# or the error message (string) on error.

# check_send_message:

# Returns the id of the sent message.  Has same argspec as check_message.

# check_message:

# Returns message ready for sending with do_send_message on success or the error message (string) on error.

# returns default streams in json serializeable format

# We use transaction.atomic to support select_for_update in the attachment codepath.

# We use transaction.atomic to support select_for_update in the attachment codepath.

# In general, it's better to avoid using .values() because it makes

# the code pretty ugly, but in this case, it has significant

# performance impact for loading / for users with large numbers of

# subscriptions, so it's worth optimizing.

# NOTE: Regexes must be simple enough that they can be easily translated to JavaScript

# RegExp syntax. In addition to JS-compatible syntax, the following features are available:

#   * Named groups will be converted to numbered groups automatically

#   * Inline-regex flags will be stripped, and where possible translated to RegExp-wide flags

"""Give you the last 1000 messages on your public streams, so you have
    something to look at in your home view once you finish the
    tutorial."""
"""Takes in a realm object, the name of an attribute to update, and the
    value to update.
    """
"""
    Deactivate this realm. Do NOT deactivate the users -- we need to be able to
    tell the difference between users that were intentionally deactivated,
    e.g. by a realm admin, and users who can't currently use Zulip because their
    realm has been deactivated.
    """
"""Only includes users on the explicit message to line"""
"""See
    https://zulip.readthedocs.io/en/latest/subsystems/sending-messages.html
    for high-level documentation on this subsystem.
    """
"""Note that stream_dict["name"] is assumed to already be stripped of
    whitespace"""
"""
    Sends a PM error notification to a bot's owner if one hasn't already
    been sent in the last 5 minutes.
    """
"""If a bot sends a message to a stream that doesn't exist or has no
    subscribers, sends a notification to the bot owner (if not a
    cross-realm bot) so that the owner can correct the issue."""
"""See
    https://zulip.readthedocs.io/en/latest/subsystems/sending-messages.html
    for high-level documentation on this subsystem.
    """
"""
    Create a message object and checks it, but doesn't send it or save it to the database.
    The internal function that calls this can therefore batch send a bunch of created
    messages together as one database query.
    Call do_send_messages with a list of the return values of this method.
    """
"""
    See _internal_prep_message for details of how this works.
    """
"""
    See _internal_prep_message for details of how this works.
    """
"""
    See _internal_prep_message for details of how this works.
    """
"""internal_send_message should only be used where `sender_email` is a
    system bot."""
""" Validates whether the user can view the subscribers of a stream.  Raises a JsonableError if:
        * The user and the stream are in different realms
        * The realm is MIT and the stream is not invite only.
        * The stream is invite only, requesting_user is passed, and that user
          does not subscribe to the stream.
    """
"""Helper for validate_user_access_to_subscribers that doesn't require
    a full stream object.  This function is a bit hard to read,
    because it is carefully optimized for performance in the two code
    paths we call it from:

    * In `bulk_get_subscriber_user_ids`, we already know whether the
    user was subscribed via `sub_dict`, and so we want to avoid a
    database query at all (especially since it calls this in a loop);
    * In `validate_user_access_to_subscribers`, we want to only check
    if the user is subscribed when we absolutely have to, since it
    costs a database query.

    The `check_user_subscribed` argument is a function that reports
    whether the user is subscribed to the stream.

    Note also that we raise a ValidationError in cases where the
    caller is doing the wrong thing (maybe these should be
    AssertionErrors), and JsonableError for 400 type errors.
    """
"""sub_dict maps stream_id => whether the user is subscribed to that stream."""
""" Build a query to get the subscribers list for a stream, raising a JsonableError if:

    'realm' is optional in stream.

    The caller can refine this query with select_related(), values(), etc. depending
    on whether it wants objects or just certain fields
    """
"""Verifies that the user's proposed full name is valid.  The caller
    is responsible for checking check permissions.  Returns the new
    full name, which may differ from what was passed in (because this
    function strips whitespace)."""
"""Takes in a UserProfile object, the name of a global notification
    preference to update, and the value to update to
    """
"""Updates the message as stored in the to_dict cache (for serving
    messages)."""
"""
    The main function for message editing.  A message edit event can
    modify:
    * the message's content (in which case the caller will have
      set both content and rendered_content),
    * the topic, in which case the caller will have set topic_name
    * or both

    With topic edits, propagate_mode determines whether other message
    also have their topics edited.
    """
"""
    Send the confirmation/welcome e-mail to an invited user.
    """
""" Get streams with subscribers """
"""
    Deleting a field will also delete the user profile data
    associated with it in CustomProfileFieldValue model.
    """
# SETUP METHODS FOLLOW

"""
    Absolute URLs are used to simplify logic for applications that
    won't be served by browsers, such as rendering GCM notifications.
    """
"""Compute the Gravatar hash for an email address."""
# This is only sed in populate_db, so doesn't realy need tests

"""
    Creates and saves a UserProfile with the given email.
    Has some code based off of UserManage.create_user, but doesn't .save()
    """
# See https://zulip.readthedocs.io/en/latest/subsystems/caching.html for docs

# Generic_bulk_cached fetch and its helpers

# Required Arguments are as follows:

# * object_ids: The list of object ids to look up

# * cache_key_function: object_id => cache key

# * query_function: [object_ids] => [objects from database]

# Optional keyword arguments:

# * setter: Function to call before storing items to cache (e.g. compression)

# * extractor: Function to call on items returned from cache

#   (e.g. decompression).  Should be the inverse of the setter

#   function.

# * id_fetcher: Function mapping an object from database => object_id

#   (in case we're using a key more complex than obj.id)

# * cache_transformer: Function mapping an object from database =>

#   value for cache (in case the values that we're caching are some

#   function of the objects, not the objects themselves)

# Called by models.py to flush the user_profile cache whenever we save

# a user_profile object

# Called by models.py to flush various caches whenever we save

# a Realm object.  The main tricky thing here is that Realm info is

# generally cached indirectly through user_profile objects.

# Called by models.py to flush the stream cache whenever we save a stream

# object.

"""
    The main goal of this function getting value from the cache like in the "cache_with_key".
    A cache value can contain any data including the "None", so
    here used exception for case if value isn't found in the cache.
    """
"""Decorator which applies Django caching to a function.

       Decorator argument is a function which computes a cache key
       from the original function's arguments.  You are responsible
       for avoiding collisions with other uses of this decorator or
       other uses of caching."""
"""Decorator which applies Django caching to a function.

       Uses a key based on the function's name, filename, and
       the repr() of its arguments."""
"""
    This is a wrapper over lru_cache function. It adds following features on
    top of lru_cache:

        * It will not cache result of functions with unhashable arguments.
        * It will clear cache whenever zerver.lib.cache.KEY_PREFIX changes.
    """
# See https://zulip.readthedocs.io/en/latest/subsystems/caching.html for docs

# This file needs to be different from cache.py because cache.py

# cannot import anything from zerver.models or we'd have an import

# loop

# Format is (objects query, items filler function, timeout, batch size)

#

# The objects queries are put inside lambdas to prevent Django from

# doing any setup for things we're unlikely to use (without the lambda

# wrapper the below adds an extra 3ms or so to startup time for

# anything importing this file).

"""For servers like zulipchat.com with a lot of realms, it only makes
    sense to do cache-filling work for realms that have any currently
    active users/clients.  Otherwise, we end up with every single-user
    trial organization that has ever been created costing us N streams
    worth of cache work (where N is the number of default streams for
    a new organization).
    """
# Encodes the provided URL using the same algorithm used by the camo

# caching https image proxy

# This file is adapted from samples/shellinabox/ssh-krb-wrapper in

# https://github.com/davidben/webathena, which has the following

# license:

#

# Copyright (c) 2013 David Benjamin and Alan Huang

#

# Permission is hereby granted, free of charge, to any person

# obtaining a copy of this software and associated documentation files

# (the "Software"), to deal in the Software without restriction,

# including without limitation the rights to use, copy, modify, merge,

# publish, distribute, sublicense, and/or sell copies of the Software,

# and to permit persons to whom the Software is furnished to do so,

# subject to the following conditions:

#

# The above copyright notice and this permission notice shall be

# included in all copies or substantial portions of the Software.

#

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

# BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

# SOFTWARE.

# Some DER encoding stuff. Bleh. This is because the ccache contains a

# DER-encoded krb5 Ticket structure, whereas Webathena deserializes

# into the various fields. Re-encoding in the client would be easy as

# there is already an ASN.1 implementation, but in the interest of

# limiting MIT Kerberos's exposure to malformed ccaches, encode it

# ourselves. To that end, here's the laziest DER encoder ever.

# Kerberos ccache writing code. Using format documentation from here:

# http://www.gnu.org/software/shishi/manual/html_node/The-Credential-Cache-Binary-File-Format.html

"""converts a string to binary string"""
"""
Context managers, i.e. things you can use with the 'with' statement.
"""
"""Lock a file object using flock(2) for the duration of a 'with' statement.

       If shared is True, use a LOCK_SH lock, otherwise LOCK_EX."""
"""Lock a file using flock(2) for the duration of a 'with' statement.

       If shared is True, use a LOCK_SH lock, otherwise LOCK_EX.

       The file is given by name and will be created if it does not exist."""
# create_user_profile is based on Django's User.objects.create_user,

# except that we don't save to the database so it can used in

# bulk_creates

#

# Only use this for bulk_create -- for normal usage one should use

# create_user (below) which will also make the Subscription and

# Recipient objects

"""Warning: Does not save, to avoid extra database queries"""
# Similar to the tracking done in Django's CursorDebugWrapper, but done at the

# psycopg2 cursor level so it works with SQLAlchemy.

"""A psycopg2 cursor class that tracks the time spent executing queries."""
"""A psycopg2 connection class that uses TimeTrackingCursors."""
# Interactive debugging code from

# http://stackoverflow.com/questions/132058/showing-the-stack-trace-from-a-running-python-application

# (that link also points to code for an interactive remote debugger

# setup, which we might want if we move Tornado to run in a daemon

# rather than via screen).

# SIGUSR1 => Just print the stack

# SIGUSR2 => Print stack + open interactive debugging shell

"""Interrupt running process, and provide a python prompt for
    interactive debugging."""
# See https://jackstromberg.com/2013/01/useraccountcontrol-attributeflag-values/

# for docs on what these values mean.

# Digests accumulate 4 types of interesting traffic for a user:

# 1. Missed PMs

# 2. New streams

# 3. New users

# 4. Interesting stream traffic, as determined by the longest and most

#    diversely comment upon topics.

# Changes to this should also be reflected in

# zerver/worker/queue_processors.py:DigestWorker.consume()

# Temporary missed message addresses

## Sending the Zulip ##

# Email mirror rate limiter code:

"""~~~\n%s\n~~~"""
"""
    Builds the message list object for the missed message email template.
    The messages are collapsed into per-recipient and per-sender blocks, like
    our web interface
    """
"""
    Send a reminder email to a user if she's missed some PMs by being offline.

    The email will have its reply to address set to a limited used email
    address that will send a zulip message to the correct recipient. This
    allows the user to respond to missed PMs, huddles, and @-mentions directly
    from the email.

    `user_profile` is the user to send the reminder to
    `missed_messages` is a list of dictionaries to Message objects and other data
                      for a group of messages that share a recipient (and topic)
    """
# Translates emoticons to their colon syntax, e.g. `:smiley:`.

"""Raises an exception if the user cannot administer the target realm
    emoji name in their organization."""
# System documented in https://zulip.readthedocs.io/en/latest/subsystems/logging.html

"""
    Escape CR and LF characters.
    """
# See https://zulip.readthedocs.io/en/latest/subsystems/events-system.html for

# high-level documentation on how this system works.

# Fetch initial data.  When event_types is not specified, clients want

# all event types.  Whenever you add new code to this function, you

# should also add corresponding events for changes in the data

# structures and new code to apply_events (and add a test in EventsRegisterTest).

# This is the main code for the `./manage.py export` data export tool.

# User docs: https://zulip.readthedocs.io/en/latest/production/export-and-import.html

#

# Most developers will interact with this primarily when they add a

# new table to the schema, in which case they likely need to (1) add

# it the lists in `ALL_ZULIP_TABLES` and similar data structures and

# (2) if it doesn't belong in EXCLUDED_TABLES, add a Config object for

# it to get_realm_config.

# Custom mypy types follow:

# These next two types are callbacks, which mypy does not

# support well, because PEP 484 says "using callbacks

# with keyword arguments is not perceived as a common use case."

# CustomFetch = Callable[[TableData, Config, Context], None]

# PostProcessData = Callable[[TableData, Config, Context], None]

# The keys of our MessageOutput variables are normally

# List[Record], but when we write partials, we can get

# lists of integers or a single integer.

# TODO: This could maybe be improved using TypedDict?

# This set contains those database tables that we expect to not be

# included in the export.  This tool does validation to ensure that

# every table in the database is either exported or listed here, to

# ensure we never accidentally fail to export a table.

# These get their own file as analytics data can be quite large and

# would otherwise make realm.json unpleasant to manually inspect

# This data structure lists all the Django DateTimeField fields in the

# data model.  These are converted to floats during the export process

# via floatify_datetime_fields, and back during the import process.

#

# TODO: This data structure could likely eventually be replaced by

# inspecting the corresponding Django models

"""
        In Django 1.11.5, model_to_dict evaluates the QuerySet of
        many-to-many field to give us a list of instances. We require
        a list of primary keys, so we get the primary keys from the
        instances below.
        """
"""As part of the system for doing parallel exports, this runs on one
    batch of Message objects and adds the corresponding UserMessage
    objects. (This is called by the export_usermessage_batch
    management command)."""
# See https://zulip.readthedocs.io/en/latest/subsystems/hotspots.html

# for documentation on this subsystem.

# -*- coding: utf-8 -*-

"""
    This is an expensive function. If you are using it in a loop, it will
    make your code slow.
    """
# ID_MAP is a dictionary that maps table names to dictionaries

# that map old ids to new ids.  We use this in

# re_map_foreign_keys and other places.

#

# We explicity initialize ID_MAP with the tables that support

# id re-mapping.

#

# Code reviewers: give these tables extra scrutiny, as we need to

# make sure to reload related tables AFTER we re-map the ids.

# Client is a table shared by multiple realms, so in order to

# correctly import multiple realms into the same server, we need to

# check if a Client object already exists, and so we need to support

# remap all Client IDs to the values in the new DB.

# Importing data suffers from a difficult ordering problem because of

# models that reference each other circularly.  Here is a correct order.

#

# * Client [no deps]

# * Realm [-notifications_stream]

# * Stream [only depends on realm]

# * Realm's notifications_stream

# * Now can do all realm_tables

# * UserProfile, in order by ID to avoid bot loop issues

# * Huddle

# * Recipient

# * Subscription

# * Message

# * UserMessage

#

# Because the Python object => JSON conversion process is not fully

# faithful, we have to use a set of fixers (e.g. on DateTime objects

# and Foreign Keys) to do the import correctly.

# create_users and do_import_system_bots differ from their equivalent in

# zerver/management/commands/initialize_voyager_db.py because here we check if the bots

# don't already exist and only then create a user for these bots.

"""
    Because the URLs for uploaded files encode the realm ID of the
    organization being imported (which is only determined at import
    time), we need to rewrite the URLs of links to uploaded files
    during the import process.
    """
"""
    When the export data doesn't contain the table `zerver_realmauditlog`,
    this function creates RealmAuditLog objects for `subscription_created`
    type event for all the existing Stream subscriptions.

    This is needed for all the export tools which do not include the
    table `zerver_realmauditlog` (Slack, Gitter, etc.) because the appropriate
    data about when a user was subscribed is not exported by the third-party
    service.
    """
"""
    The tokens in the services are created by 'generate_api_key'.
    As the tokens are unique, they should be re-created for the imports.
    """
"""
    Build new huddle hashes with the updated ids of the users
    """
"""
    Extract the IDs of the user_profiles involved in a huddle from the subscription object
    This helps to generate a unique huddle hash from the updated user_profile ids
    """
"""
    In CustomProfileField with 'field_type' like 'USER', the IDs need to be
    re-mapped.
    """
"""
    This function sets the rendered_content of all the messages
    after the messages have been imported from a non-Zulip platform.
    """
"""
    Returns the ids present in the current table
    """
"""
    Increases the sequence number for a given table by the amount of objects being
    imported into that table. Hence, this gives a reserved range of ids to import the
    converted slack objects into the tables.
    """
"""
    This is a wrapper function for all the realm data tables
    and only avatar and attachment records need to be passed through the internal function
    because of the difference in data format (TableData corresponding to realm data tables
    and List[Record] corresponding to the avatar and attachment records)
    """
"""
    We need to assign new ids to rows during the import/export
    process.

    The tricky part is making sure that foreign key references
    are in sync with the new ids, and this wrapper function does
    the re-mapping only for ManyToMany fields.
    """
"""
    This is an internal function for tables with ManyToMany fields,
    which takes the old ID list of the ManyToMany relation and returns the
    new updated ID list.
    """
"""Used to fixup the authentication_methods bitfield to be a string"""
"""E.g. (RealmDomain -> 'zerver_realmdomain')"""
"""Given an email address, returns the initial password for that account, as
       created by populate_db."""
"""This module declares all of the (documented) integrations available
in the Zulip server.  The Integration class is used as part of
generating the documentation on the /integrations page, while the
WebhookIntegration class is also used to generate the URLs in
`zproject/urls.py` for webhook integrations.

To add a new non-webhook integration, add code to the INTEGRATIONS
dictionary below.

To add a new webhook integration, declare a WebhookIntegration in the
WEBHOOK_INTEGRATIONS list below (it will be automatically added to
INTEGRATIONS).

To add a new integration category, add to the CATEGORIES dict.

Over time, we expect this registry to grow additional convenience
features for writing and configuring integrations efficiently.
"""
"""
    We need this class to don't creating url object for git integrations.
    We want to have one generic url with dispatch function for github service and github webhook.
    """
# Taken from

# https://github.com/simplejson/simplejson/blob/8edc82afcf6f7512b05fba32baa536fe756bd273/simplejson/encoder.py#L378-L402

# License: MIT

"""An encoder that produces JSON safe to embed in HTML.
    To embed JSON content in, say, a script tag on a web page, the
    characters &, < and > should be escaped. They cannot be escaped
    with the usual entities (e.g. &amp;) because they are not expanded
    within <script> tags.
    """
# System documented in https://zulip.readthedocs.io/en/latest/subsystems/logging.html

# Adapted http://djangosnippets.org/snippets/2242/ by user s29 (October 25, 2010)

"""Prevents Django's 'Not Found' warnings from being logged for common
    404 errors that don't reflect a problem in Zulip.  The overall
    result is to keep the Zulip error logs cleaner than they would
    otherwise be.

    Assumes that its input is a django.request log record.
    """
"""Note: `filename` should be declared in zproject/settings.py in ZULIP_PATHS."""
# Library code for use in management commands

"""The numeric or string ID (subdomain) of the Zulip organization to modify.
You can use the command list_realms to find ID of the realms in this server."""
"""Returns a Zulip Client object to be used for things done in management commands"""
# Match multi-word string between @** ** or match any one-word

# sequences after @

# We won't try to fetch more unread message IDs from the database than

# this limit.  The limit is super high, in large part because it means

# client-side code mostly doesn't need to think about the case that a

# user has more older unread messages that were cut off.

"""Given a iterable of messages and reactions stitch reactions
    into messages.
    """
"""You can access a message by ID in our APIs that either:
    (1) You received or have previously accessed via starring
        (aka have a UserMessage row for).
    (2) Was sent to a public stream in your realm.

    We produce consistent, boring error messages to avoid leaking any
    information from a security perspective.
    """
"""Return HTML for given markdown. Bugdown may add properties to the
    message object such as `mentions_user_ids`, `mentions_user_group_ids`, and
    `mentions_wildcard`.  These are only on this Django object and are not
    saved in the database.
    """
# Simple one-time-pad library, to be used for encrypting Zulip API

# keys when sending them to the mobile apps via new standard mobile

# authentication flow.  This encryption is used to protect against

# credential-stealing attacks where a malicious app registers the

# zulip:// URL on a device, which might otherwise allow it to hijack a

# user's API key.

#

# The decryption logic here isn't actually used by the flow; we just

# have it here as part of testing the overall library.

"""Given two hex strings of equal length, return a hex string with
    the bitwise xor of the two hex strings."""
"""Given an ascii string, encode it as a hex string"""
"""Given a hex array, decode it back to a string"""
# Most of this list was curated from the following sources:

# http://wiki.dwscoalition.org/notes/List_of_reserved_subdomains (license: CC-BY-SA 3.0)

# http://stackoverflow.com/questions/11868191/which-saas-subdomains-to-block (license: CC-BY-SA 2.5)

"""Changes to this function should come with corresponding changes to
    BuildNarrowFilterTest."""
"""Create this realm's internal bots.

    This function is idempotent; it does nothing for a bot that
    already exists.
    """
"""This checks if there is any realm internal bot missing.

    If that is the case, it creates the missing realm internal bots.
    """
# Set of helper functions to manipulate the OpenAPI files that define our REST

# API's specification.

# A list of exceptions we allow when running validate_against_openapi_schema.

# The validator will ignore these keys when they appear in the "content"

# passed.

"""Reload the OpenAPI file if it has been modified after the last time
        it was read, and then return the parsed data.
        """
"""Fetch a fixture from the full spec object.
    """
"""Compare a "content" dict with the defined schema for a specific method
    in an endpoint.
    """
"""Transform an OpenAPI-like type to a Pyton one.
    https://swagger.io/docs/specification/data-models/data-types
    """
"""
    bot_id is the user_id of the bot sending the response

    message_info is used to address the message and should have these fields:
        type - "stream" or "private"
        display_recipient - like we have in other message events
        topic - see get_topic_from_message_info

    response_data is what the bot wants to send back and has these fields:
        content - raw markdown content for Zulip to render
    """
"""
        The name of the argument is 'event' on purpose. This argument will hide
        the 'event' argument of the request_retry function. Keeping the same name
        results in a smaller diff.
        """
"""
    This decorator should obviously be used only in a dev environment.
    It works best when surrounding a function that you expect to be
    called once.  One strategy is to write a backend test and wrap the
    test case with the profiled decorator.

    You can run a single test case like this:

        # edit zerver/tests/test_external.py and place @profiled above the test case below
        ./tools/test-backend zerver.tests.test_external.RateLimitTests.test_ratelimit_decrease

    Then view the results like this:

        ./tools/show-profile-results test_ratelimit_decrease.profile

    """
# -*- coding: utf-8 -*-

# We store the token as b64, but apns-client wants hex strings

#

# Sending to APNs, for iOS

#

#

# Sending to GCM, for Android

#

#

# Sending to a bouncer

#

#

# Managing device tokens

#

#

# Push notifications in general

#

"""
    Parse GCM options, supplying defaults, and raising an error if invalid.

    The options permitted here form part of the Zulip notification
    bouncer's API.  They are:

    `priority`: Passed through to GCM; see upstream doc linked below.
        Zulip servers should always set this; when unset, we guess a value
        based on the behavior of old server versions.

    Including unrecognized options is an error.

    For details on options' semantics, see this GCM upstream doc:
      https://developers.google.com/cloud-messaging/http-server-ref

    Returns `priority`.
    """
"""
    Send a GCM message to the given devices.

    See https://developers.google.com/cloud-messaging/http-server-ref
    for the GCM upstream API which this talks to.

    data: The JSON object (decoded) to send as the 'data' parameter of
        the GCM message.
    options: Additional options to control the GCM message sent.
        For details, see `parse_gcm_options`.
    """
"""
    Determine what alert string to display based on the missed messages.
    """
"""
    On an iOS notification, this is the first bolded line.
    """
"""
    On an iOS notification, this is the second bolded line.
    """
"""This should be called when a message that had previously had a
    mobile push executed is read.  This triggers a mobile push notifica
    mobile app when the message is read on the server, to remove the
    message from the notification.

    """
"""
    missed_message is the event received by the
    zerver.worker.queue_processors.PushNotificationWorker.consume function.
    """
# This simple queuing library doesn't expose much of the power of

# rabbitmq/pika's queuing system; its purpose is to just provide an

# interface for external files to put things into queues and take them

# out from bots without having to import pika code all over our codebase.

# Patch pika.adapters.tornado_connection.TornadoConnection so that a socket error doesn't

# throw an exception and disconnect the tornado process from the rabbitmq

# queue. Instead, just re-connect as usual

# We using a simple lock to prevent multiple RabbitMQ messages being

# sent to the SimpleQueueClient at the same time; this is a workaround

# for an issue with the pika BlockingConnection where using

# BlockingConnection for multiple queues causes the channel to

# randomly close.

# Implement a rate-limiting scheme inspired by the one described here, but heavily modified

# http://blog.domaintools.com/2013/04/rate-limiting-with-redis/

"""Returns how many API calls in this range this client has, as well as when
       the rate-limit will be reset to 0"""
"""Increases the rate-limit for the specified entity"""
"""While it does actually send the notice, this function has a lot of
    code and comments around error handling for the push notifications
    bouncer.  There are several classes of failures, each with its own
    potential solution:

    * Network errors with requests.request.  We let those happen normally.

    * 500 errors from the push bouncer or other unexpected responses;
      we don't try to parse the response, but do make clear the cause.

    * 400 errors from the push bouncer.  Here there are 2 categories:
      Our server failed to connect to the push bouncer (should throw)
      vs. client-side errors like and invalid token.

    """
# When adding new functions/classes to this file, you need to also add

# their types to request.pyi in this directory (a mypy stubs file that

# we use to ensure mypy does correct type inference with REQ, which it

# can't do by default due to the dynamic nature of REQ).

#

# Because request.pyi exists, the type annotations in this file are

# mostly not processed by mypy.

# Used in conjunction with @has_request_variables, below

# Extracts variables from the request object and passes them as

# named function arguments.  The request object must be the first

# argument to the function.

#

# To use, assign a function parameter a default value that is an

# instance of the REQ class.  That parameter will then be automatically

# populated from the HTTP request.  The request object must be the

# first argument to the decorated function.

#

# This should generally be the innermost (syntactically bottommost)

# decorator applied to a view, since other decorators won't preserve

# the default parameter values used by has_request_variables.

#

# Note that this can't be used in helper functions which are not

# expected to call json_error or json_success, as it uses json_error

# internally when it encounters an error

"""whence: the name of the request variable that should be used
        for this parameter.  Defaults to a request variable of the
        same name as the parameter.

        converter: a function that takes a string and returns a new
        value.  If specified, this will be called on the request
        variable value before passing to the function

        default: a value to be used for the argument if the parameter
        is missing in the request

        validator: similar to converter, but takes an already parsed JSON
        data structure.  If specified, we will parse the JSON request
        variable value before passing to the function

        str_validator: Like validator, but doesn't parse JSON first.

        argument_type: pass 'body' to extract the parsed JSON
        corresponding to the request body

        type: a hint to typing (using mypy) what the type of this parameter is.
        Currently only typically necessary if default=None and the type cannot
        be inferred in another way (eg. via converter).

        aliases: alternate names for the POST var
        """
"""Dispatch to a REST API endpoint.

    Unauthenticated endpoints should not use this, as authentication is verified
    in the following ways:
        * for paths beginning with /api, HTTP Basic auth
        * for paths beginning with /json (used by the web client), the session token

    This calls the function named in kwargs[request.method], if that request
    method is supported, and after wrapping that function to:

        * protect against CSRF (if the user is already authenticated through
          a Django session)
        * authenticate via an API key (otherwise)
        * coerce PUT/PATCH/DELETE into having POST-like semantics for
          retrieving variables

    Any keyword args that are *not* HTTP methods are passed through to the
    target function.

    Never make a urls.py pattern put user input into a variable called GET, POST,
    etc, as that is where we route HTTP verbs to target functions.
    """
"""
        INSERT INTO zerver_archivedattachment_messages (id, archivedattachment_id,
            archivedmessage_id)
        SELECT zerver_attachment_messages.id, zerver_attachment_messages.attachment_id,
            zerver_attachment_messages.message_id
        FROM zerver_attachment_messages
        LEFT JOIN zerver_archivedattachment_messages
            ON zerver_archivedattachment_messages.id = zerver_attachment_messages.id
        WHERE zerver_attachment_messages.message_id in ({message_ids})
            AND  zerver_archivedattachment_messages.id IS NULL
    """
## Logging setup ##

# When changing the arguments to this function, you may need to write a

# migration to change or remove any emails in ScheduledEmail.

"""Unlike most scheduled emails, invitation emails don't have an
    existing user object to key off of, so we filter by address here."""
# Documented in https://zulip.readthedocs.io/en/latest/subsystems/sending-messages.html#soft-deactivation

"""This function takes a soft-deactivated user, and computes and adds
    to the database any UserMessage rows that were not created while
    the user was soft-deactivated.  The end result is that from the
    perspective of the message database, it should be impossible to
    tell that the user was soft-deactivated at all.

    At a high level, the algorithm is as follows:

    * Find all the streams that the user was at any time a subscriber
      of when or after they were soft-deactivated (`recipient_ids`
      below).

    * Find all the messages sent to those streams since the user was
      soft-deactivated.  This will be a superset of the target
      UserMessages we need to create in two ways: (1) some UserMessage
      rows will have already been created in do_send_messages because
      the user had a nonzero set of flags (the fact that we do so in
      do_send_messages simplifies things considerably, since it means
      we don't need to inspect message content to look for things like
      mentions here), and (2) the user might not have been subscribed
      to all of the streams in recipient_ids for the entire time
      window.

    * Correct the list from the previous state by excluding those with
      existing UserMessage rows.

    * Correct the list from the previous state by excluding those
      where the user wasn't subscribed at the time, using the
      RealmAuditLog data to determine exactly when the user was
      subscribed/unsubscribed.

    * Create the UserMessage rows.

    For further documentation, see:

      https://zulip.readthedocs.io/en/latest/subsystems/sending-messages.html#soft-deactivation

    """
# This is a Pool that doesn't close connections.  Therefore it can be used with

# existing Django database connections.

# -*- coding: utf-8 -*-

# Return the amount of Zulip usage for this user between the two

# given dates

# Useful reading is https://zulip.readthedocs.io/en/latest/subsystems/front-end-build-process.html

# Only set allow_realm_admin flag to True when you want to allow realm admin to

# access unsubscribed private stream content.

"""Common function for backend code where the target use attempts to
    access the target stream, returning all the data fetched along the
    way.  If that user does not have permission to access that stream,
    we throw an exception.  A design goal is that the error message is
    the same for streams you can't access and streams that don't exist."""
"""
    It may seem a little silly to have this helper function for unmuting
    topics, but it gets around a linter warning, and it helps to be able
    to review all security-related stuff in one place.

    Our policy for accessing streams when you unmute a topic is that you
    don't necessarily need to have an active subscription or even "legal"
    access to the stream.  Instead, we just verify the stream_id has been
    muted in the past (not here, but in the caller).

    Long term, we'll probably have folks just pass us in the id of the
    MutedTopic row to unmute topics.
    """
"""Determine whether the provided user is allowed to access the
    history of the target stream.  The stream is specified by name.

    This is used by the caller to determine whether this user can get
    historical messages before they joined for a narrowing search.

    Because of the way our search is currently structured,
    we may be passed an invalid stream here.  We return
    False in that situation, and subsequent code will do
    validation and raise the appropriate JsonableError.

    Note that this function should only be used in contexts where
    access_stream is being called elsewhere to confirm that the user
    can actually see this stream.
    """
"""Converts list of dicts to a list of Streams, validating input in the process

    For each stream name, we validate it to ensure it meets our
    requirements for a proper stream name using check_stream_name.

    This function in autocreate mode should be atomic: either an exception will be raised
    during a precheck, or all the streams specified will have been created if applicable.

    @param streams_raw The list of stream dictionaries to process;
      names should already be stripped of whitespace by the caller.
    @param user_profile The user for whom we are retreiving the streams
    @param autocreate Whether we should create streams if they don't already exist
    """
# -*- coding: utf-8 -*-

"""
    We cannot use override_settings to change upload directory because
    because settings.LOCAL_UPLOADS_DIR is used in url pattern and urls
    are compiled only once. Otherwise using a different upload directory
    for conflicting test cases would have provided better performance
    while providing the required isolation.
    """
"""
        We need to urlencode, since Django's function won't do it for us.
        """
"""
        Use this for patch requests that have file uploads or
        that need some sort of multi-part content.  In the future
        Django's test client may become a bit more flexible,
        so we can hopefully eliminate this.  (When you post
        with the Django test client, it deals with MULTIPART_CONTENT
        automatically, but not patch.)
        """
"""
        We simulate hitting an endpoint here, although we
        actually resolve the URL manually and hit the view
        directly.  We have this helper method to allow our
        instrumentation to work for /notify_tornado and
        future similar methods that require doing funny
        things to a request object.
        """
"""
        We need this function to call request.session.save().
        do_two_factor_login doesn't save session; in normal request-response
        cycle this doesn't matter because middleware will save the session
        when it finds it dirty; however,in tests we will have to do that
        explicitly.
        """
"""
        Stage two of the two-step registration process.

        If things are working correctly the account should be fully
        registered after this call.

        You can pass the HTTP_HOST variable for subdomains via kwargs.
        """
"""
        identifier: Can be an email or a remote server uuid.
        """
"""
        Helper function to get the stream names for a user
        """
"""
        Successful POSTs return a 200 and JSON of the form {"result": "success",
        "msg": ""}.
        """
"""
        Invalid POSTs return an error status code and JSON of the form
        {"result": "error", "msg": "reason"}.
        """
"""
    Common for all webhooks tests

    Override below class attributes and run send_and_test_message
    If you create your url in uncommon way you can override build_webhook_url method
    In case that you need modify body or create it without using fixture you can also override get_body method
    """
"""Can be implemented either as returning a dictionary containing the
        post parameters or as string containing the body of the request."""
"""
    Test class for database migrations inspired by this blog post:
       https://www.caktusgroup.com/blog/2016/02/02/writing-unit-tests-django-migrations/
    Documented at https://zulip.readthedocs.io/en/latest/subsystems/schema-migrations.html
    """
# -*- coding: utf-8 -*-

"""
    This function has a side effect of creating a new hash file or
    updating the old hash file.
    """
"""Redirect stdout to /dev/null."""
"""A mock request object where get_host() works.  Useful for testing
    routes that use Zulip's subdomains feature"""
# Each tuple is delay, test_name, slowness_reason

# Monkey-patch database creation to fix unnecessary sleep(1)

"""
    This class has unpythonic function names because base class follows
    this style.
    """
"""
    The class follows the unpythonic style of function names of the
    base class.
    """
"""Replacement for Django's _destroy_test_db that removes the
    unnecessary sleep(1)."""
"""
    When database_id is None, the name of the databases is picked up
    by the database settings.
    """
"""
    This function runs only under parallel mode. It initializes the
    individual processes which are also called workers.
    """
"""
    You can now use _worker_id.
    """
"""
        This function mostly contains the code from
        unittest.TestSuite.run. The need to override this function
        occurred because we use run_test to run the testcase.
        """
"""
    This class allows us to avoid changing the main logic of
    ParallelTestSuite and still make it serializable.
    """
"""Render a TeX string into HTML using KaTeX

    Returns the HTML string, or None if there was some error in the TeX syntax

    Keyword arguments:
    tex -- Text string with the TeX to render
           Don't include delimiters ('$$', '\[ \]', etc.)
    is_inline -- Boolean setting that indicates whether the render should be
                 inline (i.e. for embedding it in text) or not. The latter
                 will show the content centered, and in the "expanded" form
                 (default True)
    """
# -*- coding: utf-8 -*-

# See https://zulip.readthedocs.io/en/latest/subsystems/thumbnailing.html

# Based on http://code.activestate.com/recipes/483752/

# Only use these constants for events.

# This constant is actually embedded into

# the JSON data for message edit history,

# so we'll always need to handle legacy data

# unless we do a pretty tricky migration.

# This constant is pretty closely coupled to the

# database, but it's the JSON field.

# This is used in low-level message functions in

# zerver/lib/message.py, and it's not user facing.

# See zerver/lib/validator.py for more details of Validators,

# including many examples

# This type is specific for zerver.lib.actions.extract_recipients. After

# deciding to support IDs for some of our API, extract_recipients'

# implementation diverged from other converter functions in many ways.

# See zerver/lib/request.pyi to see how this is used.

# These sizes were selected based on looking at the maximum common

# sizes in a library of animated custom emoji, balanced against the

# network cost of very large emoji images.

# Performance Note:

#

# For writing files to S3, the file could either be stored in RAM

# (if it is less than 2.5MiB or so) or an actual temporary file on disk.

#

# Because we set FILE_UPLOAD_MAX_MEMORY_SIZE to 0, only the latter case

# should occur in practice.

#

# This is great, because passing the pseudofile object that Django gives

# you to boto would be a pain.

# To come up with a s3 key we randomly generate a "directory". The

# "file name" is the original filename provided by the user run

# through a sanitization function.

# https://stackoverflow.com/a/6218425

### Common

### S3

### Local

# Common and wrappers

"""
    Sanitizes a value to be safe to store in a Linux filesystem, in
    S3, and in a URL.  So unicode is allowed, but not special
    characters other than ".", "-", and "_".

    This implementation is based on django.utils.text.slugify; it is
    modified by:
    * adding '.' and '_' to the list of allowed characters.
    * preserving the case of the value.
    """
# NOTE: We don't try to absolutely prevent 2 bots from having the same

# name (e.g. you can get there by reactivating a deactivated bot after

# making a new bot with the same name).  This is just a check designed

# to make it unlikely to happen by accident.

# Adds an outgoing webhook or embedded bot service.

# Warning: If you change this parsing, please test using

#   zerver/tests/test_decorators.py

# And extend zerver/tests/fixtures/user_agents_unique with any new test cases

"""^ (?P<name> [^/ ]* [^0-9/(]* )
             (/ (?P<version> [^/ ]* ))?
             ([ /] .*)?
           $"""
"""This function is used in do_events_register code path so this code
    should be performant.  We need to do 2 database queries because
    Django's ORM doesn't properly support the left join between
    UserGroup and UserGroupMembership that we need.
    """
# -*- coding: utf-8 -*-

# Runs the callback with slices of all_list of a given batch_size

"""Transparently either submit metrics to statsd
    or do nothing without erroring out"""
"""Set a gauge value."""
"""
    return a hex digest of `string`.
    """
"""
    Sends a single event to statsd with the desired name and the current timestamp

    This can be used to provide vertical lines in generated graphs,
    for example when doing a prod deploy, bankruptcy request, or
    other one-off events

    Note that to draw this event as a vertical line in graphite
    you can use the drawAsInfinite() command
    """
"""
    Group elements into list of size `group_size` and fill empty cells with
    `filler`. Recipe from https://docs.python.org/3/library/itertools.html
    """
"""
    This function can be used to identify the source of API auth
    request. We can have two types of sources, Remote Zulip Servers
    and UserProfiles.
    """
# Converter functions for use with has_request_variables

"""
    Use this validator if an argument is of a variable type (e.g. processing
    properties that might be strings or booleans).

    `allowed_type_funcs`: the check_* validator functions for the possible data
    types for this variable.
    """
"""
    This function is used to validate the data sent to the server while
    creating/editing choices of the choice field in Organization settings.
    """
"""
    This function is used to validate the value selected by the user against a
    choice field. This is not used to validate admin data.
    """
"""
<table class="table">
  <thead>
    <tr>
      <th>Argument</th>
      <th>Example</th>
      <th>Required</th>
      <th>Description</th>
    </tr>
  </thead>
<tbody>
"""
"""
<tr>
  <td><code>{argument}</code></td>
  <td class="json-api-example"><code>{example}</code></td>
  <td>{required}</td>
  <td>{description}</td>
</tr>
"""
#!/usr/bin/env python3

# Pass the path to your zuliprc file here.

#!/usr/bin/env python

# The user for this zuliprc file must be an organization administrator

"""
#!/usr/bin/env python3

import zulip

# Pass the path to your zuliprc file here.
client = zulip.Client(config_file="~/zuliprc")

"""
"""
#!/usr/bin/env python

import zulip

# The user for this zuliprc file must be an organization administrator
client = zulip.Client(config_file="~/zuliprc-admin")

"""
# Global vars

"""
Fenced Code Extension for Python Markdown
=========================================

This extension adds Fenced Code Blocks to Python-Markdown.

    >>> import markdown
    >>> text = '''
    ... A paragraph before a fenced code block:
    ...
    ... ~~~
    ... Fenced code block
    ... ~~~
    ... '''
    >>> html = markdown.markdown(text, extensions=['fenced_code'])
    >>> print html
    <p>A paragraph before a fenced code block:</p>
    <pre><code>Fenced code block
    </code></pre>

Works with safe_mode also (we check this because we are using the HtmlStash):

    >>> print markdown.markdown(text, extensions=['fenced_code'], safe_mode='replace')
    <p>A paragraph before a fenced code block:</p>
    <pre><code>Fenced code block
    </code></pre>

Include tilde's in a code block and wrap with blank lines:

    >>> text = '''
    ... ~~~~~~~~
    ...
    ... ~~~~
    ... ~~~~~~~~'''
    >>> print markdown.markdown(text, extensions=['fenced_code'])
    <pre><code>
    ~~~~
    </code></pre>

Removes trailing whitespace from code blocks that cause horizontal scrolling
    >>> import markdown
    >>> text = '''
    ... A paragraph before a fenced code block:
    ...
    ... ~~~
    ... Fenced code block    \t\t\t\t\t\t\t
    ... ~~~
    ... '''
    >>> html = markdown.markdown(text, extensions=['fenced_code'])
    >>> print html
    <p>A paragraph before a fenced code block:</p>
    <pre><code>Fenced code block
    </code></pre>

Language tags:

    >>> text = '''
    ... ~~~~{.python}
    ... # Some python code
    ... ~~~~'''
    >>> print markdown.markdown(text, extensions=['fenced_code'])
    <pre><code class="python"># Some python code
    </code></pre>

Copyright 2007-2008 [Waylan Limberg](http://achinghead.com/).

Project website: <http://packages.python.org/Markdown/extensions/fenced_code_blocks.html>
Contact: markdown@freewisdom.org

License: BSD (see ../docs/LICENSE for details)

Dependencies:
* [Python 2.4+](http://python.org)
* [Markdown 2.0+](http://packages.python.org/Markdown/)
* [Pygments (optional)](http://pygments.org)

"""
"""
    # ~~~ or ```
    (?P<fence>
        ^(?:~{3,}|`{3,})
    )

    [ ]* # spaces

    (
        \\{?\\.?
        (?P<lang>
            [a-zA-Z0-9_+-./#]*
        ) # "py" or "javascript"
        \\}?
    ) # language, like ".py" or "{javascript}"
    [ ]* # spaces
    $
    """
""" Add FencedBlockPreprocessor to the Markdown instance. """
""" Match and store Fenced Code Blocks in the HtmlStash. """
""" basic html escaping """
"""
<table>
    <thead>
        <tr>
            <th align="center">Emoticon</th>
            <th align="center">Emoji</th>
        </tr>
    </thead>
    <tbody>
        {body}
    </tbody>
</table>
"""
"""
<tr>
    <td align="center"><code>{emoticon}</code></td>
    <td align="center">
        <img
            src="/static/generated/emoji/images-google-64/{codepoint}.png"
            alt="{name}"
            class="emoji-big">
    </td>
</tr>
"""
""" Add SettingHelpExtension to the Markdown instance. """
# There is a lot of duplicated code between this file and

# help_settings_links.py. So if you're making a change here consider making

# it there as well.

"""
1. From your desktop, click on the **gear**
   (<i class="fa fa-cog"></i>) in the upper right corner.

1. Select %(item)s.
"""
"""
1. From your desktop, click on the **gear**
   (<i class="fa fa-cog"></i>) in the upper right corner.

1. Click **Manage streams**.
"""
""" Add RelativeLinksHelpExtension to the Markdown instance. """
# There is a lot of duplicated code between this file and

# help_relative_links.py. So if you're making a change here consider making

# it there as well.

"""
1. From your desktop, click on the **gear**
   (<i class="fa fa-cog"></i>) in the upper right corner.

1. Select **%(setting_type_name)s**.

1. On the left, click %(setting_reference)s.
"""
""" Add SettingHelpExtension to the Markdown instance. """
"""
    This is a custom implementation of the markdown_include
    extension that checks for include statements and if the included
    macro file does not exist or can't be opened, raises a custom
    JsonableError exception. The rest of the functionality is identical
    to the original markdown_include extension.
    """
# If adding new entries here, also check if you need to update

# tabbed-instructions.js

"""
<div class="code-section {tab_class}" markdown="1">
{nav_bar}
<div class="blocks">
{blocks}
</div>
</div>
"""
"""
<ul class="nav">
{tabs}
</ul>
"""
"""
<li data-language="{data_language}">{name}</li>
"""
"""
<div data-language="{data_language}" markdown="1">
{content}
</div>
"""
# -*- coding: utf-8 -*-

"""{
    "created_at": "Sat Sep 10 22:23:38 +0000 2011",
    "favorite_count": 1,
    "full_text": "@twitter meets @seepicturely at #tcdisrupt cc.@boscomonkey @episod http://t.co/6J2EgYM",
    "hashtags": [
        {
            "text": "tcdisrupt"
        }
    ],
    "id": 112652479837110270,
    "id_str": "112652479837110273",
    "in_reply_to_screen_name": "Twitter",
    "in_reply_to_user_id": 783214,
    "lang": "en",
    "retweet_count": 4,
    "source": "<a href=\\"http://instagram.com\\" rel=\\"nofollow\\">Instagram</a>",
    "urls": [
        {
            "expanded_url": "http://instagr.am/p/MuW67/",
            "url": "http://t.co/6J2EgYM"
        }
    ],
    "user": {
        "created_at": "Mon May 16 20:07:59 +0000 2011",
        "description": "Eoin's photography account. See @mceoin for tweets.",
        "followers_count": 3,
        "id": 299862462,
        "lang": "en",
        "location": "Twitter",
        "name": "Eoin McMillan",
        "profile_background_color": "131516",
        "profile_background_image_url": "http://abs.twimg.com/images/themes/theme14/bg.gif",
        "profile_background_tile": true,
        "profile_image_url": "http://pbs.twimg.com/profile_images/1380912173/Screen_shot_2011-06-03_at_7.35.36_PM_normal.png",
        "profile_link_color": "009999",
        "profile_sidebar_fill_color": "EFEFEF",
        "profile_text_color": "333333",
        "screen_name": "imeoin",
        "statuses_count": 278,
        "url": "http://t.co/p9hKpiGMyN"
    },
    "user_mentions": [
        {
            "id": 783214,
            "name": "Twitter",
            "screen_name": "Twitter"
        },
        {
            "id": 14792670,
            "name": "Bosco So",
            "screen_name": "boscomonkey"
        },
        {
            "id": 819797,
            "name": "Taylor Singletary",
            "screen_name": "episod"
        }
    ]
}"""
"""{
    "created_at": "Sat Sep 10 22:23:38 +0000 2011",
    "favorite_count": 1,
    "full_text": "http://t.co/@foo",
    "hashtags": [
        {
            "text": "tcdisrupt"
        }
    ],
    "id": 112652479837110270,
    "id_str": "112652479837110273",
    "in_reply_to_screen_name": "Twitter",
    "in_reply_to_user_id": 783214,
    "lang": "en",
    "retweet_count": 4,
    "source": "<a href=\\"http://instagram.com\\" rel=\\"nofollow\\">Instagram</a>",
    "urls": [
      {
        "expanded_url": "http://foo.com",
        "url": "http://t.co/@foo"
      }
    ],
    "user": {
        "created_at": "Mon May 16 20:07:59 +0000 2011",
        "description": "Eoin's photography account. See @mceoin for tweets.",
        "followers_count": 3,
        "id": 299862462,
        "lang": "en",
        "location": "Twitter",
        "name": "Eoin McMillan",
        "profile_background_color": "131516",
        "profile_background_image_url": "http://abs.twimg.com/images/themes/theme14/bg.gif",
        "profile_background_tile": true,
        "profile_image_url": "http://pbs.twimg.com/profile_images/1380912173/Screen_shot_2011-06-03_at_7.35.36_PM_normal.png",
        "profile_link_color": "009999",
        "profile_sidebar_fill_color": "EFEFEF",
        "profile_text_color": "333333",
        "screen_name": "imeoin",
        "statuses_count": 278,
        "url": "http://t.co/p9hKpiGMyN"
    },
    "user_mentions": [
        {
            "id": 783214,
            "name": "Foo",
            "screen_name": "foo"
        }
    ]
}"""
"""{
    "created_at": "Sat Sep 10 22:23:38 +0000 2011",
    "favorite_count": 1,
    "full_text": "http://t.co/xo7pAhK6n3",
    "id": 112652479837110270,
    "id_str": "112652479837110273",
    "in_reply_to_screen_name": "Twitter",
    "in_reply_to_user_id": 783214,
    "lang": "en",
    "media": [
      {
        "display_url": "pic.twitter.com/xo7pAhK6n3",
        "expanded_url": "http://twitter.com/NEVNBoston/status/421654515616849920/photo/1",
        "id": 421654515495211010,
        "media_url": "http://pbs.twimg.com/media/BdoEjD4IEAIq86Z.jpg",
        "media_url_https": "https://pbs.twimg.com/media/BdoEjD4IEAIq86Z.jpg",
        "sizes": {"large": {"h": 700, "resize": "fit", "w": 1024},
                   "medium": {"h": 410, "resize": "fit", "w": 599},
                   "small": {"h": 232, "resize": "fit", "w": 340},
                   "thumb": {"h": 150, "resize": "crop", "w": 150}},
        "type": "photo",
        "url": "http://t.co/xo7pAhK6n3"}
    ],
    "retweet_count": 4,
    "source": "<a href=\\"http://instagram.com\\" rel=\\"nofollow\\">Instagram</a>",
    "user": {
        "created_at": "Mon May 16 20:07:59 +0000 2011",
        "description": "Eoin's photography account. See @mceoin for tweets.",
        "followers_count": 3,
        "id": 299862462,
        "lang": "en",
        "location": "Twitter",
        "name": "Eoin McMillan",
        "profile_background_color": "131516",
        "profile_background_image_url": "http://abs.twimg.com/images/themes/theme14/bg.gif",
        "profile_background_tile": true,
        "profile_image_url": "http://pbs.twimg.com/profile_images/1380912173/Screen_shot_2011-06-03_at_7.35.36_PM_normal.png",
        "profile_link_color": "009999",
        "profile_sidebar_fill_color": "EFEFEF",
        "profile_text_color": "333333",
        "screen_name": "imeoin",
        "statuses_count": 278,
        "url": "http://t.co/p9hKpiGMyN"
    },
    "user_mentions": [
        {
            "id": 783214,
            "name": "Foo",
            "screen_name": "foo"
        }
    ]
}"""
"""{
    "created_at": "Sat Sep 10 22:23:38 +0000 2011",
    "favorite_count": 1,
    "full_text": "Zulip is 💯% open-source!",
    "hashtags": [
        {
            "text": "tcdisrupt"
        }
    ],
    "id": 112652479837110270,
    "id_str": "112652479837110273",
    "in_reply_to_screen_name": "Twitter",
    "in_reply_to_user_id": 783214,
    "lang": "en",
    "retweet_count": 4,
    "source": "<a href=\\"http://instagram.com\\" rel=\\"nofollow\\">Instagram</a>",
    "user": {
        "created_at": "Mon May 16 20:07:59 +0000 2011",
        "description": "Eoin's photography account. See @mceoin for tweets.",
        "followers_count": 3,
        "id": 299862462,
        "lang": "en",
        "location": "Twitter",
        "name": "Eoin McMillan",
        "profile_background_color": "131516",
        "profile_background_image_url": "http://abs.twimg.com/images/themes/theme14/bg.gif",
        "profile_background_tile": true,
        "profile_image_url": "http://pbs.twimg.com/profile_images/1380912173/Screen_shot_2011-06-03_at_7.35.36_PM_normal.png",
        "profile_link_color": "009999",
        "profile_sidebar_fill_color": "EFEFEF",
        "profile_text_color": "333333",
        "screen_name": "imeoin",
        "statuses_count": 278,
        "url": "http://t.co/p9hKpiGMyN"
    },
    "user_mentions": [
        {
            "id": 783214,
            "name": "Twitter",
            "screen_name": "Twitter"
        },
        {
            "id": 14792670,
            "name": "Bosco So",
            "screen_name": "boscomonkey"
        },
        {
            "id": 819797,
            "name": "Taylor Singletary",
            "screen_name": "episod"
        }
    ]
}"""
# Zulip's main markdown implementation.  See docs/subsystems/markdown.md for

# detailed documentation on our markdown syntax.

# Format version of the bugdown rendering; stored along with rendered

# messages so that we can efficiently determine what needs to be re-rendered

# height is not actually used

# All of our emojis(non ZWJ sequences) belong to one of these unicode blocks:

# \U0001f100-\U0001f1ff - Enclosed Alphanumeric Supplement

# \U0001f200-\U0001f2ff - Enclosed Ideographic Supplement

# \U0001f300-\U0001f5ff - Miscellaneous Symbols and Pictographs

# \U0001f600-\U0001f64f - Emoticons (Emoji)

# \U0001f680-\U0001f6ff - Transport and Map Symbols

# \U0001f900-\U0001f9ff - Supplemental Symbols and Pictographs

# \u2000-\u206f         - General Punctuation

# \u2300-\u23ff         - Miscellaneous Technical

# \u2400-\u243f         - Control Pictures

# \u2440-\u245f         - Optical Character Recognition

# \u2460-\u24ff         - Enclosed Alphanumerics

# \u2500-\u257f         - Box Drawing

# \u2580-\u259f         - Block Elements

# \u25a0-\u25ff         - Geometric Shapes

# \u2600-\u26ff         - Miscellaneous Symbols

# \u2700-\u27bf         - Dingbats

# \u2900-\u297f         - Supplemental Arrows-B

# \u2b00-\u2bff         - Miscellaneous Symbols and Arrows

# \u3000-\u303f         - CJK Symbols and Punctuation

# \u3200-\u32ff         - Enclosed CJK Letters and Months

# The equivalent JS regex is \ud83c[\udd00-\udfff]|\ud83d[\udc00-\ude4f]|\ud83d[\ude80-\udeff]|

# \ud83e[\udd00-\uddff]|[\u2000-\u206f]|[\u2300-\u27bf]|[\u2b00-\u2bff]|[\u3000-\u303f]|

# [\u3200-\u32ff]. See below comments for explanation. The JS regex is used by marked.js for

# frontend unicode emoji processing.

# The JS regex \ud83c[\udd00-\udfff]|\ud83d[\udc00-\ude4f] represents U0001f100-\U0001f64f

# The JS regex \ud83d[\ude80-\udeff] represents \U0001f680-\U0001f6ff

# The JS regex \ud83e[\udd00-\uddff] represents \U0001f900-\U0001f9ff

# The JS regex [\u2000-\u206f] represents \u2000-\u206f

# The JS regex [\u2300-\u27bf] represents \u2300-\u27bf

# Similarly other JS regexes can be mapped to the respective unicode blocks.

# For more information, please refer to the following article:

# http://crocodillon.com/blog/parsing-emoji-unicode-in-javascript

# We need the following since upgrade from py-markdown 2.6.11 to 3.0.1

# modifies the link handling significantly. The following is taken from

# py-markdown 2.6.11 markdown/inlinepatterns.py.

# Given a regular expression pattern, linkifies groups that match it

# using the provided format string to construct the URL.

# This prevents realm_filters from running on the content of a

# Markdown link, breaking up the link.  This is a monkey-patch, but it

# might be worth sending a version of this change upstream.

# These are used as keys ("realm_filters_keys") to md_engines and the respective

# realm filter caches

# We want to log Markdown parser failures, but shouldn't log the actual input

# message for privacy reasons.  The compromise is to replace all alphanumeric

# characters with 'x'.

#

# We also use repr() to improve reproducibility, and to escape terminal control

# codes, which can do surprisingly nasty things.

"""
                     (?<![^\s'"\(,:<])            # Start after whitespace or specified chars
                     \#\*\*                       # and after hash sign followed by double asterisks
                         (?P<stream_name>[^\*]+)  # stream name can contain anything
                     \*\*                         # ends by double asterisks
                    """
"""
                    [^\s()\"]*?            # Containing characters that won't end the URL
                    (?: \( %s \)           # and more characters in matched parens
                        [^\s()\"]*?        # followed by more characters
                    )*                     # zero-or-more sets of paired parens
                   """
"""
        (?<![^\s'"\(,:<])    # Start after whitespace or specified chars
                             # (Double-negative lookbehind to allow start-of-string)
        (?P<url>             # Main group
            (?:(?:           # Domain part
                https?://[\w.:@-]+?   # If it has a protocol, anything goes.
               |(?:                   # Or, if not, be more strict to avoid false-positives
                    (?:[\w-]+\.)+     # One or more domain components, separated by dots
                    (?:%s)            # TLDs (filled in via format from tlds-alpha-by-domain.txt)
                )
            )
            (?:/             # A path, beginning with /
                %s           # zero-to-6 sets of paired parens
            )?)              # Path is optional
            | (?:[\w.-]+\@[\w.-]+\.[\w]+) # Email is separate, since it can't have a path
            %s               # File path start with file:///, enable by setting ENABLE_FILE_LINKS=True
            | (?:bitcoin:[13][a-km-zA-HJ-NP-Z1-9]{25,34})  # Bitcoin address pattern, see https://mokagio.github.io/tech-journal/2014/11/21/regex-bitcoin.html
        )
        (?=                            # URL must be followed by (not included in group)
            [!:;\?\),\.\'\"\>]*         # Optional punctuation characters
            (?:\Z|\s)                  # followed by whitespace or end of string
        )
        """
""" If the link points to a local destination we can just switch to that
    instead of opening a new tab. """
""" Return a `<code>` element containing the matching text. """
"""
        Use data from the twitter API to turn links, mentions and media into A
        tags. Also convert unicode emojis to images.

        This works by using the urls, user_mentions and media data from
        the twitter API and searching for unicode emojis in the text using
        `unicode_emoji_regex`.

        The first step is finding the locations of the URLs, mentions, media and
        emoji in the text. For each match we build a dictionary with type, the start
        location, end location, the URL to link to, and the text(codepoint and title
        in case of emojis) to be used in the link(image in case of emojis).

        Next we sort the matches by start location. And for each we add the
        text from the end of the last link to the start of the current link to
        the output. The text needs to added to the text attribute of the first
        node (the P tag) or the tail the last link created.

        Finally we add any remaining text to the last node.
        """
"""
            Helper to set the text or the tail of the current_node
            """
""" Translates emoticons like `:)` into emoji like `:smile:`. """
"""
    A pattern that allows including in-app modal links in messages.
    """
"""Extract the filename if a URL is an uploaded file, or return the original URL"""
"""Set certain attributes we want on every link."""
"""
    Sanitize a url against xss attacks.
    See the docstring on markdown.inlinepatterns.LinkPattern.sanitize_url.
    """
""" Process unordered list blocks.

        Based on markdown.blockprocessors.UListProcessor, but does not accept
        '+' or '-' as a bullet character."""
""" Process unordered list blocks.

        Based on markdown.blockprocessors.ListIndentProcessor, but with 2-space indent
    """
""" Process BlockQuotes.

        Based on markdown.blockprocessors.BlockQuoteProcessor, but with 2-space indent
    """
""" Allows unordered list blocks that come directly after a
        paragraph to be rendered as an unordered list

        Detects paragraphs that have a matching list item that comes
        directly after a line of text, and inserts a newline between
        to satisfy Markdown"""
""" Insert a newline between a paragraph and ulist if missing """
""" Finds a sequence of lines numbered by the same number"""
""" Augment a realm filter so it only matches after start-of-string,
    whitespace, or opening delimiters, won't match if there are word
    characters directly after, and saves what was matched as "name". """
"""(?<![^\s'"\(,:<])(?P<name>"""
""" Applied a given realm filter to the input """
""" Return a setting for the given key or an empty string. """
"""We use this unusual logging approach to log the bugdown error, in
    order to prevent AdminNotifyHandler from sending the santized
    original markdown formatting into another Zulip message, which
    could cause an infinite exception loop."""
"""
        Returns the user IDs that might have been mentioned by this
        content.  Note that because this data structure has not parsed
        the message and does not know about escaping/code blocks, this
        will overestimate the list of user ids.
        """
"""Convert Markdown to HTML, with Zulip-specific settings and hacks."""
# Based on django.core.validators.URLValidator, with ftp support removed.

"""
        Finding a first image after the h1 header.
        Presumably it will be the main image.
        """
# Django prefixes all custom HTTP headers with `HTTP_`

"""
Hi there!  Your bot {bot_name} just sent an HTTP request to {request_path} that
is missing the HTTP {header_name} header.  Because this header is how
{integration_name} indicates the event type, this usually indicates a configuration
issue, where you either entered the URL for a different integration, or are running
an older version of the third-party service that doesn't provide that header.
Contact {support_email} if you need help debugging!
"""
"""
Hi there! It looks like you tried to setup the Zulip {webhook_name} integration,
but didn't correctly configure the webhook to send data in the JSON format
that this integration expects!
"""
""" {committers_details}.

{commits_data}
"""
"""

{commits_data}
"""
"""{user_name} {action} tag {tag}"""
"""Add users to a MailChimp mailing list."""
"""Add some or all users in a realm to a set of streams."""
"""Bankrupt one or many users."""
"""Change the names for many users."""
"""Change the email address for a user."""
"""Checks your Zulip Voyager Django configuration for issues."""
"""Checks redis to make sure our rate limiting system hasn't grown a bug
    and left redis with a bunch of data

    Usage: ./manage.py [--trim] check_redis"""
"""Convert the Gitter data into Zulip data format."""
"""Convert the Hipchat data into Zulip data format."""
"""Convert the Slack data into Zulip data format."""
"""
Create default stream groups which the users can choose during sign up.

./manage.py create_default_stream_groups -s gsoc-1,gsoc-2,gsoc-3 -d "Google summer of code"  -r zulip
"""
"""Create concurrent indexes for large tables."""
"""\
Create realm internal bots if absent, in all realms.

These are normally created when the realm is, so this should be a no-op
except when upgrading to a version that adds a new realm internal bot.
"""
"""Create a stream, and subscribe all active users (excluding bots).

This should be used for TESTING only, unless you understand the limitations of
the command."""
"""Create the specified user with a default initial password.

Set tos_version=None, so that the user needs to do a ToS flow on login.

Omit both <email> and <full name> for interactive user creation.
"""
"""You must confirm that this user has accepted the
Terms of Service by passing --this-user-has-accepted-the-tos."""
"""Either specify an email and full name as two
parameters, or specify no parameters for interactive user creation."""
"""Script to deactivate a realm."""
"""Remove unclaimed attachments from storage older than a supplied
              numerical value indicating the limit of how old the attachment can be.
              One week is taken as the default value."""
## Setup ##

"""\
Deliver email messages that have been queued by various things
(at this time invitation reminders and day1/day2 followup emails).

This management command is run via supervisor.  Do not run on multiple
machines, as you may encounter multiple sends in a specific race
condition.  (Alternatively, you can set `EMAIL_DELIVERER_DISABLED=True`
on all but one machine to make the command have no effect.)
"""
"""Deliver emails queued by various parts of Zulip
(either for immediate sending or sending at a specified time).

Run this command under supervisor. This is for SMTP email delivery.

Usage: ./manage.py deliver_email
"""
## Setup ##

"""Deliver scheduled messages from the ScheduledMessage table.
Run this command under supervisor.

This management command is run via supervisor.  Do not run on multiple
machines, as you may encounter multiple sends in a specific race
condition.  (Alternatively, you can set `EMAIL_DELIVERER_DISABLED=True`
on all but one machine to make the command have no effect.)

Usage: ./manage.py deliver_scheduled_messages
"""
## Setup ##

"""
Forward messages sent to the configured email gateway to Zulip.

For zulip.com, messages to that address go to the Inbox of emailgateway@zulip.com.
Zulip voyager configurations will differ.

Messages meant for Zulip have a special recipient form of

    <stream name>+<regenerable stream token>@streams.zulip.com

This pattern is configurable via the EMAIL_GATEWAY_PATTERN settings.py
variable.

Run this in a cronjob every N minutes if you have configured Zulip to poll
an external IMAP mailbox for messages. The script will then connect to
your IMAP server and batch-process all messages.

We extract and validate the target stream from information in the
recipient address and retrieve, forward, and archive the message.

"""
## Logging setup ##

"""Enqueue digest emails for users that haven't checked the app
in a while.
"""
"""Read JSON lines from a file and enqueue them to a worker queue.

Each line in the file should either be a JSON payload or two tab-separated
fields, the second of which is a JSON payload.  (The latter is to accommodate
the format of error files written by queue workers that catch exceptions--their
first field is a timestamp that we ignore.)

You can use "-" to represent stdin.
"""
"""Exports all data from a Zulip realm

    This command exports all significant data from a Zulip realm.  The
    result can be imported using the `./manage.py import` command.

    Things that are exported:
    * All user-accessible data in the Zulip database (Messages,
      Streams, UserMessages, RealmEmoji, etc.)
    * Copies of all uploaded files and avatar images along with
      metadata needed to restore them even in the ab

    Things that are not exported:
    * Confirmation and PreregistrationUser (transient tables)
    * Sessions (everyone will need to login again post-export)
    * Users' passwords and API keys (users will need to use SSO or reset password)
    * Mobile tokens for APNS/GCM (users will need to reconnect their mobile devices)
    * ScheduledEmail (Not relevant on a new server)
    * RemoteZulipServer (Unlikely to be migrated)
    * third_party_api_results cache (this means rerending all old
      messages could be expensive)

    Things that will break as a result of the export:
    * Passwords will not be transferred.  They will all need to go
      through the password reset flow to obtain a new password (unless
      they intend to only use e.g. Google Auth).
    * Users will need to logout and re-login to the Zulip desktop and
      mobile apps.  The apps now all have an option on the login page
      where you can specify which Zulip server to use; your users
      should enter <domain name>.
    * All bots will stop working since they will be pointing to the
      wrong server URL, and all users' API keys have been rotated as
      part of the migration.  So to re-enable your integrations, you
      will need to direct your integrations at the new server.
      Usually this means updating the URL and the bots' API keys.  You
      can see a list of all the bots that have been configured for
      your realm on the `/#organization` page, and use that list to
      make sure you migrate them all.

    The proper procedure for using this to export a realm is as follows:

    * Use `./manage.py deactivate_realm` to deactivate the realm, so
      nothing happens in the realm being exported during the export
      process.

    * Use `./manage.py export` to export the realm, producing a data
      tarball.

    * Transfer the tarball to the new server and unpack it.

    * Use `./manage.py import` to import the realm

    * Use `./manage.py reactivate_realm` to reactivate the realm, so
      users can login again.

    * Inform the users about the things broken above.

    We recommend testing by exporting without having deactivated the
    realm first, to make sure you have the procedure right and
    minimize downtime.

    Performance: In one test, the tool exported a realm with hundreds
    of users and ~1M messages of history with --threads=1 in about 3
    hours of serial runtime (goes down to ~50m with --threads=6 on a
    machine with 8 CPUs).  Importing that same data set took about 30
    minutes.  But this will vary a lot depending on the average number
    of recipients of messages in the realm, hardware, etc."""
"""Exports message data from a Zulip user

    This command exports the message history for a single Zulip user.

    Note that this only exports the user's message history and
    realm-public metadata needed to understand it; it does nothing
    with (for example) any bots owned by the user."""
"""UserMessage fetching helper for export.py"""
"""Fix problems related to unread counts."""
"""
    Outputs a randomly generated, 1-time-use link for Organization creation.
    Whoever visits the link can create a new organization on this server, regardless of whether
    settings.OPEN_REALM_CREATION is enabled. The link would expire automatically after
    settings.REALM_CREATION_LINK_VALIDITY_DAYS.

    Usage: ./manage.py generate_realm_creation_link """
# -*- coding: utf-8 -*-

"""Import extracted Zulip database dump directories into a fresh Zulip instance.

This command should be used only on a newly created, empty Zulip instance to
import a database dump from one or more JSON files."""
"""Give an existing user administrative permissions over their (own) Realm.

ONLY perform this on customer request from an authorized person.
"""
"""List realms in the server and it's configuration settings(optional).

Usage examples:

./manage.py list_realms
./manage.py list_realms --all"""
"""
The contents of this file are taken from
https://github.com/niwinz/django-jinja/blob/master/django_jinja/management/commands/makemessages.py

Jinja2's i18n functionality is not exactly the same as Django's.
In particular, the tags names and their syntax are different:

  1. The Django ``trans`` tag is replaced by a _() global.
  2. The Django ``blocktrans`` tag is called ``trans``.

(1) isn't an issue, since the whole ``makemessages`` process is based on
converting the template tags to ``_()`` calls. However, (2) means that
those Jinja2 ``trans`` tags will not be picked up by Django's
``makemessages`` command.

There aren't any nice solutions here. While Jinja2's i18n extension does
come with extraction capabilities built in, the code behind ``makemessages``
unfortunately isn't extensible, so we can:

  * Duplicate the command + code behind it.
  * Offer a separate command for Jinja2 extraction.
  * Try to get Django to offer hooks into makemessages().
  * Monkey-patch.

We are currently doing that last thing. It turns out there we are lucky
for once: It's simply a matter of extending two regular expressions.
Credit for the approach goes to:
http://stackoverflow.com/questions/2090717

"""
"""^-?\s*endtrans\s*-?$"""
"""^-?\s*trans(?:\s+(?!'|")(?=.*?=.*?)|\s*-?$)"""
"""^-?\s*pluralize(?:\s+.+|-?$)"""
"""_\(((?:".*?")|(?:'.*?')).*\)"""
"""
        Missing strings are removed, new strings are added and already
        translated strings are not touched.
        """
"""Merge two streams."""
"""
Shows backlog count of ScheduledEmail
"""
"""Shows backlog count of ScheduledEmail
(The number of currently overdue (by at least a minute) email jobs)

This is run as part of the nagios health check for the deliver_email command.

Usage: ./manage.py print_email_delivery_backlog
"""
"""
            This process is watched by Django's autoreload, so exiting
            with status code 3 will cause this process to restart.
            """
"""Manually block or unblock a user from accessing the API"""
"""Script to reactivate a deactivated realm."""
"""Manage domains for the specified realm"""
"""Create a link filter rule for the specified realm.

NOTE: Regexes must be simple enough that they can be easily translated to JavaScript
      RegExp syntax. In addition to JS-compatible syntax, the following features are available:

      * Named groups will be converted to numbered groups automatically
      * Inline-regex flags will be stripped, and where possible translated to RegExp-wide flags

Example: ./manage.py realm_filters --realm=zulip --op=add '#(?P<id>[0-9]{2,8})' \
    'https://support.example.com/ticket/%(id)s'
Example: ./manage.py realm_filters --realm=zulip --op=remove '#(?P<id>[0-9]{2,8})'
Example: ./manage.py realm_filters --realm=zulip --op=show
"""
"""Register a remote Zulip server for push notifications."""
"""Remove some or all users in a realm from a stream."""
"""Change the stream name for a realm."""
# We must call zerver.tornado.ioloop_logging.instrument_tornado_ioloop

# before we import anything else from our project in order for our

# Tornado load logging to work; otherwise we might accidentally import

# zerver.lib.queue (which will instantiate the Tornado ioloop) before

# this.

"""Script to scrub a deactivated realm."""
"""Send email to specified email address."""
"""Sends one-use only links for resetting password to target users

        """
"""Sends realm reactivation email to admins"""
"""Send some stats to statsd."""
# This command loads an email from a specified file and sends it

# to the email mirror. Simple emails can be passed in a JSON file,

# Look at zerver/tests/fixtures/email/1.json for an example of how

# it should look. You can also pass a file which has the raw email,

# for example by writing an email.message.Message type object

# to a file using as_string() or as_bytes() methods, or copy-pasting

# the content of "Show original" on an email in Gmail.

# See zerver/tests/fixtures/email/1.txt for a very simple example,

# but anything that the message_from_binary_file function

# from the email library can parse should work.

# Value of the TO: header doesn't matter, as it is overriden

# by the command in order for the email to be sent to the correct stream.

"""
Send specified email from a fixture file to the email mirror
Example:
./manage.py send_to_email_mirror --fixture=zerver/tests/fixtures/emails/filename

"""
"""
Create webhook message based on given fixture
Example:
./manage.py send_webhook_fixture_message \
    [--realm=zulip] \
    --fixture=zerver/webhooks/integration/fixtures/name.json \
    '--url=/api/v1/external/integration?stream=stream_name&api_key=api_key'

To pass custom headers along with the webhook message use the --custom-headers
command line option.
Example:
    --custom-headers='{"X-Custom-Header": "value"}'

The format is a JSON dictionary, so make sure that the header names do
not contain any spaces in them and that you use the precise quoting
approach shown above.
"""
"""Sets user message flags. Used internally by actions.py. Marks all
    Expects a comma-delimited list of user message ids via stdin, and an EOF to terminate."""
"""Show the admins in a realm."""
"""Show unread counts for a particular user."""
"""Soft activate/deactivate users. Users are recognised by their emails here."""
## Setup ##

# Run this on a cronjob to pick up on name changes.

"""Transfer uploads to S3 """
"""Turn off digests for a subdomain/string_id or specified set of email addresses."""
# -*- coding: utf-8 -*-

# Generated by Django 1.11.2 on 2017-06-22 10:22

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# We hackishly patch this function in order to revert it to the state

# it had when this migration was first written.  This is a balance

# between copying in a historical version of hundreds of lines of code

# from zerver.lib.upload (which would pretty annoying, but would be a

# pain) and just using the current version, which doesn't work

# since we rearranged the avatars in Zulip 1.6.

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.10.4 on 2016-12-20 07:02

# -*- coding: utf-8 -*-

# Generated by Django 1.10.4 on 2016-12-20 13:45

# -*- coding: utf-8 -*-

# Generated by Django 1.10.4 on 2016-12-29 02:18

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-01-23 17:44

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-01-25 20:55

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-02-11 03:07

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-02-23 05:37

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-02-15 06:18

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-01 06:28

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-02 07:28

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-04 07:33

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-02-27 14:34

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-04 07:40

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-02-27 17:03

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-15 11:43

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-16 12:22

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-19 19:06

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-18 12:38

"""Does nothing"""
# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-21 15:56

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-21 15:58

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-26 01:10

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-13 23:32

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-27 20:00

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-28 00:22

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-31 14:21

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-31 05:51

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-04-17 06:49

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-04-13 22:12

"""Migration 0041 had a bug, where if multiple messages referenced the
    same attachment, rather than creating a single attachment object
    for all of them, we would incorrectly create one for each message.
    This results in exceptions looking up the Attachment object
    corresponding to a file that was used in multiple messages that
    predate migration 0041.

    This migration fixes this by removing the duplicates, moving their
    messages onto a single canonical Attachment object (per path_id).
    """
# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-04-13 22:29

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-04-23 19:51

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-03-09 05:23

"""converts a string to a native string"""
# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-04-27 16:55

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-05-10 05:59

"""Delete any old scheduled jobs, to handle changes in the format of
    that table.  Ideally, we'd translate the jobs, but it's not really
    worth the development effort to save a few invitation reminders
    and day2 followup emails.
    """
# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-05-11 20:27

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-05-02 21:44

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-05-22 14:49

# -*- coding: utf-8 -*-

# Generated by Django 1.11.2 on 2017-06-20 10:31

# -*- coding: utf-8 -*-

# Generated by Django 1.11.2 on 2017-06-26 21:56

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-05-10 05:59

"""Delete any old scheduled jobs, to handle changes in the format of
    send_email. Ideally, we'd translate the jobs, but it's not really
    worth the development effort to save a few invitation reminders
    and day2 followup emails.
    """
# -*- coding: utf-8 -*-

# Generated by Django 1.11.2 on 2017-07-07 08:34

# -*- coding: utf-8 -*-

# Generated by Django 1.11.2 on 2017-07-10 13:53

# -*- coding: utf-8 -*-

# Generated by Django 1.11.2 on 2017-07-07 15:58

# -*- coding: utf-8 -*-

# Generated by Django 1.11.2 on 2017-07-16 08:57

# -*- coding: utf-8 -*-

# Generated by Django 1.11.2 on 2017-07-11 23:41

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.11.2 on 2017-07-22 13:44

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.11.2 on 2017-08-09 04:21

# -*- coding: utf-8 -*-

# Generated by Django 1.11.2 on 2017-06-18 21:26

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.11.4 on 2017-08-27 17:08

# -*- coding: utf-8 -*-

# Generated by Django 1.11.4 on 2017-08-30 00:26

# -*- coding: utf-8 -*-

# Generated by Django 1.11.4 on 2017-08-30 00:26

# -*- coding: utf-8 -*-

# Generated by Django 1.11.4 on 2017-08-31 00:13

# -*- coding: utf-8 -*-

# Generated by Django 1.11.4 on 2017-08-30 00:26

# -*- coding: utf-8 -*-

# Generated by Django 1.11.4 on 2017-09-08 17:52

# -*- coding: utf-8 -*-

# Generated by Django 1.11.4 on 2017-09-08 17:52

# -*- coding: utf-8 -*-

# Generated by Django 1.11.4 on 2017-09-04 22:48

# -*- coding: utf-8 -*-

# Generated by Django 1.11.4 on 2017-08-24 02:39

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.11.5 on 2017-10-08 18:37

# -*- coding: utf-8 -*-

# Generated by Django 1.11.5 on 2017-10-18 16:15

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.11.5 on 2017-10-14 15:12

# -*- coding: utf-8 -*-

# Generated by Django 1.11.5 on 2017-10-19 21:42

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2017-10-30 05:05

# -*- coding: utf-8 -*-

# Generated by Django 1.11.5 on 2017-10-28 11:13

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2017-11-01 08:01

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2017-11-14 19:52

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2017-11-14 19:28

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2017-11-01 19:12

# -*- coding: utf-8 -*-

# Generated by Django 1.11.5 on 2017-10-19 22:01

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2017-11-24 09:10

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2017-11-22 20:45

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2017-11-29 01:38

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2017-11-30 04:58

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2017-11-30 04:58

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2017-12-05 01:08

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2017-12-27 17:55

# change emojiset to text if emoji_alt_code is true.

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2017-11-30 20:05

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-01-03 18:14

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-01-06 09:56

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-01-10 01:11

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-01-12 10:37

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-01-24 20:24

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-01-24 20:24

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-01-21 08:47

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-02-18 07:02

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-02-28 17:38

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-02-19 22:27

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-03-09 18:00

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-03-09 21:21

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2017-11-29 12:33

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-03-05 19:20

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-02-10 02:59

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.11.4 on 2017-09-28 22:56

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-03-29 18:47

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-03-30 17:18

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-04-02 12:42

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-04-03 01:52

"""Fixes UserProfile objects that incorrectly had a bot_owner set"""
# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-06 19:17

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-06 04:10

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-20 19:29

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-10 14:57

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-23 16:37

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-10 04:57

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-24 22:12

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-24 09:10

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-28 20:34

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-28 22:31

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-29 17:24

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-29 17:25

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-08 15:49

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-27 08:03

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-05-12 04:57

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-01-26 21:54

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-05-24 18:45

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-05-08 17:24

# -*- coding: utf-8 -*-

# Generated by Django 1.11.13 on 2018-06-28 01:09

# -*- coding: utf-8 -*-

# Generated by Django 1.11.13 on 2018-07-05 17:57

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.11.13 on 2018-07-26 18:38

# -*- coding: utf-8 -*-

# Generated by Django 1.11.13 on 2018-06-14 13:39

# -*- coding: utf-8 -*-

# Generated by Django 1.11.13 on 2018-07-27 21:47

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-08-01 10:59

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-08-01 23:05

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-08-16 18:10

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-08-15 13:41

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-08-10 21:36

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-08-17 06:06

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-08-22 05:45

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-08-22 09:57

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-08-28 19:01

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-10-10 22:52

# -*- coding: utf-8 -*-

# Generated by Django 1.11.16 on 2018-11-20 04:43

# -*- coding: utf-8 -*-

# Generated by Django 1.11.16 on 2018-11-14 12:15

# -*- coding: utf-8 -*-

# Generated by Django 1.11.16 on 2018-12-06 21:36

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-03-12 03:18

# -*- coding: utf-8 -*-

# Generated by Django 1.11.16 on 2018-12-05 14:50

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-08-16 00:34

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-10-11 00:12

# -*- coding: utf-8 -*-

# Generated by Django 1.11.16 on 2018-12-27 17:09

# -*- coding: utf-8 -*-

# Generated by Django 1.11.16 on 2018-12-17 18:49

# -*- coding: utf-8 -*-

# Generated by Django 1.11.16 on 2018-12-30 10:07

# -*- coding: utf-8 -*-

# Generated by Django 1.11.16 on 2018-12-28 18:00

# -*- coding: utf-8 -*-

# Generated by Django 1.11.18 on 2019-01-19 19:59

# -*- coding: utf-8 -*-

# Generated by Django 1.11.16 on 2019-01-07 11:46

# -*- coding: utf-8 -*-

# Generated by Django 1.11.18 on 2019-01-31 22:33

# -*- coding: utf-8 -*-

# Generated by Django 1.11.18 on 2019-02-02 02:49

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.11.18 on 2019-02-06 21:49

# -*- coding: utf-8 -*-

# Generated by Django 1.11.18 on 2019-01-15 16:07

# -*- coding: utf-8 -*-

# Generated by Django 1.11.18 on 2019-03-03 13:47

# -*- coding: utf-8 -*-

# Generated by Django 1.11.18 on 2019-02-25 12:42

# -*- coding: utf-8 -*-

# Generated by Django 1.11.20 on 2019-03-14 01:11

# -*- coding: utf-8 -*-

# Generated by Django 1.11.20 on 2019-03-17 08:37

# Prevent the automatic substitution of macros in these docs. If

# they contain a macro, it is always used literally for documenting

# the macro system.

# Much of the time, render_markdown_path is called with hashable

# arguments, so this decorator is effective even though it only caches

# the results when called if none of the arguments are unhashable.

"""
    Given a list of values, return a string nicely formatting those values,
    summarizing when you have more than `display_limit`. Eg, for a
    `display_limit` of 3 we get the following possible cases:

    Jessica
    Jessica and Waseem
    Jessica, Waseem, and Tim
    Jessica, Waseem, Tim, and 1 other
    Jessica, Waseem, Tim, and 2 others
    """
"""Given a path to a markdown file, return the rendered html.

    Note that this assumes that any HTML in the markdown file is
    trusted; it is intended to be used for documentation, not user
    data."""
# -*- coding: utf-8 -*-

"""
        Users start out with no alert words.
        """
"""
        add_user_alert_words can add multiple alert words at once.
        """
"""
        Removing alert words works via remove_user_alert_words, even
        for multi-word and non-ascii words.
        """
"""
        We can gather alert words for an entire realm via
        alert_words_in_realm. Alerts added for one user do not impact other
        users.
        """
"""Send a bunch of messages as othello, so Hamlet is notified"""
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

"""This is a base class for testing social-auth backends. Following
    methods can be overrided by subclasses as per the backend:

        registerExtraEndpoints() - If the backend being tested calls some extra
                                   endpoints then they can be added here.

        get_account_data_dict() - Return the data returned by the user info endpoint
                                  according to the respective backend.
    """
"""If the user already exists, signup flow just logs them in"""
"""If the user doesn't exist yet, social auth can be used to register an account"""
"""If the user doesn't exist yet, social auth can be used to register an account"""
"""If `is_signup` is not set then a new account isn't created"""
"""If the user doesn't exist yet in closed realm, give an error"""
"""If the user doesn't exist yet, Google auth can be used to register an account"""
"""If the user doesn't exist yet, Google auth can be used to register an account"""
"""This test verifies the behavior of the redirect_to logic in
        login_or_register_remote_user."""
"""
    JWT uses ZulipDummyBackend.
    """
"""
        Calling POST /json/users/me/subscriptions should successfully add
        streams, and a stream to the
        list of subscriptions and confirm the right number of events
        are generated.
        When 'principals' has a bot, no notification message event or invitation email
        is sent when add_subscriptions_backend is called in the above api call.
        """
"""Deleting a bogus bot will succeed silently."""
"""You cannot deactivate somebody else's bot."""
"""Deleting a bogus bot will succeed silently."""
# -*- coding: utf-8 -*-

"""<a href="http://t.co/@foo" target="_blank" title="http://t.co/@foo">http://foo.com</a>"""
"""Zulip is <span aria-label=\"100\" class="emoji emoji-1f4af" role=\"img\" title="100">:100:</span>% open-source!"""
"""Hello, everyone. Prod deployment has been completed
        And this is a new line
        to test out how markdown convert this into something line ending splitted array
        and this is a new line
        last"""
"""This is to test out alert words work in languages with accented characters too
        bonjour est (énormément) ce a quoi ressemble le français
        et j'espère qu'il n'y n' réglementaire a pas de mots d'alerte dans ce texte français
        """
"""hello how is this possible how are you doing today
        This is to test that the no user_ids who have alrert wourldword is participating
        in sending of the message
        """
"""This is to test a empty alert words i.e. no user has any alert-words set"""
"""The code above will print 10 random values of numbers between 1 and 100.
        The second line, for x in range(10), determines how many values will be printed (when you use
        range(x), the number that you use in place of x will be the amount of values that you'll have
        printed. if you want 20 values, use range(20). use range(5) if you only want 5 values returned,
        etc.). I was talking abou the issue124 on github. Then the third line: print random.randint(1,101) will automatically select a random integer
        between 1 and 100 for you. The process is fairly simple
        """
"""#StreamName requires the stream be spelled with the correct case
        currently.  If we change that in the future, we'll need to change this
        test."""
"""Test the markdown configs for the MIT Zephyr mirroring system;
        verifies almost all inline patterns are disabled, but
        inline_interesting_links is still enabled"""
"""Determines whether we're correctly passing the realm context"""
"""A rendered message with an ultra-long lenght (> 10 * MAX_MESSAGE_LENGTH)
        throws an exception"""
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

"""
user: {email} ({realm})
client: {client_name}
URL: {path_info}
content_type: {content_type}
custom_http_headers:
{custom_headers}
body:

{body}
                """
"""
user: {email} ({realm})
client: {client_name}
URL: {path_info}
content_type: {content_type}
custom_http_headers:
{custom_headers}
body:

{body}
                """
"""
user: {email} ({realm})
client: {client_name}
URL: {path_info}
content_type: {content_type}
custom_http_headers:
{custom_headers}
body:

{body}
                """
"""
        rest_dispatch rejects requests in a deactivated realm, both /json and api

        """
"""
        authenticated_json_view views fail in a deactivated realm

        """
"""
        Using a webhook while in a deactivated realm fails

        """
"""
        Verifies the zulip_login_required decorator blocks deactivated users.
        """
"""
        rest_dispatch rejects requests from deactivated users, both /json and api

        """
"""
        authenticated_json_view views fail with a deactivated user

        """
"""
        logging in fails with an inactive user

        """
"""
        logging in fails with an inactive user

        """
"""
        Deactivated users can't use webhooks

        """
"""Test for our user agent parsing logic, using a large data set."""
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

""" Manual installation which did not execute `tools/provision`
        would not have the `static/generated/github-contributors.json` fixture
        file.
        """
""" We can't check the contributors list since it is rendered client-side """
"""Utility function primarily used in authors page"""
"""Test the !DEVELOPMENT code path of config-error."""
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

"""Reply

        -----Original Message-----

        Quote"""
"""
        <html>
            <body>
                <p>Reply</p>
                <blockquote>

                    <div>
                        On 11-Apr-2011, at 6:54 PM, Bob &lt;bob@example.com&gt; wrote:
                    </div>

                    <div>
                        Quote
                    </div>

                </blockquote>
            </body>
        </html>
        """
"""A mention should take precedence over regular stream messages for email subjects."""
"""A mention should take precedence over regular stream messages for email subjects.

        Each sender who has mentioned a user should appear in the email subject line.
        """
"""Should receive separate emails for each topic within a stream."""
"""(?<=\=['"])/(?=[^<]+>)"""
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# See https://zulip.readthedocs.io/en/latest/subsystems/events-system.html for

# high-level documentation on how this system works.

"""
        Make sure we properly assert failures for recipient types that should not
        get typing... notifications.
        """
"""Test updating each setting in UserProfile.property_types dict."""
"""Tests the logic for when missed-message notifications
    should be triggered, based on user settings"""
"""Tests what arguments missedmessage_hook passes into maybe_enqueue_notifications.
        Combined with the previous test, this ensures that the missedmessage_hook is correct"""
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Splitting this out, since I imagine this will eventually have most of the

# complicated hotspots logic.

# -*- coding: utf-8 -*-

"""
    Tranlations strings should change with locale. URLs should be locale
    aware.
    """
# -*- coding: utf-8 -*-

"""
    Tests for export
    """
"""
    Tests for import_realm
    """
# -*- coding: utf-8 -*-

"""<html>
          <head>
          <meta property="og:title" content="The Rock" />
          <meta property="og:type" content="video.movie" />
          <meta property="og:url" content="http://www.imdb.com/title/tt0117500/" />
          <meta property="og:image" content="http://ia.media-imdb.com/images/rock.jpg" />
          <meta property="og:description" content="The Rock film" />
          </head>
        </html>"""
"""
          <html>
            <head><title>Test title</title></head>
            <body>
                <h1>Main header</h1>
                <p>Description text</p>
            </body>
          </html>
        """
"""
          <html>
            <body>
                <h1>Main header</h1>
                <img src="http://test.com/test.jpg">
                <div>
                    <p>Description text</p>
                </div>
            </body>
          </html>
        """
"""
          <html>
            <body>
                <div>
                    <div>
                        <p>Description text</p>
                    </div>
                </div>
            </body>
          </html>
        """
"""
          <html>
            <head><meta name="description" content="description 123"</head>
            <body></body>
          </html>
        """
"""
          <html>
            <head>
                <title>Test title</title>
                <meta property="og:title" content="The Rock" />
                <meta property="og:type" content="video.movie" />
                <meta property="og:url" content="http://www.imdb.com/title/tt0117500/" />
                <meta property="og:image" content="http://ia.media-imdb.com/images/rock.jpg" />
            </head>
            <body>
                <h1>Main header</h1>
                <p>Description text</p>
            </body>
          </html>
        """
# -*- coding: utf-8 -*-

"""A random exception passes happily through AdminNotifyHandler"""
"""A request with no stack and multi-line report.getMessage() is handled properly"""
"""A normal request is handled properly"""
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

"""
        Make sure `is_private` flag is not leaked to the API.
        """
"""
        Newly created users are auto-subbed to the ability to receive
        personals.
        """
"""
        If you send a personal to yourself, only you see it.
        """
"""
        Send a private message from `sender_email` to `receiver_email` and check
        that only those two parties actually received the message.
        """
"""
        If you send a personal, only you and the recipient see it.
        """
"""
        Sending a PM containing non-ASCII characters succeeds.
        """
"""
        Check that messages sent to a stream reach all subscribers to that stream.
        """
"""
        If you send a message to a stream, everyone subscribed to the stream
        receives the messages.
        """
"""
        Sending a stream message containing non-ASCII characters in the stream
        name, topic, or message body succeeds.
        """
"""
        Sending a message to a stream to which you are subscribed is
        successful.
        """
"""
        Same as above, but for the API view
        """
"""
        Sending a message to a stream (by stream ID) to which you are
        subscribed is successful.
        """
"""
        Sending a message to an announcement_only stream by a realm admin
        successful.
        """
"""
        Sending a message to an announcement_only stream not by a realm
        admin fails.
        """
"""
        Sending messages without a to field should be sent to the default
        stream for the user_profile.
        """
"""
        Sending a message to a nonexistent stream fails.
        """
"""
        Nonexistent stream name with bad characters should be escaped properly.
        """
"""&<"'><non-existent>"""
"""&<"'><non-existent>"""
"""
        Sending a personal message to a valid username is successful.
        """
"""
        Sending a personal message to a valid user ID is successful.
        """
"""
        Sending a personal message to a valid user ID is successful.
        """
"""
        Sending a personal message to yourself plus another user is successful,
        and counts as a message just to that user.
        """
"""
        Sending a personal message to an invalid email returns error JSON.
        """
"""
        Sending a personal message to a deactivated user returns error JSON.
        """
"""
        Sending a message of unknown type returns error JSON.
        """
"""
        Sending a message that is empty or only whitespace should fail
        """
"""
        Sending a message that has empty string topic should fail
        """
"""
        Sending a message without topic should fail
        """
"""
        Messages other than the type of "private" or "stream" are considered as invalid
        """
"""
        Sending private message without recipients should fail
        """
"""
        Sending a mirrored huddle message works
        """
"""
        Sending a mirrored personal message works
        """
"""
        Sending a mirrored personal message to someone else is not allowed.
        """
"""
        Sending two mirrored huddles in the row return the same ID
        """
"""
        A message with null bytes in it is handled.
        """
"""
        A message with mixed whitespace at the end is cleaned up.
        """
"""
        Sending a message longer than the maximum message length succeeds but is
        truncated.
        """
"""
        Sending a message with a topic longer than the maximum topic length
        succeeds, but the topic is truncated.
        """
"""This is also tested by a client test, but here we can verify
        the cache against the database"""
"""This test verifies the accuracy of construction of Zulip's edit
        history data structures."""
"""Test mirror dummy user creation for PM recipients"""
"""Test mirror dummy user creation for sender when sending to stream"""
"""
        You can set a message as starred/un-starred through
        POST /json/messages/flags.
        """
"""
        You can set a message as starred/un-starred through
        POST /json/messages/flags.
        """
"""
        You can set a message as starred/un-starred through
        POST /json/messages/flags.
        """
"""
        New messages aren't starred.
        """
"""We send a PM to a bot's owner if their bot sends a message to
        an unsubscribed stream"""
# -*- coding: utf-8 -*-

# These are tests for Zulip's database migrations.  System documented at:

#   https://zulip.readthedocs.io/en/latest/subsystems/schema-migrations.html

#

# You can also read

#   https://www.caktusgroup.com/blog/2016/02/02/writing-unit-tests-django-migrations/

# to get a tutorial on the framework that inspired this feature.

"""Test runs after the migration, and verifies the data was migrated correctly"""
# -*- coding: utf-8 -*-

"""
        Test old `/json/messages` returns reactions.
        """
"""
        Test old `/json/messages` returns reactions.
        """
"""
        A call to GET /json/messages with valid parameters returns a list of
        messages.
        """
"""
        The client_gravatar flag determines whether we send avatar_url.
        """
"""
        A request for old messages with a narrow by pm-with only returns
        conversations with that user.
        """
"""
        A request for old messages with a narrow by group-pm-with only returns
        group-private conversations with that user.
        """
"""
        A request for old messages with a narrow by stream only returns
        messages for that stream.
        """
"""
        A request for old messages for a user in the mit.edu relam with unicode
        stream name should be correctly escaped in the database query.
        """
"""
        A request for old messages for a user in the mit.edu realm with unicode
        topic name should be correctly escaped in the database query.
        """
"""
        We handle .d grouping for MIT realm personal messages correctly.
        """
"""
        A request for old messages with a narrow by sender only returns
        messages sent by that person.
        """
"""
            UPDATE zerver_message SET
            search_tsvector = to_tsvector('zulip.english_us_search',
            subject || rendered_content)
            """
"""Verify support for searching a stream you're not subscribed to"""
"""
                UPDATE zerver_message SET
                search_pgroonga = escape_html(subject) || ' ' || rendered_content
                """
"""
        Test that specifying an anchor but 0 for num_before and num_after
        returns at most 1 message.
        """
"""
        anchor, num_before, and num_after are all required
        POST parameters for get_messages.
        """
"""
        A call to GET /json/messages requesting more than
        MAX_MESSAGES_PER_FETCH messages returns an error message.
        """
"""
        num_before, num_after, and narrow must all be non-negative
        integers or strings that can be converted to non-negative integers.
        """
"""
        narrow must be a list of string pairs.
        """
"""
        Unrecognized narrow operators are rejected.
        """
"""
        We expect search operands to be strings, not integers.
        """
"""
        If an invalid stream name is requested in get_messages, an error is
        returned.
        """
"""
        If an invalid 'pm-with' is requested in get_messages, an
        error is returned.
        """
"""Older messages may not have rendered_content in the database"""
"""
        Test that our logic related to `use_first_unread_anchor`
        invokes the `message_id = LARGER_THAN_MAX_MESSAGE_ID` hack for
        the `/* get_messages */` query when relevant muting
        is in effect.

        This is a very arcane test on arcane, but very heavily
        field-tested, logic in get_messages_backend().  If
        this test breaks, be absolutely sure you know what you're
        doing.
        """
"""
    Uses django's user_logged_in signal to send emails on new login.

    The receiver handler for this signal is always registered in production,
    development and testing, but emails are only sent based on SEND_LOGIN_EMAILS setting.

    SEND_LOGIN_EMAILS is set to true in default settings.
    It is turned off during testing.
    """
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

"""Make sure that the tools we use to handle our OpenAPI specification
    (located in zerver/lib/openapi.py) work as expected.

    These tools are mostly dedicated to fetching parts of the -already parsed-
    specification, and comparing them to objects returned by our REST API.
    """
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

"""Mostly a test for UserActivityInterval"""
"""Zephyr mirror realms such as MIT never get a list of users"""
"""Zephyr mirror realms find out the status of their mirror bot"""
"""This method is used to carry out the push notification bouncer
        requests using the Django test browser, rather than python-requests.
        """
"""This is a variant of the below test_push_api, but using the full
        push notification bouncer flow
        """
"""This is a variant of the below test_push_api, but using the full
        push notification bouncer flow
        """
"""This is a variant of the below test_push_api, but using the full
        push notification bouncer flow
        """
"""This method is used to carry out the push notification bouncer
        requests using the Django test browser, rather than python-requests.
        """
"""Simulates the race where message is deleted before handlingx push notifications"""
"""Simulates the race where message is missing when handling push notifications"""
"""This simulates a condition that should only be an error if the user is
        not long-term idle; we fake it, though, in the sense that the user should
        not have received the message in the first place"""
"""This simulates a condition that should only be an error if the user is
        not long-term idle; we fake it, though, in the sense that the user should
        not have received the message in the first place"""
"""This test is pretty hacky, and needs to carefully reset the state
        it modifies in order to avoid leaking state that can lead to
        nondeterministic results for other tests.
        """
# This is used for testing LoopQueueProcessingWorker, which

# would run forever if we don't mock time.sleep to abort the

# loop.

"""Tests the retry_send_email_failures decorator to make sure it
        retries sending the email 3 times and then gives up."""
"""Tests the retry logic of signups queue."""
# -*- coding: utf-8 -*-

"""
        Sending reaction without emoji fails
        """
"""
        Sending invalid emoji fails
        """
"""
        Sending deactivated realm emoji fails.
        """
"""
        Reacting with valid emoji succeeds
        """
"""
        Reacting with zulip emoji succeeds
        """
"""
        Reacting with valid emoji on a historical message succeeds
        """
"""
        Reacting with valid realm emoji succeeds
        """
"""
        An emoji name is mapped canonically to emoji code.
        """
"""
        Reacting without a message_id fails
        """
"""
        Reacting to an invalid message id fails
        """
"""
        Reacting to a inaccessible (for instance, private) message fails
        """
"""
        Creating the same reaction twice fails
        """
"""
        Removing a reaction twice fails
        """
"""
        Removes an old existing reaction but the name of emoji got changed during
        various emoji infra changes.
        """
"""
        Removes an old existing reaction but the realm emoji used there has been deactivated.
        """
"""
        Recipients of the message receive the reaction event
        and event contains relevant data
        """
"""
        Recipients of the message receive the reaction event
        and event contains relevant data
        """
"""
        Reacting with valid emoji on a historical message succeeds.
        """
"""
        Recipients of the message receive the reaction event
        and event contains relevant data
        """
"""
        Recipients of the message receive the reaction event
        and event contains relevant data
        """
"""The main complicated thing about setting realm names is fighting the
        cache, and we start by populating the cache for Hamlet, and we end
        by checking the cache to ensure that the new value is there."""
"""The main complicated thing about deactivating realm names is
        updating the cache, and we start by populating the cache for
        Hamlet, and we end by checking the cache to ensure that his
        realm appears to be deactivated.  You can make this test fail
        by disabling cache.flush_realm()."""
"""The main complicated thing about changing realm subdomains is
        updating the cache, and we start by populating the cache for
        Hamlet, and we end by checking the cache to ensure that his
        realm appears to be deactivated.  You can make this test fail
        by disabling cache.flush_realm()."""
"""Ensure early exit is working in realm deactivation"""
"""Test updating realm properties.

        If new realm properties have been added to the Realm model but the
        test_values dict below has not been updated, this will raise an
        assertion error.
        """
"""Tests updating the realm property 'allow_message_editing'."""
"""Tests updating the realm property 'allow_message_deleting'."""
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

"""
        Test receiving expired messages retention tool.
    """
"""Some files here ...[zulip.txt](
            http://localhost:9991/user_uploads/1/31/4CBjtTLYZhk66pZrF8hnYGwc/zulip.txt)
            http://localhost:9991/user_uploads/1/31/4CBjtTLYZhk66pZrF8hnYGwc/temp_file.py ....
            Some more.... http://localhost:9991/user_uploads/1/31/4CBjtTLYZhk66pZrF8hnYGwc/abc.py
        """
"""Some files here
            http://localhost:9991/user_uploads/1/31/4CBjtTLYZhk66pZrF8hnYGwc/zulip.txt ...
            http://localhost:9991/user_uploads/1/31/4CBjtTLYZhk66pZrF8hnYGwc/hello.txt ....
            http://localhost:9991/user_uploads/1/31/4CBjtTLYZhk66pZrF8hnYGwc/new.py ....
        """
"""Some files here ...[zulip.txt](
            http://localhost:9991/user_uploads/1/31/4CBjtTLYZhk66pZrF8hnYGwc/zulip.txt)
            http://localhost:9991/user_uploads/1/31/4CBjtTLYZhk66pZrF8hnYGwc/temp_file.py ....
            Some more.... http://localhost:9991/user_uploads/1/31/4CBjtTLYZhk66pZrF8hnYGwc/abc.py ...
            http://localhost:9991/user_uploads/1/31/4CBjtTLYZhk66pZrF8hnYGwc/new.py ....
            http://localhost:9991/user_uploads/1/31/4CBjtTLYZhk66pZrF8hnYGwc/hello.txt ....
        """
# -*- coding: utf-8 -*-

"""Service bots should not get access to mentions if they aren't a
        direct recipient."""
"""
        A call to /json/settings with valid parameters changes the user's
        settings correctly and returns correct values.
        """
"""Test updating each boolean setting in UserProfile property_types"""
"""
        We need to supply at least one non-empty parameter
        to this API, or it should fail.  (Eventually, we should
        probably use a patch interface for these changes.)
        """
"""Test updating each non-boolean setting in UserProfile property_types"""
"""Test banned emojisets are not accepted."""
# -*- coding: utf-8 -*-

"""Sends a message during user creation"""
"""
    Log in, reset password, log out, log in with new password.
    """
"""If the email auth backend is not enabled, password reset should do nothing"""
"""If both email and ldap auth backends are enabled, limit password
           reset to users outside the LDAP domain"""
"""
    Logging in, registration, and logging out.
    """
"""
        If you try to register for a deactivated realm, you get a clear error
        page.
        """
"""
        If you try to register for a deactivated realm, you get a clear error
        page.
        """
"""
        If you try to log in to a deactivated realm, you get a clear error page.
        """
"""
        You can log in even if your password contain non-ASCII characters.
        """
"""You will be redirected to the app's main page if you land on the
        login page when already logged in.
        """
"""You will be redirected to the app's main page if you land on the
        login page when already logged in.
        """
"""<p><a href="https://www.google.com/images/srpr/logo4w.png" \
target="_blank" title="https://www.google.com/images/srpr/logo4w.png">\
https://www.google.com/images/srpr/logo4w.png</a></p>"""
"""
        Invites the specified users to Zulip with the specified streams.

        users should be a string containing the users to invite, comma or
            newline separated.

        streams should be a list of strings.
        """
"""
        A call to /json/invites with valid parameters causes an invitation
        email to be sent.
        """
"""
        Test that a new user invited to a stream receives some initial
        history but only from public streams.
        """
"""
        Test that a new user invited to a stream receives some initial
        history but only from public streams.
        """
"""
        Test inviting a user as invalid type of user i.e. type of invite_as
        is not in PreregistrationUser.INVITE_AS
        """
"""
        A call to /json/invites with valid parameters causes an invitation
        email to be sent.
        """
"""
        A call to /json/invites with valid parameters causes an invitation
        email to be sent.
        """
"""
        The invite_by_admins_only realm setting works properly.
        """
"""
        A call to /json/invites with valid parameters unconditionally
        subscribes the invitee to the notifications stream if it exists and is
        public.
        """
"""
        Test that a new user invited to a stream receives some initial
        history but only from public streams.
        """
"""
        Invites multiple users with a variety of delimiters.
        """
"""bob-test@zulip.com,     carol-test@zulip.com,
            dave-test@zulip.com


earl-test@zulip.com"""
"""
        Tests inviting with various missing or invalid parameters.
        """
"""
        Guest user can't invite new users
        """
"""
        Tests inviting to a non-existent stream.
        """
"""
        If you invite an address already using Zulip, no invitation is sent.
        """
"""
        If you invite a mix of already existing and new users, invitations are
        only sent to the new users.
        """
"""
        In a realm with `emails_restricted_to_domains = True`, you can't invite people
        with a different domain from that of the realm or your e-mail address.
        """
"""
        In a realm with `disallow_disposable_email_addresses = True`, you can't invite
        people with a disposable domain.
        """
"""
        In a realm with `emails_restricted_to_domains = False`, you can invite people
        with a different domain from that of the realm or your e-mail address.
        """
"""
        If you invite someone with a different domain from that of the realm
        when `emails_restricted_to_domains = False`, but `emails_restricted_to_domains` later
        changes to true, the invitation should succeed but the invitee's signup
        attempt should fail.
        """
"""
        If you invite someone with a disposable email when
        `disallow_disposable_email_addresses = False`, but
        later changes to true, the invitation should succeed
        but the invitee's signup attempt should fail.
        """
"""
        If you invite someone with an email containing plus when
        `emails_restricted_to_domains = False`, but later change
        `emails_restricted_to_domains = True`, the invitation should
        succeed but the invitee's signup attempt should fail as
        users are not allowed to signup using email containing +
        when the realm is restricted to domain.
        """
"""
        Inviting someone to streams with non-ASCII characters succeeds.
        """
"""
        A GET call to /json/invites returns all unexpired invitations.
        """
"""
        A DELETE call to /json/invites/<ID> should delete the invite and
        any scheduled invitation reminder emails.
        """
"""
        A DELETE call to /json/invites/multiuse<ID> should delete the
        multiuse_invite.
        """
"""
        A POST call to /json/invites/<ID>/resend should send an invitation reminder email
        and delete any scheduled invitation reminder email.
        """
"""
        We provide one-click unsubscribe links in missed message
        e-mails that you can click even when logged out to update your
        email notification settings.
        """
"""
        We provide one-click unsubscribe links in welcome e-mails that you can
        click even when logged out to stop receiving them.
        """
"""
        We provide one-click unsubscribe links in digest e-mails that you can
        click even when logged out to stop receiving them.

        Unsubscribing from these emails also dequeues any digest email jobs that
        have been queued.
        """
"""
        We provide one-click unsubscribe links in login
        e-mails that you can click even when logged out to update your
        email notification settings.
        """
"""
        Trying to create a realm without a creation_key should fail when
        OPEN_REALM_CREATION is false.
        """
"""
        Make sure we redirect for SMTP errors.
        """
"""
        Make sure we redirect for SMTP errors.
        """
"""
        Check if the default language of new user is the default language
        of the realm.
        """
"""
        Check if the default twenty_four_hour_time setting of new user
        is the default twenty_four_hour_time of the realm.
        """
"""
        Check if signing up with an active email redirects to a login page.
        """
"""
        Check if signing up with an email used in another realm succeeds.
        """
"""
        Check if an invalid name during signup is handled properly.
        """
"""
        Check if signing up without a password works properly when
        password_auth_enabled is False.
        """
"""
        Check if signing up without a full name redirects to a registration
        form.
        """
"""
        Check if signing up without a full name redirects to a registration
        form.
        """
"""
        Check if attempting to authenticate to the wrong subdomain logs an
        error and redirects.
        """
"""
        Check that manually changing the subdomain in a registration
        confirmation link doesn't allow you to register to a different realm.
        """
"""The most common way for LDAP authentication to be used is with a
        server that doesn't have a terms-of-service required, in which
        case we offer a complete single-sign-on experience (where the
        user just enters their LDAP username and password, and their
        account is created if it doesn't already exist).

        This test verifies that flow.
        """
"""
        Test `name_changes_disabled` when we are not running under LDAP.
        """
"""
        Trying to activate an already-active mirror dummy user should
        raise an AssertionError.
        """
# -*- coding: utf-8 -*-

# This method will be used by the mock to replace requests.get

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

"""
        Create a stream for deletion by an administrator.
        """
"""
        Delete the stream and assess the result.
        """
"""
        You must be on the realm to create a stream.
        """
"""
        When an administrator deletes a public stream, that stream is not
        visible to users at all anymore.
        """
"""
        Administrators can delete private streams they are on.
        """
"""
        Administrators can delete public streams they aren't on, including
        private streams in their realm.
        """
"""
        If you're not an admin, you can't remove other people from streams.
        """
"""
        If you're an admin, you can remove people from public streams, even
        those you aren't on.
        """
"""
        If you're an admin, you can remove other people from private streams you
        are on.
        """
"""
        If you're an admin, you can remove people from private
        streams you aren't on.
        """
"""
        When realm.create_stream_by_admins_only setting is active and
        the number of days since the user had joined is less than waiting period
        threshold, non admin users shouldn't be able to create new streams.
        """
"""
        Non admin users with account age greater or equal to waiting period
        threshold should be able to create new streams.
        """
"""
        Trying to unsubscribe someone who already isn't subscribed to a stream
        fails gracefully.
        """
"""
        Trying to unsubscribe an invalid user from a stream fails gracefully.
        """
"""
        A POST request to /api/v1/users/me/subscriptions/properties with stream_id and
        color data sets the stream color, and for that stream only. Also, make sure that
        any invalid hex color codes are bounced.
        """
"""
        Updating the color property requires a `stream_id` key.
        """
"""
        Updating the color property requires a subscribed stream.
        """
"""
        Updating the color property requires a color.
        """
"""
        A POST request to /api/v1/users/me/subscriptions/properties with stream_id and
        pin_to_top data pins the stream.
        """
"""
        Trying to set a property incorrectly returns a JSON error.
        """
"""
        Trying to set an invalid property returns a JSON error.
        """
"""
        Trying to set valid json returns success message.
        """
"""
        Trying to set an invalid property returns a JSON error.
        """
"""
        Trying to set an invalid stream id returns a JSON error.
        """
"""
        Only way to force an error is with a empty string.
        """
"""
        All tests will be logged in as hamlet. Also save various useful values
        as attributes that tests can access.
        """
"""
        Helper function to make up random stream names. It takes
        existing_stream_names and randomly appends a digit to the end of each,
        but avoids names that appear in the list names_to_avoid.
        """
"""
        Calling /api/v1/users/me/subscriptions should successfully return your subscriptions.
        """
"""
        Check result of adding subscriptions.

        You can add subscriptions for yourself or possibly many
        principals, which is why e-mails map to subscriptions in the
        result.

        The result json is of the form

        {"msg": "",
         "result": "success",
         "already_subscribed": {self.example_email("iago"): ["Venice", "Verona"]},
         "subscribed": {self.example_email("iago"): ["Venice8"]}}
        """
"""
        Calling POST /json/users/me/subscriptions should successfully add
        streams, and should determine which are new subscriptions vs
        which were already subscribed. We add 2 new streams to the
        list of subscriptions and confirm the right number of events
        are generated.
        """
"""
        Calling POST /json/users/me/subscriptions should successfully add
        streams, and should determine which are new subscriptions vs
        which were already subscribed. We add 2 new streams to the
        list of subscriptions and confirm the right number of events
        are generated.
        """
"""
        Calling POST /json/users/me/subscriptions should notify when a new stream is created.
        """
"""
        Calling POST /json/users/me/subscriptions should notify when a new stream is created.
        """
"""
        Calling POST /json/users/me/subscriptions in a new realm
        should notify with a proper new stream link
        """
"""
        Calling POST /json/users/me/subscriptions should notify when a new stream is created.
        """
"""
        Subscribing to a stream name with non-ASCII characters succeeds.
        """
"""
        Calling POST /json/users/me/subscriptions on a stream whose name is >60
        characters should return a JSON error.
        """
"""
        Calling POST /json/users/me/subscriptions on a stream whose name contains
        null characters should return a JSON error.
        """
"""
        You can't subscribe other people to streams if you are a guest or your waiting period is not over.
        """
"""
        You can't subscribe other people to streams if you are a guest or your waiting period is not over.
        """
"""
        Calling POST /json/users/me/subscriptions on a stream whose name is invalid (as
        defined by valid_stream_name in zerver/views.py) should return a JSON
        error.
        """
"""
        Calling POST /json/users/me/subscriptions on behalf of another principal (for
        whom you have permission to add subscriptions) should successfully add
        those subscriptions and send a message to the subscribee notifying
        them.
        """
"""
        Members can subscribe to streams where only admins can post
        but not create those streams, only realm admins can
        """
"""Guest users cannot subscribe themselves to anything"""
"""
        Check users getting add_peer_event is correct
        """
"""
        Check users getting add_peer_event is correct
        """
"""
        You can subscribe other people to streams.
        """
"""
        You can't subscribe deactivated people to streams.
        """
"""
        You can subscribe other people to invite only streams.
        """
"""
        You can subscribe other people to streams even if they containing
        non-ASCII characters.
        """
"""
        Calling subscribe on behalf of a principal that does not exist
        should return a JSON error.
        """
"""
        Calling subscribe on behalf of a principal in another realm
        should return a JSON error.
        """
"""
        Check result of removing subscriptions.

        Unlike adding subscriptions, you can only remove subscriptions
        for yourself, so the result format is different.

        {"msg": "",
         "removed": ["Denmark", "Scotland", "Verona"],
         "not_subscribed": ["Rome"], "result": "success"}
        """
"""
        Calling DELETE /json/users/me/subscriptions should successfully remove streams,
        and should determine which were removed vs which weren't subscribed to.
        We cannot randomly generate stream names because the remove code
        verifies whether streams exist.
        """
"""
        Calling DELETE /json/users/me/subscriptions on a stream that doesn't exist
        should return a JSON error.
        """
"""
        Call /json/subscriptions/exists on a stream and expect a certain result.
        """
"""
        Calling /json/subscriptions/exist on a stream to which you are subbed
        should return that it exists and that you are subbed.
        """
"""
        Calling /json/subscriptions/exist on a stream to which you are not
        subbed should return that it exists and that you are not subbed.
        """
"""
        Calling /json/subscriptions/exist on a stream that doesn't exist should
        return that it doesn't exist.
        """
"""
        Calling /json/subscriptions/exist on a stream whose name is invalid (as
        defined by valid_stream_name in zerver/views.py) should return a JSON
        error.
        """
"""
        Call /json/subscriptions/exist on an existing stream and autosubscribe to it.
        """
"""Call /json/subscriptions/exist on an existing private stream with
        autosubscribe should fail.
        """
"""
        When creating a subscription, the desktop, push, and audible notification
        settings for that stream are derived from the global notification
        settings.
        """
"""
        When creating a subscription, the desktop, push, and audible notification
        settings for that stream are derived from the global notification
        settings.
        """
"""
        Check that gather_subscriptions_helper does not include deactivated streams in its
        results.
        """
"""
        Ensure the validate_user_access_to_subscribers_helper is properly raising
        ValidationError on missing user, user not-in-realm.
        """
"""
        Test database query count when creating stream with api/v1/users/me/subscriptions.
        """
"""
        Ensure that the query we use to get public streams successfully returns
        a list of streams
        """
"""
        If you try to send a message to an invite-only stream to which
        you aren't subscribed, you'll get a 400.
        """
"""
        Make sure that /api/v1/users/me/subscriptions properly returns
        the invite-only bit for streams that are invite-only
        """
"""
        A successful call to get_subscribers returns the list of subscribers in
        the form:

        {"msg": "",
         "result": "success",
         "subscribers": [self.example_email("hamlet"), self.example_email("prospero")]}
        """
"""
        get_subscribers returns the list of subscribers.
        """
"""
        gather_subscriptions returns correct results with only 3 queries

        (We also use this test to verify subscription notifications to
        folks who get subscribed to streams.)
        """
"""
        Check never_subscribed streams are fetched correctly and not include invite_only streams.
        """
"""
        gather_subscriptions returns correct results with only 3 queries
        """
"""
        Even a non-subscriber to a public stream can query a stream's membership
        with get_subscribers.
        """
"""
        A subscriber to a private stream can query that stream's membership.
        """
"""
        json_get_subscribers also returns the list of subscribers for a stream.
        """
"""
        json_get_subscribers in zerver/views/streams.py
        also returns the list of subscribers for a stream.
        """
"""
        A non-subscriber non realm admin user to a private stream can't query that stream's membership.
        But unsubscribed realm admin users can query private stream's membership.
        """
"""
        A comprehensive security test for the access_stream_by_* API functions.
        """
# -*- coding: utf-8 -*-

"""
    Tests that backend template rendering doesn't crash.

    This renders all the Zulip backend templates, passing dummy data
    as the context, which allows us to verify whether any of the
    templates are broken enough to not render at all (no verification
    is done that the output looks right).  Please see `get_context`
    function documentation for more information.
    """
"""Get the dummy context for shallow testing.

        The context returned will always contain a parameter called
        `shallow_tested`, which tells the signal receiver that the
        test was not rendered in an actual logical test (so we can
        still do coverage reporting on which templates have a logical
        test).

        Note: `context` just holds dummy values used to make the test
        pass. This context only ensures that the templates do not
        throw a 500 error when rendered using dummy data.  If new
        required parameters are added to a template, this test will
        fail; the usual fix is to just update the context below to add
        the new parameter to the dummy data.

        :param kwargs: Keyword arguments can be used to update the base
            context.

        """
"""
header

<h1 id="heading">Heading</h1>
<p>
  <div class="code-section has-tabs" markdown="1">
    <ul class="nav">
      <li data-language="ios">iOS</li>
      <li data-language="desktop-web">Desktop/Web</li>
    </ul>
    <div class="blocks">
      <div data-language="ios" markdown="1"></p>
        <p>iOS instructions</p>
      <p></div>
      <div data-language="desktop-web" markdown="1"></p>
        <p>Desktop/browser instructions</p>
      <p></div>
    </div>
  </div>
</p>

<h2 id="heading-2">Heading 2</h2>
<p>
  <div class="code-section has-tabs" markdown="1">
    <ul class="nav">
      <li data-language="desktop-web">Desktop/Web</li>
      <li data-language="android">Android</li>
    </ul>
    <div class="blocks">
      <div data-language="desktop-web" markdown="1"></p>
        <p>Desktop/browser instructions</p>
      <p></div>
      <div data-language="android" markdown="1"></p>
        <p>Android instructions</p>
      <p></div>
    </div>
  </div>
</p>

<h2 id="heading-3">Heading 3</h2>
<p>
  <div class="code-section no-tabs" markdown="1">
    <ul class="nav">
      <li data-language="null_tab">None</li>
    </ul>
    <div class="blocks">
      <div data-language="null_tab" markdown="1"></p>
        <p>Instructions for all platforms</p>
      <p></div>
    </div>
  </div>
</p>

footer
"""
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

"""WebSocketBaseTestCase is based on combination of Tornado
and Django test systems. It require to use decorator '@gen.coroutine'
for each test case method( see documentation: http://www.tornadoweb.org/en/stable/testing.html).
It requires implementation of 'get_app' method to initialize tornado application and launch it.
"""
"""Close a websocket connection and wait for the server side.
        """
""" Return tornado app to launch for test cases
        """
# -*- coding: utf-8 -*-

"""
        Checks if print_types outputs `signature` when func is called with *args and **kwargs.
        Do not decorate func with print_types before passing into this function.
        func will be decorated with print_types within this function.
        """
# -*- coding: utf-8 -*-

"""
        Sending typing notification without op parameter fails
        """
"""
        Sending typing notification with invalid value for op parameter fails
        """
"""
        Sending typing notification without recipient fails
        """
"""
        Sending typing notification to invalid recipient fails
        """
"""
        Sending typing notification to a single recipient is successful
        """
"""
        Sending typing notification to a single recipient (using user IDs)
        is successful
        """
"""
        Sending typing notification to a single recipient is successful
        """
"""
        Sending typing notification to multiple recipients (using user IDs)
        is successful
        """
"""
        Sending typing notification to yourself
        is successful.
        """
"""
        Sending typing notification to yourself (using user IDs)
        is successful.
        """
"""
        Sending typing notification to another user
        is successful.
        """
"""
        Sending stopped typing notification to yourself
        is successful.
        """
"""
        Sending stopped typing notification to another user
        is successful.
        """
# -*- coding: utf-8 -*-AA

"""
        Posting a pointer to /update (in the form {"pointer": pointer}) changes
        the pointer we store for your UserProfile.
        """
"""
        Same as above, but for the API view
        """
"""
        Posting json to /json/users/me/pointer which does not contain a pointer key/value pair
        returns a 400 and error message.
        """
"""
        Posting json to /json/users/me/pointer with an invalid pointer returns a 400 and error
        message.
        """
"""
        Posting json to /json/users/me/pointer with an out of range (< 0) pointer returns a 400
        and error message.
        """
"""
        Getting old messages (a get request to /json/messages) should never
        return an unread message older than the current pointer, when there's
        no narrow set.
        """
# -*- coding: utf-8 -*-

"""
        Tests the /api/v1/user_uploads api endpoint. Here a single file is uploaded
        and downloaded using a username and api_key
        """
"""
        Tests the /api/v1/user_uploads api endpoint with ?api_key
        auth. Here a single file is uploaded and downloaded using a
        username and api_key
        """
"""
        When files are copied into the system clipboard and pasted for upload
        the filename may not be supplied so the extension is determined from a
        query string parameter.
        """
"""
        In Python 2, we need to encode unicode filenames (which converts them to
        str) before they can be rendered correctly.  However, in Python 3, the
        separate unicode type does not exist, and we don't need to perform this
        encoding.  This test ensures that we handle filename encodings properly,
        and does so in a way that preserves 100% test coverage for Python 3.
        """
"""
        Attempting to upload big files should fail.
        """
"""
        Attempting to upload two files should fail.
        """
"""
        Calling this endpoint with no files should fail.
        """
"""
        A call to /json/user_uploads should return a uri and actually create an
        entry in the database. This entry will be marked unclaimed till a message
        refers it.
        """
"""
        This test tries to claim the same attachment twice. The messages field in
        the Attachment model should have both the messages in its entry.
        """
"""This test tries to claim the same attachment more than once, first
        with a private stream and then with different recipients."""
"""
        Unicode filenames should be processed correctly.
        """
"""
        Realm quota for uploading should not be exceeded.
        """
"""Verifies URL schemes for avatars and realm icons."""
"""
        Attempting to upload two files should fail.
        """
"""
        Calling this endpoint with no files should fail.
        """
"""
        A PUT request to /json/users/me/avatar with a valid file should return a url and actually create an avatar.
        """
"""
        A PUT request to /json/users/me/avatar with an invalid file should fail.
        """
"""
        A DELETE request to /json/users/me/avatar should delete the profile picture and return gravatar URL
        """
"""
        Attempting to upload two files should fail.
        """
"""
        Calling this endpoint with no files should fail.
        """
"""
        A PUT request to /json/realm/icon with a valid file should return a url
        and actually create an realm icon.
        """
"""
        A PUT request to /json/realm/icon with an invalid file should fail.
        """
"""
        A DELETE request to /json/realm/icon should delete the realm icon and return gravatar URL
        """
"""
        Attempting to upload two files should fail.
        """
"""
        Calling this endpoint with no files should fail.
        """
"""
        A PUT request to /json/realm/logo with a valid file should return a url
        and actually create an realm logo.
        """
"""
        A PUT request to /json/realm/logo with an invalid file should fail.
        """
"""
        A DELETE request to /json/realm/logo should delete the realm logo and return gravatar URL
        """
"""
        A call to /json/user_uploads should return a uri and actually create an object.
        """
# -*- coding: utf-8 -*-

"""
    Account creation URLs are accessible even when not logged in. Authenticated
    URLs redirect to a page.
    """
"""
        Test which views are accessible when not logged in.
        """
# -*- coding: utf-8 -*-

"""
        Ensures change_is_admin raises an AssertionError when invalid permissions
        are provided to it.
        """
"""Tests whether fetching a user object the normal way, with
        `get_user`, makes 1 cache query and 1 database query.
        """
"""
        Ensure GET /users/me returns a max message id and returns successfully
        """
"""
        Ensure GET /users/me returns a proper pointer id after the pointer is updated
        """
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Copyright 2009 Facebook

#

# Licensed under the Apache License, Version 2.0 (the "License"); you may

# not use this file except in compliance with the License. You may obtain

# a copy of the License at

#

#     http://www.apache.org/licenses/LICENSE-2.0

#

# Unless required by applicable law or agreed to in writing, software

# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT

# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the

# License for the specific language governing permissions and limitations

# under the License.

# Further patched by Zulip check whether the code we're about to

# reload actually imports before reloading into it.  This fixes a

# major development workflow problem, where if one did a `git rebase`,

# Tornado would crash itself by auto-reloading into a version of the

# code that didn't work.

# os.execv is broken on Windows and can't properly parse command line

# arguments and executable name if they contain whitespaces. subprocess

# fixes that behavior.

"""Automatically restart the server when a source file is modified.

Most applications should not access this module directly.  Instead,
pass the keyword argument ``autoreload=True`` to the
`tornado.web.Application` constructor (or ``debug=True``, which
enables this setting and several others).  This will enable autoreload
mode as well as checking for changes to templates and static
resources.  Note that restarting is a destructive operation and any
requests in progress will be aborted when the process restarts.  (If
you want to disable autoreload while using other debug-mode features,
pass both ``debug=True`` and ``autoreload=False``).

This module can also be used as a command-line wrapper around scripts
such as unit test runners.  See the `main` method for details.

The command-line wrapper and Application debug modes can be used together.
This combination is encouraged as the wrapper catches syntax errors and
other import-time failures, while debug mode catches changes once
the server has started.

This module depends on `.IOLoop`, so it will not work in WSGI applications
and Google App Engine.  It also will not work correctly when `.HTTPServer`'s
multi-process mode is used.

Reloading loses any Python interpreter command-line arguments (e.g. ``-u``)
because it re-executes Python using ``sys.executable`` and ``sys.argv``.
Additionally, modifying these variables will cause reloading to behave
incorrectly.

"""
"""Begins watching source files for changes.

    .. versionchanged:: 4.1
       The ``io_loop`` argument is deprecated.
    """
"""Wait for a watched file to change, then restart the process.

    Intended to be used at the end of scripts like unit test runners,
    to run the tests again after any source file changes (but see also
    the command-line interface in `main`)
    """
"""Add a file to the watch list.

    All imported modules are watched by default.
    """
"""Add a function to be called before reloading the process.

    Note that for open file and socket handles it is generally
    preferable to set the ``FD_CLOEXEC`` flag (using `fcntl` or
    ``tornado.platform.auto.set_close_exec``) instead
    of using a reload hook to close them.
    """
# See https://zulip.readthedocs.io/en/latest/subsystems/events-system.html for

# high-level documentation on how this system works.

# The idle timeout used to be a week, but we found that in that

# situation, queues from dead browser sessions would grow quite large

# due to the accumulation of message data in those queues.

# We garbage-collect every minute; this is totally fine given that the

# GC scan takes ~2ms with 1000 event queues.

# Capped limit for how long a client can request an event queue

# to live

# The heartbeats effectively act as a server-side timeout for

# get_events().  The actual timeout value is randomized for each

# client connection based on the below value.  We ensure that the

# maximum timeout value is 55 seconds, to deal with crappy home

# wireless routers that kill "inactive" http connections.

# maps queue ids to client descriptors

# maps user id to list of client descriptors

# maps realm id to list of client descriptors with all_public_streams=True

# list of registered gc hooks.

# each one will be called with a user profile id, queue, and bool

# last_for_client that is true if this is the last queue pertaining

# to this user_profile_id

# that is about to be deleted

# The following functions are called from Django

# Workaround to support the Python-requests 1.0 transition of .json

# from a property to a function

# Send email notifications to idle users

# after they are idle for 1 hour

# Runs in the Django process to send a notification to Tornado.

#

# We use JSON rather than bare form parameters, so that we can represent

# different types and for compatibility with non-HTTP transports.

"""The receiver_is_off_zulip logic used to determine whether a user
    has no active client suffers from a somewhat fundamental race
    condition.  If the client is no longer on the Internet,
    receiver_is_off_zulip will still return true for
    DEFAULT_EVENT_QUEUE_TIMEOUT_SECS, until the queue is
    garbage-collected.  This would cause us to reliably miss
    push/email notifying users for messages arriving during the
    DEFAULT_EVENT_QUEUE_TIMEOUT_SECS after they suspend their laptop (for
    example).  We address this by, when the queue is garbage-collected
    at the end of those 10 minutes, checking to see if it's the last
    one, and if so, potentially triggering notifications to the user
    at that time, resulting in at most a DEFAULT_EVENT_QUEUE_TIMEOUT_SECS
    delay in the arrival of their notifications.

    As Zulip's APIs get more popular and the mobile apps start using
    long-lived event queues for perf optimization, future versions of
    this will likely need to replace checking `last_for_client` with
    something more complicated, so that we only consider clients like
    web browsers, not the mobile apps or random API scripts.
    """
"""This function has a complete unit test suite in
    `test_enqueue_notifications` that should be expanded as we add
    more features here."""
"""See
    https://zulip.readthedocs.io/en/latest/subsystems/sending-messages.html
    for high-level documentation on this subsystem.
    """
"""`users` is a list of user IDs, or in the case of `message` type
    events, a list of dicts describing the users and metadata about
    the user/message pair."""
# Modified version of the base Tornado handler for Django

# We mark this for nocoverage, since we only change 1 line of actual code.

"""
        Populate middleware lists from settings.MIDDLEWARE. This is copied
        from Django. This uses settings.MIDDLEWARE setting with the old
        business logic. The middleware architecture is not compatible
        with our asynchronous handlers. The problem occurs when we return
        None from our handler. The Django middlewares throw exception
        because they can't handler None, so we can either upgrade the Django
        middlewares or just override this method to use the new setting with
        the old logic. The added advantage is that due to this our event
        system code doesn't change.
        """
# There isn't a good way to get at what the underlying poll implementation

# will be without actually constructing an IOLoop, so we just assume it will

# be epoll.

# This is used for a somewhat hacky way of passing the port number

# into this early-initialized module.

# A hack to keep track of how much time we spend working, versus sleeping in

# the event loop.

#

# Creating a new event loop instance with a custom impl object fails (events

# don't get processed), so instead we modify the ioloop module variable holding

# the default poll implementation.  We need to do this before any Tornado code

# runs that might instantiate the default event loop.

# See https://zulip.readthedocs.io/en/latest/subsystems/sending-messages.html#websockets

# for high-level documentation on this subsystem.

# We disable the eventsource and htmlfile transports because they cannot

# securely send us the zulip.com cookie, which we use as part of our

# authentication scheme.

"""Given a successful authentication for an email address (i.e. we've
    confirmed the user controls the email address) that does not
    currently have a Zulip account in the target realm, send them to
    the registration flow or the "continue to registration" flow,
    depending on is_signup, whether the email address can join the
    organization (checked in HomepageForm), and similar details.
    """
"""Given a successful authentication showing the user controls given
    email address (remote_username) and potentially a UserProfile
    object (if the user already has a Zulip account), redirect the
    browser to the appropriate place:

    * The logged-in app if the user already has a Zulip account and is
      trying to login, potentially to an initial narrow or page that had been
      saved in the `redirect_to` parameter.
    * The registration form if is_signup was set (i.e. the user is
      trying to create a Zulip account)
    * A special `confirm_continue_registration.html` "do you want to
      register or try another account" if the user doesn't have a
      Zulip account but is_signup is False (i.e. the user tried to login
      and then did social authentication selecting an email address that does
      not have a Zulip account in this organization).
    * A zulip:// URL to send control back to the mobile apps if they
      are doing authentication using the mobile_flow_otp flow.
    """
"""Given a valid signed authentication token (generated by
    redirect_and_log_into_subdomain called on auth.zulip.example.com),
    call login_or_register_remote_user, passing all the authentication
    result data that had been encoded in the signed token.
    """
"""
        Login the user and redirect to the desired page.

        We need to override this function so that we can redirect to
        realm.uri instead of '/'.
        """
"""
    This is how Django implements as_view(), so extra_context will be passed
    to the __init__ method of TwoFactorLoginView.

    def as_view(cls, **initkwargs):
        def view(request, *args, **kwargs):
            self = cls(**initkwargs)
            ...

        return view
    """
"""This function allows logging in without a password on the Zulip
    mobile apps when connecting to a Zulip development environment.  It
    requires DevAuthBackend to be included in settings.AUTHENTICATION_BACKENDS.
    """
"""Returns which authentication methods are enabled on the server"""
"""Deprecated route; this is to be replaced by api_get_server_settings"""
# Zulip Mobile release 16.2.96 was made 2018-08-22.  It fixed a

# bug in our Android code that causes spammy, obviously-broken

# notifications once the "remove_push_notification" feature is

# enabled on the user's Zulip server.

# TODO: Should be Select, but sqlalchemy stubs are busted

# TODO: should be Callable[[ColumnElement], ColumnElement], but sqlalchemy stubs are busted

# When you add a new operator to this, also update zerver/lib/narrow.py

# The offsets we get from PGroonga are counted in characters

# whereas the offsets from tsearch_extras are in bytes, so we

# have to account for both cases in the logic below.

# We do not @require_login for send_message_backend, since it is used

# both from the API and the web service.  Code calling

# send_message_backend should either check the API key or check that

# the user is logged in.

"""
        Extend the given query to one narrowed by the given term, and return the result.

        This method satisfies an important security property: the returned
        query never includes a message that the given query didn't.  In
        particular, if the given query will only find messages that a given
        user can legitimately see, then so will the returned query.
        """
"""
        Escape user input to place in a regex

        Python's re.escape escapes unicode characters in a way which postgres
        fails on, '\u03bb' to '\\\u03bb'. This function will correctly escape
        them for postgres, '\u03bb' to '\\u03bb'.
        """
"""This fills out the message edit history entries from the database,
    which are designed to have the minimum data possible, to instead
    have the current topic + content as of that time, plus data on
    whatever changed.  This makes it much simpler to do future
    processing.

    Note that this mutates what is passed to it, which is sorta a bad pattern.
    """
# Custom realm filters

# -*- coding: utf-8 -*-

"""
    Send an email with a confirmation link to the provided e-mail so the user
    can complete their registration.
    """
# System documented in https://zulip.readthedocs.io/en/latest/subsystems/logging.html

# Read the source map information for decoding JavaScript backtraces.

"""Accepts an error report and stores in a queue for processing.  The
    actual error reports are later handled by do_report_error (below)"""
# By default, lists all streams that the user has access to --

# i.e. public streams plus invite-only streams that the user is on

"""
    This is the entry point to changing subscription properties. This
    is a bulk endpoint: requestors always provide a subscription_data
    list containing dictionaries for each stream of interest.

    Requests are of the form:

    [{"stream_id": "1", "property": "in_home_view", "value": False},
     {"stream_id": "1", "property": "color", "value": "#c2c2c2"}]
    """
# -*- coding: utf-8 -*-

# See https://zulip.readthedocs.io/en/latest/subsystems/thumbnailing.html

# Email unsubscribe functions. All have the function signature

# processor(user_profile).

# The keys are part of the URL for the unsubscribe link and must be valid

# without encoding.

# The values are a tuple of (display name, unsubscribe function), where the

# display name is what we call this class of email in user-visible text.

# Login NOT required. These are for one-click unsubscribes.

# -*- coding: utf-8 -*-

"""Accepts an email address or user ID and returns the avatar"""
# We don't use @human_users_only here, because there are use cases for

# a bot regenerating its own API key.

# Hack for mit.edu users whose Kerberos usernames don't match what they zephyr

# as.  The key is for Kerberos and the value is for zephyr.

# This is used only by the casper test in 00-realm-creation.js.

# Since this dispatcher is an API-style endpoint, it needs to be

# explicitly marked as CSRF-exempt

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

"""
        Tests if ansibletower project update successful notification is handled correctly
        """
"""
        Tests if ansibletower project update failed notification is handled correctly
        """
"""
        Tests if ansibletower job successful multiple hosts notification is handled correctly
        """
"""
        Tests if ansibletower job successful notification is handled correctly
        """
"""
        Tests if ansibletower job failed notification is handled correctly
        """
"""
        Tests if ansibletower job failed notification is handled correctly
        """
"""
        Tests if ansibletower inventory update successful notification is handled correctly
        """
"""
        Tests if ansibletower inventory update failed notification is handled correctly
        """
"""
        Tests if ansibletower adhoc command successful notification is handled correctly
        """
"""
        Tests if ansibletower adhoc command failed notification is handled correctly
        """
"""
        Tests if ansibletower system job successful notification is handled correctly
        """
"""
        Tests if ansibletower system job failed notification is handled correctly
        """
# -*- coding: utf-8 -*-

"""Webhook integration was successful.
Test User / Acme (Google Play)"""
"""Acme - Group chat
App Store, Acme Technologies, Inc.
★★★★★ United States
**Great for Information Management**
Acme enables me to manage the flow of information quite well. I only wish I could create and edit my Acme Post files in the iOS app.
*by* **Mr RESOLUTIONARY** *for v3.9*
[Permalink](http://appfollow.io/permalink) · [Add tag](http://watch.appfollow.io/add_tag)"""
"""Acme - Group chat
App Store, Acme Technologies, Inc.
★★★★★ United States
**Great for Information Management**
Acme enables me to manage the flow of information quite well. I only wish I could create and edit my Acme Post files in the iOS app.
*by* **Mr RESOLUTIONARY** *for v3.9*
[Permalink](http://appfollow.io/permalink) · [Add tag](http://watch.appfollow.io/add_tag)"""
# Webhooks for external integrations.

# -*- coding: utf-8 -*-

"""
        Tests if appveyor build success notification is handled correctly
        """
"""
        Tests if appveyor build failure notification is handled correctly
        """
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

"""Leo Franchi [pushed](http://lfranchi-svn.beanstalkapp.com/work-test) 1 commit to branch master.

* add some stuff ([e50508d](http://lfranchi-svn.beanstalkapp.com/work-test/changesets/e50508df))"""
"""Leo Franchi [pushed](http://lfranchi-svn.beanstalkapp.com/work-test) 1 commit to branch master.

* add some stuff ([e50508d](http://lfranchi-svn.beanstalkapp.com/work-test/changesets/e50508df))"""
"""Leo Franchi [pushed](http://lfranchi-svn.beanstalkapp.com/work-test) 3 commits to branch master. Commits by Leo Franchi (2) and Tomasz Kolek (1).

* Added new file ([edf529c](http://lfranchi-svn.beanstalkapp.com/work-test/changesets/edf529c7))
* Filled in new file with some stuff ([c2a191b](http://lfranchi-svn.beanstalkapp.com/work-test/changesets/c2a191b9))
* More work to fix some bugs ([2009815](http://lfranchi-svn.beanstalkapp.com/work-test/changesets/20098158))"""
"""Leo Franchi [pushed](http://lfranchi-svn.beanstalkapp.com/work-test) 3 commits to branch master. Commits by Leo Franchi (2) and Tomasz Kolek (1).

* Added new file ([edf529c](http://lfranchi-svn.beanstalkapp.com/work-test/changesets/edf529c7))
* Filled in new file with some stuff ([c2a191b](http://lfranchi-svn.beanstalkapp.com/work-test/changesets/c2a191b9))
* More work to fix some bugs ([2009815](http://lfranchi-svn.beanstalkapp.com/work-test/changesets/20098158))"""
"""Leo Franchi [pushed](http://lfranchi-svn.beanstalkapp.com/work-test) 3 commits to branch master.

* Added new file ([edf529c](http://lfranchi-svn.beanstalkapp.com/work-test/changesets/edf529c7))
* Filled in new file with some stuff ([c2a191b](http://lfranchi-svn.beanstalkapp.com/work-test/changesets/c2a191b9))
* More work to fix some bugs ([2009815](http://lfranchi-svn.beanstalkapp.com/work-test/changesets/20098158))"""
"""Leo Franchi [pushed](http://lfranchi-svn.beanstalkapp.com/work-test) 3 commits to branch master.

* Added new file ([edf529c](http://lfranchi-svn.beanstalkapp.com/work-test/changesets/edf529c7))
* Filled in new file with some stuff ([c2a191b](http://lfranchi-svn.beanstalkapp.com/work-test/changesets/c2a191b9))
* More work to fix some bugs ([2009815](http://lfranchi-svn.beanstalkapp.com/work-test/changesets/20098158))"""
"""Leo Franchi [pushed](http://lfranchi-svn.beanstalkapp.com/work-test) 50 commits to branch master.

{}[and {} more commit(s)]"""
"""Leo Franchi [pushed](http://lfranchi-svn.beanstalkapp.com/work-test) 50 commits to branch master.

{}[and {} more commit(s)]"""
"""Leo Franchi pushed [revision 3](http://lfranchi-svn.beanstalkapp.com/work-test/changesets/3):

> Removed a file and added another one!"""
"""Leo Franchi pushed [revision 2](http://lfranchi-svn.beanstalkapp.com/work-test/changesets/2):

> Added some code"""
# Webhooks for external integrations.

# Beanstalk's web hook UI rejects url with a @ in the username section of a url

# So we ask the user to replace them with %40

# We manually fix the username here before passing it along to @authenticated_rest_api_view

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

"""kolaszek [pushed](https://bitbucket.org/kolaszek/repository-name/branch/master) 3 commits to branch master. Commits by zbenjamin (2) and kolaszek (1).\n\n{}* first commit ([84b96ad](https://bitbucket.org/kolaszek/repository-name/commits/84b96adc644a30fd6465b3d196369d880762afed))"""
"""kolaszek [pushed](https://bitbucket.org/kolaszek/repository-name/branch/master) 10 commits to branch master. Commits by james (3), Brendon (2), Tomasz (2) and others (3).\n\n{}* first commit ([84b96ad](https://bitbucket.org/kolaszek/repository-name/commits/84b96adc644a30fd6465b3d196369d880762afed))"""
"""kolaszek [pushed](https://bitbucket.org/kolaszek/repository-name/branch/master) 3 commits to branch master. Commits by zbenjamin (2) and kolaszek (1).\n\n{}* first commit ([84b96ad](https://bitbucket.org/kolaszek/repository-name/commits/84b96adc644a30fd6465b3d196369d880762afed))"""
"""kolaszek [pushed](https://bitbucket.org/kolaszek/repository-name/branch/master) 10 commits to branch master. Commits by james (3), Brendon (2), Tomasz (2) and others (3).\n\n{}* first commit ([84b96ad](https://bitbucket.org/kolaszek/repository-name/commits/84b96adc644a30fd6465b3d196369d880762afed))"""
# Webhooks for external integrations.

#  -*- coding: utf-8 -*-

"""hypro999 commented on [508d1b6](http://139.59.64.214:7990/projects\
/SBOX/repos/sandbox/commits/508d1b67f1f8f3a25f543a030a7a178894aa9907)\n~~~ quote\nJust an \
arbitrary comment on a commit.\n~~~"""
"""hypro999 edited their comment on [508d1b6](http://139.59.64.214:7990\
/projects/SBOX/repos/sandbox/commits/508d1b67f1f8f3a25f543a030a7a178894aa9907)\n~~~ quote\nJust \
an arbitrary comment on a commit. Nothing to see here...\n~~~"""
"""hypro999 deleted their comment on [508d1b6]\
(http://139.59.64.214:7990/projects/SBOX/repos/sandbox/commits/508d1b67f1f8f3a25f543a030a7a178894a\
a9907)\n~~~ quote\nJust an arbitrary comment on a commit. Nothing to see here...\n~~~"""
"""User Hemanth V. Alluri(login: hypro999) forked the repository into \
[sandbox fork](http://139.59.64.214:7990/users/hypro999/repos/sandbox-fork/browse)."""
"""hypro999 changed the name of the **sandbox** repo from **sandbox** \
to **sandbox v2**"""
"""hypro999 created branch2 branch"""
"""hypro999 pushed tag newtag"""
"""hypro999 deleted branch branch2"""
"""hypro999 removed tag test-tag"""
"""hypro999 pushed to branch master. Head is now \
e68c981ef53dbab0a5ca320a2d8d80e216c70528"""
"""hypro999 pushed to branch branch1. Head is now \
3980c2be32a7e23c795741d5dc1a2eecb9b85d6d"""
"""hypro999 pushed to branch master. Head is now \
fc43d13cff1abb28631196944ba4fc4ad06a2cf2"""
"""hypro999 pushed to branch master. Head is now \
fc43d13cff1abb28631196944ba4fc4ad06a2cf2"""
"""hypro999 pushed to branch branch1. Head is now \
3980c2be32a7e23c795741d5dc1a2eecb9b85d6d"""
# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

"""
        Tests if codeship testing status is mapped correctly
        """
"""
        Tests if codeship error status is mapped correctly
        """
"""
        Tests if codeship success status is mapped correctly
        """
"""
        Tests if codeship other status is mapped correctly
        """
# Webhooks for external integrations.

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Tests for the Desk.com webhook integration.

#

# The stream name must be provided in the url-encoded test fixture data,

# and must match STREAM_NAME set here.

#

# Example:

#

# stream=deskdotcom&topic=static%20text%20notification&data=This%20is%20a%20custom%20action.

#

# Webhooks for external integrations.

# Desk.com's integrations all make the user supply a template, where it fills

# in stuff like {{customer.name}} and posts the result as a "data" parameter.

# There's no raw JSON for us to work from. Thus, it makes sense to just write

# a template Zulip message within Desk.com and have the webhook extract that

# from the "data" param and post it, which this does.

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

"""
        Messages are generated on ticket creation through Freshdesk's
        "Dispatch'r" service.
        """
"""Requester ☃ Bob <requester-bob@example.com> created [ticket #11](http://test1234zzz.freshdesk.com/helpdesk/tickets/11):

~~~ quote
Test ticket description ☃.
~~~

Type: **Incident**
Priority: **High**
Status: **Pending**"""
"""
        Messages are generated when a ticket's status changes through
        Freshdesk's "Observer" service.
        """
"""Requester Bob <requester-bob@example.com> updated [ticket #11](http://test1234zzz.freshdesk.com/helpdesk/tickets/11):

Status: **Resolved** => **Waiting on Customer**"""
"""
        A fixture without the requisite keys should raise JsonableError.
        """
"""
        Messages are generated when a ticket's priority changes through
        Freshdesk's "Observer" service.
        """
"""Requester Bob <requester-bob@example.com> updated [ticket #11](http://test1234zzz.freshdesk.com/helpdesk/tickets/11):

Priority: **High** => **Low**"""
"""
        Ignore unknown event payloads.
        """
"""
        Messages are generated when a note gets added to a ticket through
        Freshdesk's "Observer" service.
        """
"""Requester Bob <requester-bob@example.com> added a {} note to [ticket #11](http://test1234zzz.freshdesk.com/helpdesk/tickets/11)."""
"""
        Freshdesk sends us descriptions as HTML, so we have to make the
        descriptions Zulip markdown-friendly while still doing our best to
        preserve links and images.
        """
"""Webhooks for external integrations."""
"""
    A helper class to turn a dictionary with ticket information into
    an object where each of the keys is an attribute for easy access.
    """
"""The Freshdesk API is currently pretty broken: statuses are customizable
    but the API will only tell you the number associated with the status, not
    the name. While we engage the Freshdesk developers about exposing this
    information through the API, since only FlightCar uses this integration,
    hardcode their statuses.
    """
"""These are always of the form "{ticket_action:created}" or
    "{status:{from:4,to:6}}". Note the lack of string quoting: this isn't
    valid JSON so we have to parse it ourselves.
    """
"""There are public (visible to customers) and private note types."""
"""Freshdesk will only tell us the first event to match our webhook
    configuration, so if we change multiple properties, we only get the before
    and after data for the first one.
    """
"""They send us the description as HTML."""
"""~~~ quote
%s
~~~\n
"""
# -*- coding: utf-8 -*-

"""baxterthehacker [pushed](https://github.com/baxterthehacker/public-repo/compare/9049f1265b7d...0d1a26e67d8f) 6 commits to branch changes. Commits by Tomasz (3), Ben (2) and baxterthehacker (1).\n\n{}* Update README.md ([0d1a26e](https://github.com/baxterthehacker/public-repo/commit/0d1a26e67d8f5eaf1f6ba5c57fc3c7d91ac0fd1c))"""
"""baxterthehacker [pushed](https://github.com/baxterthehacker/public-repo/compare/9049f1265b7d...0d1a26e67d8f) 10 commits to branch changes. Commits by Tomasz (4), Ben (3), James (2) and others (1).\n\n{}* Update README.md ([0d1a26e](https://github.com/baxterthehacker/public-repo/commit/0d1a26e67d8f5eaf1f6ba5c57fc3c7d91ac0fd1c))"""
"""baxterthehacker [pushed](https://github.com/baxterthehacker/public-repo/compare/9049f1265b7d...0d1a26e67d8f) 6 commits to branch changes. Commits by Tomasz (3), Ben (2) and baxterthehacker (1).\n\n{}* Update README.md ([0d1a26e](https://github.com/baxterthehacker/public-repo/commit/0d1a26e67d8f5eaf1f6ba5c57fc3c7d91ac0fd1c))"""
"""baxterthehacker [pushed](https://github.com/baxterthehacker/public-repo/compare/9049f1265b7d...0d1a26e67d8f) 10 commits to branch changes. Commits by Tomasz (4), Ben (3), James (2) and others (1).\n\n{}* Update README.md ([0d1a26e](https://github.com/baxterthehacker/public-repo/commit/0d1a26e67d8f5eaf1f6ba5c57fc3c7d91ac0fd1c))"""
"""
Check [randscape](http://github.com/github/hello-world/runs/4) completed (success). ([d6fde92](http://github.com/github/hello-world/commit/d6fde92930d4715a2b49857d24b940956b26d2d3))
"""
"""
Check [{name}]({html_url}) {status} ({conclusion}). ([{short_hash}]({commit_url}))
"""
"""zbenjamin [pushed](https://github.com/zbenjamin/zulip-test/compare/4f9adc4777d5...b95449196980) 3 commits to branch master.

* Add baz ([48c329a](https://github.com/zbenjamin/zulip-test/commit/48c329a0b68a9a379ff195ee3f1c1f4ab0b2a89e))
* Baz needs to be longer ([06ebe5f](https://github.com/zbenjamin/zulip-test/commit/06ebe5f472a32f6f31fd2a665f0c7442b69cce72))
* Final edit to baz, I swear ([b954491](https://github.com/zbenjamin/zulip-test/commit/b95449196980507f08209bdfdc4f1d611689b7a8))"""
"""Around May 2013 the github webhook started to specify the stream.
        Before then, the stream was hard coded to "commits"."""
"""zbenjamin [pushed](https://github.com/zbenjamin/zulip-test/compare/4f9adc4777d5...b95449196980) 3 commits to branch master.

* Add baz ([48c329a](https://github.com/zbenjamin/zulip-test/commit/48c329a0b68a9a379ff195ee3f1c1f4ab0b2a89e))
* Baz needs to be longer ([06ebe5f](https://github.com/zbenjamin/zulip-test/commit/06ebe5f472a32f6f31fd2a665f0c7442b69cce72))
* Final edit to baz, I swear ([b954491](https://github.com/zbenjamin/zulip-test/commit/b95449196980507f08209bdfdc4f1d611689b7a8))"""
"""Around May 2013 the github webhook started to specify the stream.
        Before then, the stream was hard coded to "commits"."""
"""Returns True for any of "1", "true", or "True".  Returns False otherwise."""
"""
    processes github payload with version 1 field specification
    `payload` comes in unmodified from github
    `stream` is set to 'commits' if otherwise unset
    """
"""
    processes github payload with version 2 field specification
    `payload` comes in unmodified from github
    `default_stream` is set to what `stream` is in v1 above
    `commit_stream` and `issue_stream` fall back to `default_stream` if they are empty
    This and allowing alternative endpoints is what distinguishes v1 from v2 of the github configuration
    """
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

"""john [pushed](http://localhost:3000/john/try-git/compare/479e6b772b7fba19412457483f50b201286d0103...d8fce16c72a2ff56a5afc8a08645a6ce45491794) 1 commit to branch master. Commits by John (1).

* Webhook Test ([d8fce16](http://localhost:3000/john/try-git/commit/d8fce16c72a2ff56a5afc8a08645a6ce45491794))"""
"""john [pushed](http://localhost:3000/john/try-git/compare/479e6b772b7fba19412457483f50b201286d0103...d8fce16c72a2ff56a5afc8a08645a6ce45491794) 2 commits to branch master. Commits by Benjamin (1) and John (1).\n\n{}* Webhook Test ([d8fce16](http://localhost:3000/john/try-git/commit/d8fce16c72a2ff56a5afc8a08645a6ce45491794))"""
"""john [pushed](http://localhost:3000/john/try-git/compare/479e6b772b7fba19412457483f50b201286d0103...d8fce16c72a2ff56a5afc8a08645a6ce45491794) 2 commits to branch master. Commits by Benjamin (1) and John (1).\n\n{}* Webhook Test ([d8fce16](http://localhost:3000/john/try-git/commit/d8fce16c72a2ff56a5afc8a08645a6ce45491794))"""
"""john [pushed](http://localhost:3000/john/try-git/compare/479e6b772b7fba19412457483f50b201286d0103...d8fce16c72a2ff56a5afc8a08645a6ce45491794) 1 commit to branch master. Commits by John (1).

* Webhook Test ([d8fce16](http://localhost:3000/john/try-git/commit/d8fce16c72a2ff56a5afc8a08645a6ce45491794))"""
"""john opened [PR #1](http://localhost:3000/john/try-git/pulls/1)
from `feature` to `master`"""
"""john opened [PR #1 Title Text for Pull Request](http://localhost:3000/john/try-git/pulls/1)
from `feature` to `master`"""
"""john closed [PR #1](http://localhost:3000/john/try-git/pulls/1)
from `feature` to `master`"""
"""john merged [PR #2](http://localhost:3000/john/try-git/pulls/2)
from `feature` to `master`"""
# -*- coding: utf-8 -*-

# vim:fenc=utf-8

# -*- coding: utf-8 -*-

"""
The {status} **{name}** messaged:

``` quote
{content}
```
"""
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

"""user@example.com deployed version 3eb5f44 of \
[sample-project](http://sample-project.herokuapp.com)
``` quote
  * Example User: Test commit for Deploy Hook 2
```"""
"""user@example.com deployed version 3eb5f44 of \
[sample-project](http://sample-project.herokuapp.com)
``` quote
  * Example User: Test commit for Deploy Hook
  * Example User: Second test commit for Deploy Hook 2
```"""
# Webhooks for external integrations.

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

"""State changed: {}
URL: {}
Response time: {} ms
Timestamp: {}
"""
# -*- coding: utf-8 -*-

"""Leo Franchi **created** [BUG-15](http://lfranchi.com:8080/browse/BUG-15) priority Major, assigned to **no one**:

> New bug with hook"""
"""Leo Franchi **created** [BUG-15](http://lfranchi.com:8080/browse/BUG-15) priority Major, assigned to **no one**:

> New bug with hook"""
"""Leo Franchi **created** [BUG-15](http://lfranchi.com:8080/browse/BUG-15) priority Major, assigned to **no one**:

> New bug with hook"""
"""Leo Franchi **created** [BUG-15](http://lfranchi.com:8080/browse/BUG-15) priority Major, assigned to **no one**:

> New bug with hook"""
"""Leo Franchi **created** [BUG-15](http://lfranchi.com:8080/browse/BUG-15) priority Major, assigned to **no one**:

> New bug with hook"""
"""Leo Franchià **created** [BUG-15](http://lfranchi.com:8080/browse/BUG-15) priority Major, assigned to **no one**:

> New bug with à hook"""
"""Leonardo Franchi [Administrator] **created** [TEST-4](https://zulipp.atlassian.net/browse/TEST-4) priority Major, assigned to **Leonardo Franchi [Administrator]**:

> Test Created Assignee"""
"""Leo Franchi **added comment to** [BUG-15](http://lfranchi.com:8080/browse/BUG-15) (assigned to **Othello, the Moor of Venice**):


Adding a comment. Oh, what a comment it is!"""
"""Eeshan Garg **added comment to** [ZUL-1](https://zulipintegrations.atlassian.net/browse/ZUL-1):


Leaving a comment here! :)"""
"""Leo Franchi **edited comment on** [BUG-15](http://lfranchi.com:8080/browse/BUG-15) (assigned to **Othello, the Moor of Venice**):


Adding a comment. Oh, what a comment it is!"""
"""Leonardo Franchi [Administrator] **added comment to** [TEST-7](https://zulipp.atlassian.net/browse/TEST-7):\n\n\nThis is a comment that likes to **exercise** a lot of _different_ `conventions` that `jira uses`.\r\n\r\n~~~\n\r\nthis code is not highlighted, but monospaced\r\n\n~~~\r\n\r\n~~~\n\r\ndef python():\r\n    print "likes to be formatted"\r\n\n~~~\r\n\r\n[http://www.google.com](http://www.google.com) is a bare link, and [Google](http://www.google.com) is given a title.\r\n\r\nThanks!\r\n\r\n~~~ quote\n\r\nSomeone said somewhere\r\n\n~~~"""
"""Leo Franchi **updated** [BUG-15](http://lfranchi.com:8080/browse/BUG-15) (assigned to **Othello, the Moor of Venice**):

* Changed assignee to **Othello, the Moor of Venice**"""
"""Leonardo Franchi [Administrator] **updated** [TEST-1](https://zulipp.atlassian.net/browse/TEST-1) (assigned to **leo@zulip.com**):

* Changed priority from **Critical** to **Major**"""
"""Leonardo Franchi [Administrator] **updated** [TEST-1](https://zulipp.atlassian.net/browse/TEST-1):

* Changed status from **To Do** to **In Progress**"""
# Webhooks for external integrations.

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

"""`%(revision)s` deployed by **%(deployed_by)s**
%(description)s

%(changelog)s"""
# -*- coding: utf-8 -*-

# Webhooks for external integrations.

"""
    This uses the subject name from opbeat to make the subject,
    and the summary from Opbeat as the message body, with
    details about the object mentioned.
    """
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

"""
Incident [{incident_num}]({incident_url}) {action} by {assignee_info}

``` quote
{trigger_message}
```
"""
"""
Incident [{incident_num}]({incident_url}) {action} to {assignee_info}

``` quote
{trigger_message}
```
"""
"""
Incident [{incident_num}]({incident_url}) resolved by {resolving_agent_info}

``` quote
{trigger_message}
```
"""
"""
Incident [{incident_num}]({incident_url}) resolved

``` quote
{trigger_message}
```
"""
# -*- coding: utf-8 -*-

"""
        Tests if pingdom http check from up to down is handled correctly
        """
"""
        Tests if pingdom smtp check from up to down is handled correctly
        """
"""
        Tests if pingdom imap check from up to down is handled correctly
        """
"""
        Tests if pingdom imap check from down to up is handled correctly
        """
# Webhooks pfor external integrations.

# -*- coding: utf-8 -*-

"""Leo Franchi updated [Hard Code](https://www.pivotaltracker.com/s/projects/807213): [Story of the Year](http://www.pivotaltracker.com/story/show/63486316):
* state changed from **unstarted** to **accepted**"""
"""Leo Franchi added a comment to [Hard Code](https://www.pivotaltracker.com/s/projects/807213): [Story of the Year](http://www.pivotaltracker.com/story/show/63486316):
~~~quote
A comment on the story
~~~"""
"""Leo Franchi created bug: [Hard Code](https://www.pivotaltracker.com/s/projects/807213): [Story that I created](http://www.pivotaltracker.com/story/show/63495662)
* State is **unscheduled**
* Description is

> What a description"""
"""Leo Franchi updated [Hard Code](https://www.pivotaltracker.com/s/projects/807213): [Story of the Year](http://www.pivotaltracker.com/story/show/63486316):
* state changed from **accepted** to **delivered**"""
"""Leo Franchi updated [Hard Code](https://www.pivotaltracker.com/s/projects/807213): [Story of the Year](http://www.pivotaltracker.com/story/show/63486316):
* state changed from **delivered** to **accepted**"""
"""Leo Franchi moved [Hard Code](https://www.pivotaltracker.com/s/projects/807213): [Pivotal Test](http://www.pivotaltracker.com/story/show/63496066) from **unstarted** to **unscheduled**"""
"""Leo Franchi updated [Hard Code](https://www.pivotaltracker.com/s/projects/807213): [Story of the Year](http://www.pivotaltracker.com/story/show/63486316):
* Comment added:
~~~quote
Try again next time
~~~
* state changed from **delivered** to **rejected**"""
"""Leo Franchi updated [Hard Code](https://www.pivotaltracker.com/s/projects/807213): [Fresh Story](http://www.pivotaltracker.com/story/show/63495972):
* state changed from **unstarted** to **started**"""
"""Leo Franchi updated [Hard Code](https://www.pivotaltracker.com/s/projects/807213): [Pivotal Test](http://www.pivotaltracker.com/story/show/63496066):
* estimate is now **3 points**"""
"""Leo Franchi updated [Hard Code](https://www.pivotaltracker.com/s/projects/807213): [Pivotal Test](http://www.pivotaltracker.com/story/show/63496066):
* estimate changed from 3 to **0 points**
* type changed from **feature** to **bug**"""
"""Webhooks for external integrations."""
# -*- coding: utf-8 -*-

"""Creates a stat chunk about total occurrences and users affected for the
    error.

    Example: usersAffected: 2, totalOccurrences: 10
    Output: 2 users affected with 10 total occurrences

    :param error_dict: The error dictionary containing the error keys and
    values
    :returns: A message chunk that will be added to the main message
    """
"""Creates a time message chunk.

    Example: firstOccurredOn: "X", lastOccurredOn: "Y"
    Output:
    First occurred: X
    Last occurred: Y

    :param error_dict: The error dictionary containing the error keys and
    values
    :returns: A message chunk that will be added to the main message
    """
"""Creates a message chunk if exists.

    Example: message: "This is an example message" returns "Message: This is an
    example message". Whereas message: "" returns "".

    :param message: The value of message inside of the error dictionary
    :returns: A message chunk if there exists an additional message, otherwise
    returns an empty string.
    """
"""Creates a message chunk that contains the application info and the link
    to the Raygun dashboard about the application.

    :param app_dict: The application dictionary obtained from the payload
    :returns: A message chunk that will be added to the main message
    """
"""Creates a message for a repeating error follow up

    :param payload: Raygun payload
    :return: Returns the message, somewhat beautifully formatted
    """
"""Creates a message for a new error or reoccurred error

    :param payload: Raygun payload
    :return: Returns the message, somewhat beautifully formatted
    """
"""Composes a message that contains information on the error

    :param payload: Raygun payload
    :return: Returns a response message
    """
"""Creates a message from an activity that is being taken for an error

    :param payload: Raygun payload
    :return: Returns the message, somewhat beautifully formatted
    """
"""Composes a message that contains an activity that is being taken to
    an error, such as commenting, assigning an error to a user, ignoring the
    error, etc.

    :param payload: Raygun payload
    :return: Returns a response message
    """
"""Parses and returns the timestamp provided

    :param timestamp: The timestamp provided by the payload
    :returns: A string containing the time
    """
# -*- coding: utf-8 -*-

"""
**{user_name}** opened [#{id}: {review_request_title}]({review_request_url}):
"""
"""
**{user_name}** reopened [#{id}: {review_request_title}]({review_request_url}):
"""
"""
**{user_name}** closed [#{id}: {review_request_title}]({review_request_url}):
"""
"""
**{user_name}** [reviewed]({review_url}) [#{id}: {review_request_title}]({review_request_url}):

**Review**:
``` quote
{review_body_top}
```
"""
"""
``` quote
**Description**: {description}
**Status**: {status}
**Target people**: {target_people}
{extra_info}
```
"""
"""
**{user_name}** [replied]({reply_url}) to [#{id}: {review_request_title}]({review_request_url}):

**Reply**:
``` quote
{reply_body_top}
```
"""
# -*- coding: utf-8 -*-

"""[build 314](https://semaphoreci.com/donquixote/knighthood/branches/master/builds/314): passed
!avatar(don@lamancha.com) [`a490b8d`](https://github.com/donquixote/knighthood/commit/a490b8d508ebbdab1d77a5c2aefa35ceb2d62daf): Create user account for Rocinante :horse:."""
"""[deploy 17](https://semaphoreci.com/donquixote/knighthood/servers/lamancha-271/deploys/17) of [build 314](https://semaphoreci.com/donquixote/knighthood/branches/master/builds/314) on server lamancha-271: passed
!avatar(don@lamancha.com) [`a490b8d`](https://github.com/donquixote/knighthood/commit/a490b8d508ebbdab1d77a5c2aefa35ceb2d62daf): Create user account for Rocinante :horse:."""
# Webhooks for external integrations.

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

"""
        Build notifications are generated by Solano Labs after build completes.
        """
"""
        Build notifications are generated by Solano Labs after build completes.
        """
"""
        Build notifications are generated by Solano Labs after build completes.
        """
# Webhooks for external integrations.

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

"""\
[Subscription](https://dashboard.stripe.com/subscriptions/sub_E6STM5w5EX3K28) created
Plan: [flatrate](https://dashboard.stripe.com/plans/plan_E6SQ6RAtmLVtzg)
Quantity: 800
Billing method: send invoice"""
"""\
[Subscription](https://dashboard.stripe.com/subscriptions/sub_E6STM5w5EX3K28) updated
* Billing cycle anchor is now Nov 01, 2019, 12:00:00 UTC
* Current period end is now Nov 01, 2019, 12:00:00 UTC
* Current period start is now Dec 06, 2018, 05:53:55 UTC
* Start is now Dec 06, 2018, 05:53:55 UTC
* Status is now trialing
* Trial end is now Nov 01, 2019, 12:00:00 UTC
* Trial start is now Dec 06, 2018, 05:53:55 UTC"""
# Webhooks for external integrations.

# -*- coding: utf-8 -*-

"""Taiga integration for Zulip.

Tips for notification output:

*Text formatting*: if there has been a change of a property, the new
value should always be in bold; otherwise the subject of US/task
should be in bold.
"""
""" Parses the payload and finds previous and current value of change_type."""
""" Parses the comment to issue, task or US. """
""" Parses create or delete event. """
""" Parses change event. """
""" Parses the payload by delegating to specialized functions. """
""" Gets the template string and formats it with parsed data. """
# -*- coding: utf-8 -*-

# Webhooks for teamcity integration

"""
Hi there! Your bot {bot_name} just received a TeamCity payload in a
format that Zulip doesn't recognize. This usually indicates a
configuration issue in your TeamCity webhook settings. Please make sure
that you set the **Payload Format** option to **Legacy Webhook (JSON)**
in your TeamCity webhook configuration. Contact {support_email} if you
need further help!
"""
# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

"""
        Build notifications are generated by Travis after build completes.

        The subject describes the repo and Stash "project". The
        content describes the commits pushed.
        """
# Webhooks for external integrations.

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

# -*- coding: utf-8 -*-

"""
        Yo App sends notification whenever user receives a new Yo from another user.
        """
# Webhooks for external integrations.

# -*- coding: utf-8 -*-

"""
        Tests if zabbix alert is handled correctly
        """
"""
        Tests if invalid Zabbix payloads are handled correctly
        """
"""
Hi there! Your bot {bot_name} just received a Zabbix payload that is missing
some data that Zulip requires. This usually indicates a configuration issue
in your Zabbix webhook settings. Please make sure that you set the
**Default Message** option properly and provide all the required fields
when configuring the Zabbix webhook. Contact {support_email} if you
need further help!
"""
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Webhooks for external integrations.

"""
    Zendesk uses trigers with message templates. This webhook uses the
    ticket_id and ticket_title to create a subject. And passes with zendesk
    user's configured message to zulip.
    """
# Documented in https://zulip.readthedocs.io/en/latest/subsystems/queuing.html

# We probably could stop running this queue worker at all if ENABLE_FEEDBACK is False

"""Returns all the non-test worker queues."""
"""In LoopQueueProcessingWorker, consume is used just for automated tests"""
"""
    Note: Class decorators are not inherited.

    The `missedmessage_email_senders` queue was used up through 1.7.1, so we
    keep consuming from it in case we've just upgraded from an old version.
    After the 1.8 release, we can delete it and tell admins to upgrade to 1.8
    first.
    """
# Variant of PushDeviceToken for a remote server.

# We can't subclass RealmCount because we only have a realm_id here, not a foreign key.

# Zilencer views following the REST API style

# -*- coding: utf-8 -*-

"""Add a mock conversation to the development environment.

Usage: ./manage.py add_mock_conversation

After running the script:

From browser (ideally on high resolution screen):
* Refresh to get the rendered tweet
* Check that the whale emoji reaction comes before the thumbs_up emoji reaction
* Remove the blue box (it's a box shadow on .selected_message .messagebox-content;
  inspecting the selected element will find it fairly quickly)
* Change the color of the stream to #a6c7e5
* Shrink screen till the mypy link only just fits
* Take screenshot that does not include the timestamps or bottom edge

From image editing program:
* Remove mute (and edit) icons from recipient bar
"""
"""Add a new realm and initial user for manual testing of the onboarding process."""
"""Add a new user for manual testing of the onboarding process.
If realm is unspecified, will try to use a realm created by add_new_realm,
and will otherwise fall back to the zulip realm."""
"""Add a remote Zulip server for push notifications."""
"""Calculate the value of first visible message ID and store it in cache"""
"""
    Render messages to a file.
    Usage: ./manage.py render_messages <destination> <--amount>
    """
"""Script to mark all messages as unread."""
"""One-off script to migration users' stream notification settings."""
# Disable using memcached caches to avoid 'unsupported pickle

# protocol' errors if `populate_db` is run with a different Python

# from `run-dev.py`.

# Suppress spammy output from the push notifications logger

# Create some test messages, including:

# - multiple streams

# - multiple subjects per stream

# - multiple huddles

# - multiple personals converastions

# - multiple messages per subject

# - both single and multi-line content

"""
    Render messages to a file.
    Usage: ./manage.py render_messages <destination> [--amount=10000]
    """
"""Sync your API key from ~/.zuliprc into your development instance"""
# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-

# Generated by Django 1.10.5 on 2017-05-16 00:03

# -*- coding: utf-8 -*-

# Generated by Django 1.11.5 on 2017-10-12 06:27

# -*- coding: utf-8 -*-

# Generated by Django 1.11.5 on 2017-10-19 04:23

# -*- coding: utf-8 -*-

# Generated by Django 1.11.6 on 2018-01-13 11:54

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-30 06:55

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-12 01:14

# -*- coding: utf-8 -*-

# Generated by Django 1.11.11 on 2018-04-12 01:19

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-08-13 23:15

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-08-14 01:32

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-08-23 05:40

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-08-22 06:31

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-10-10 22:52

# -*- coding: utf-8 -*-

# Generated by Django 1.11.14 on 2018-09-25 12:01

# -*- coding: utf-8 -*-

# Generated by Django 1.11.18 on 2019-02-02 06:02

# Documentation for Zulip's authentication backends is split across a few places:

#

# * https://zulip.readthedocs.io/en/latest/production/authentication-methods.html and

#   zproject/prod_settings_template.py have user-level configuration documentation.

# * https://zulip.readthedocs.io/en/latest/subsystems/auth.html has developer-level

#   documentation, especially on testing authentication backends in the Zulip

#   development environment.

#

# Django upstream's documentation for authentication backends is also

# helpful background.  The most important detail to understand for

# reading this file is that the Django authenticate() function will

# call the authenticate methods of all backends registered in

# settings.AUTHENTICATION_BACKENDS that have a function signature

# matching the args/kwargs passed in the authenticate() call.

# This first batch of methods is used by other code in Zulip to check

# whether a given authentication backend is enabled for a given realm.

# In each case, we both needs to check at the server level (via

# `settings.AUTHENTICATION_BACKENDS`, queried via

# `django.contrib.auth.get_backends`) and at the realm level (via the

# `Realm.authentication_methods` BitField).

# Quick tool to test whether you're correctly authenticating to LDAP

# Authomatically add all of our social auth backends to relevant data structures.

"""Pads an authentication methods dict to contain all auth backends
    supported by the software, regardless of whether they are
    configured on this server"""
"""Used by the login page process to determine whether to show the
    'OR' for login with Google"""
"""This is the core common function used by essentially all
    authentication backends to check if there's an active user account
    with a given email address in the organization, handling both
    user-level and realm-level deactivation correctly.
    """
"""This common mixin is used to override Django's default behavior for
    looking up a logged-in user by ID to use a version that fetches
    from memcached before checking the database (avoiding a database
    query in most cases).
    """
"""Override the Django method for getting a UserProfile object from
        the user_profile_id,."""
"""Used when we want to log you in without checking any
    authentication (i.e. new user registration or when otherwise
    authentication has already been checked earlier in the process).

    We ensure that this backend only ever successfully authenticates
    when explicitly requested by including the use_dummy_backend kwarg.
    """
"""
    Email+Password Authentication Backend (the default).

    Allows a user to sign in using an email/password pair.
    """
""" Authenticate a user based on email address as the user name. """
"""
    Google Apps authentication for the legacy Android app.
    DummyAuthBackend is what's actually used for our modern Google auth,
    both for web and mobile (the latter via the mobile_flow_otp feature).

    Allows a user to sign in using a Google-issued OAuth2 token.

    Ref:
        https://developers.google.com/+/mobile/android/sign-in#server-side_access_for_your_app
        https://developers.google.com/accounts/docs/CrossClientAuth#offlineAccess
    """
"""Authentication backend that reads the Apache REMOTE_USER variable.
    Used primarily in enterprise environments with an SSO solution
    that has an Apache REMOTE_USER integration.  For manual testing, see

      https://zulip.readthedocs.io/en/latest/production/authentication-methods.html

    See also remote_user_sso in zerver/views/auth.py.
    """
"""Used to make determinations on whether a user's email address is
    managed by LDAP.  For environments using both LDAP and
    Email+Password authentication, we do not allow EmailAuthBackend
    authentication for email addresses managed by LDAP (to avoid a
    security issue where one create separate credentials for an LDAP
    user), and this function is used to enforce that rule.
    """
"""Since this inherits from _LDAPUser.AuthenticationFailed, these will
    be caught and logged at debug level inside django-auth-ldap's authenticate()"""
"""Common code between LDAP authentication (ZulipLDAPAuthBackend) and
    using LDAP just to sync user data (ZulipLDAPUserPopulator).

    To fully understand our LDAP backend, you may want to skim
    django_auth_ldap/backend.py from the upstream django-auth-ldap
    library.  It's not a lot of code, and searching around in that
    file makes the flow for LDAP authentication clear.
    """
"""Implements the userAccountControl check for whether a user has been
        disabled in an Active Directory server being integrated with
        Zulip via LDAP."""
"""Constructs the user's Zulip full_name and short_name fields from
        the LDAP data"""
"""This is used only in non-authentication contexts such as:
             ./manage.py sync_ldap_user_data
           In authentication contexts, this is overriden in ZulipLDAPAuthBackend.
        """
"""The main function of our authentication backend extension of
        django-auth-ldap.  When this is called (from `authenticate`),
        django-auth-ldap will already have verified that the provided
        username and password match those in the LDAP database.

        This function's responsibility is to check (1) whether the
        email address for this user obtained from LDAP has an active
        account in this Zulip realm.  If so, it will log them in.

        Otherwise, to provide a seamless Single Sign-On experience
        with LDAP, this function can automatically create a new Zulip
        user account in the realm (assuming the realm is configured to
        allow that email address to sign up).
        """
"""Just like ZulipLDAPAuthBackend, but doesn't let you log in.  Used
    for syncing data like names, avatars, and custom profile fields
    from LDAP in `manage.py sync_ldap_user_data` as well as in
    registration for organizations that use a different SSO solution
    for managing login (often via RemoteUserBackend).
    """
"""Allow logging in as any user without a password.  This is used for
    convenience when developing Zulip, and is disabled in production."""
"""Responsible for doing the Zulip-account lookup and validation parts
    of the Zulip Social auth pipeline (similar to the authenticate()
    methods in most other auth backends in this file).

    Returns a UserProfile object for successful authentication, and None otherwise.
    """
"""A simple wrapper function to reformat the return data from
    social_associate_user_helper as a dictionary.  The
    python-social-auth infrastructure will then pass those values into
    later stages of settings.SOCIAL_AUTH_PIPELINE, such as
    social_auth_finish, as kwargs.
    """
"""Given the determination in social_auth_associate_user for whether
    the user should be authenticated, this takes care of actually
    logging in the user (if appropriate) and redirecting the browser
    to the appropriate next page depending on the situation.  Read the
    comments below as well as login_or_register_remote_user in
    `zerver/views/auth.py` for the details on how that dispatch works.
    """
"""This is a small wrapper around the core `auth_complete` method of
        python-social-auth, designed primarily to prevent 500s for
        exceptions in the social auth code from situations that are
        really user errors.  Returning `None` from this function will
        redirect the browser to the login page.
        """
"""This patched user_data function lets us combine together the 3
        social auth backends into a single Zulip backend for GitHub Oauth2"""
# For the Dev VM environment, we use the same settings as the

# sample prod_settings.py file, with a few exceptions.

# We want LOCAL_UPLOADS_DIR to be an absolute path so that code can

# chdir without having problems accessing it.  Unfortunately, this

# means we need a duplicate definition of DEPLOY_ROOT with the one in

# settings.py.

# Check if test_settings.py set EXTERNAL_HOST.

# Uncomment extra backends if you want to test with them.  Note that

# for Google and GitHub auth you'll need to do some pre-setup.

# SLOW_QUERY_LOGS_STREAM = "errors"

# Disable Camo in development

# Flush cache after migration.

# Enable inline open graph preview in development for now

# Don't require anything about password strength in development

# SMTP settings for forwarding emails sent in development

# environment to an email account.

# Two factor authentication: Use the fake backend for development.

# Make sendfile use django to serve files in development

# Set this True to send all hotspots in development

# FAKE_LDAP_MODE supports using a fake LDAP database in the

# development environment, without needing an LDAP server!

#

# Three modes are allowed, and each will setup Zulip and the fake LDAP

# database in a way appropriate for the corresponding mode described

# in https://zulip.readthedocs.io/en/latest/production/authentication-methods.html#ldap-including-active-directory

#   (A) If users' email addresses are in LDAP and used as username.

#   (B) If LDAP only has usernames but email addresses are of the form

#       username@example.com

#   (C) If LDAP usernames are completely unrelated to email addresses.

#

# Fake LDAP data has e.g. ("ldapuser1", "ldapuser1@zulip.com") for username/email.

# FAKE_LDAP_NUM_USERS = 8

# These URLs are available only in the development environment

# These are used for voyager development. On a real voyager instance,

# these files would be served by nginx.

"""Used in development to record sent emails in a nice HTML log"""
# Future endpoints should add to urls.py, which includes these legacy urls

################################################################

# Zulip Server settings.

#

# This file controls settings that affect the whole Zulip server.

# See our documentation at:

#   https://zulip.readthedocs.io/en/latest/production/settings.html

#

# For developer documentation on the Zulip settings system, see:

#   https://zulip.readthedocs.io/en/latest/subsystems/settings.html

#

# Remember to restart the server after making changes here!

#   su zulip -c /home/zulip/deployments/current/scripts/restart-server

################################

# Mandatory settings.

#

# These settings MUST be set in production. In a development environment,

# sensible default values will be used.

# The email address for the person or team who maintains the Zulip

# installation. Note that this is a public-facing email address; it may

# appear on 404 pages, is used as the sender's address for many automated

# emails, and is advertised as a support address. An email address like

# support@example.com is totally reasonable, as is admin@example.com.

# Do not put a display name; e.g. 'support@example.com', not

# 'Zulip Support <support@example.com>'.

# The user-accessible Zulip hostname for this installation, e.g.

# zulip.example.com.  This should match what users will put in their

# web browser.  If you want to allow multiple hostnames, add the rest

# to ALLOWED_HOSTS.

#

# If you need to access the server on a specific port, you should set

# EXTERNAL_HOST to e.g. zulip.example.com:1234 here.

# Alternative hostnames.  A comma-separated list of strings

# representing the host/domain names that your users can enter in

# their browsers to access Zulip.  This is a security measure; for

# details, see the Django documentation:

# https://docs.djangoproject.com/en/1.11/ref/settings/#allowed-hosts

#

# Zulip automatically adds to this list 'localhost', '127.0.0.1', and

# patterns representing EXTERNAL_HOST and subdomains of it.  If you are

# accessing your server by other hostnames, list them here.

#

# Note that these should just be hostnames, without port numbers.

#ALLOWED_HOSTS = ['zulip-alias.example.com', '192.0.2.1']

################

# Outgoing email (SMTP) settings.

#

# Zulip needs to be able to send email (that is, use SMTP) so it can

# confirm new users' email addresses and send notifications.

#

# If you don't already have an SMTP provider, free ones are available.

#

# For more details, including a list of free SMTP providers and

# advice for troubleshooting, see the Zulip documentation:

#   https://zulip.readthedocs.io/en/latest/production/email.html

# EMAIL_HOST and EMAIL_HOST_USER are generally required.

#EMAIL_HOST = 'smtp.example.com'

#EMAIL_HOST_USER = ''

# Passwords and secrets are not stored in this file.  The password

# for user EMAIL_HOST_USER goes in `/etc/zulip/zulip-secrets.conf`.

# In that file, set `email_password`.  For example:

#   email_password = abcd1234

# EMAIL_USE_TLS and EMAIL_PORT are required for most SMTP providers.

#EMAIL_USE_TLS = True

#EMAIL_PORT = 587

# The noreply address to be used as the sender for certain generated

# emails.  Messages sent to this address could contain sensitive user

# data and should not be delivered anywhere.  The default is

# e.g. noreply-{random_token}@zulip.example.com (if EXTERNAL_HOST is

# zulip.example.com).  There are potential security issues if you set

# ADD_TOKENS_TO_NOREPLY_ADDRESS=False to remove the token; see

# https://zulip.readthedocs.io/en/latest/production/email.html for details.

#ADD_TOKENS_TO_NOREPLY_ADDRESS = True

#TOKENIZED_NOREPLY_EMAIL_ADDRESS = "noreply-{token}@example.com"

# Used for noreply emails only if ADD_TOKENS_TO_NOREPLY_ADDRESS=False

#NOREPLY_EMAIL_ADDRESS = 'noreply@example.com'

# Many countries and bulk mailers require certain types of email to display

# a physical mailing address to comply with anti-spam legislation.

# Non-commercial and non-public-facing installations are unlikely to need

# this setting.

# The address should have no newlines.

#PHYSICAL_ADDRESS = ''

################

# Authentication settings.

# Enable at least one of the following authentication backends.

# See https://zulip.readthedocs.io/en/latest/production/authentication-methods.html

# for documentation on our authentication backends.

#

# The install process requires EmailAuthBackend (the default) to be

# enabled.  If you want to disable it, do so after creating the

# initial realm and user.

########

# Google OAuth.

#

# To set up Google authentication, you'll need to do the following:

#

# (1) Visit https://console.developers.google.com/ , navigate to

# "APIs & Services" > "Credentials", and create a "Project" which will

# correspond to your Zulip instance.

#

# (2) Navigate to "APIs & services" > "Library", and find the

# "Google+ API".  Choose "Enable".

#

# (3) Return to "Credentials", and select "Create credentials".

# Choose "OAuth client ID", and follow prompts to create a consent

# screen.  Fill in "Authorized redirect URIs" with a value like

#   https://zulip.example.com/accounts/login/google/done/

# based on your value for EXTERNAL_HOST.

#

# (4) You should get a client ID and a client secret. Copy them.

# Use the client ID as `GOOGLE_OAUTH2_CLIENT_ID` here, and put the

# client secret in zulip-secrets.conf as `google_oauth2_client_secret`.

#GOOGLE_OAUTH2_CLIENT_ID = <your client ID from Google>

########

# GitHub OAuth.

#

# To set up GitHub authentication, you'll need to do the following:

#

# (1) Register an OAuth2 application with GitHub at one of:

#   https://github.com/settings/developers

#   https://github.com/organizations/ORGNAME/settings/developers

# Fill in "Callback URL" with a value like

#   https://zulip.example.com/complete/github/ as

# based on your values for EXTERNAL_HOST and SOCIAL_AUTH_SUBDOMAIN.

#

# (2) You should get a page with settings for your new application,

# showing a client ID and a client secret.  Use the client ID as

# `SOCIAL_AUTH_GITHUB_KEY` here, and put the client secret in

# zulip-secrets.conf as `social_auth_github_secret`.

#SOCIAL_AUTH_GITHUB_KEY = <your client ID from GitHub>

# (3) Optionally, you can configure the GitHub integration to only

# allow members of a particular GitHub team or organization to log

# into your Zulip server through GitHub authentication.  To enable

# this, set one of the two parameters below:

#SOCIAL_AUTH_GITHUB_TEAM_ID = <your team id>

#SOCIAL_AUTH_GITHUB_ORG_NAME = <your org name>

# (4) If you are serving multiple Zulip organizations on different

# subdomains, you need to set SOCIAL_AUTH_SUBDOMAIN.  You can set it

# to any subdomain on which you do not plan to host a Zulip

# organization.  The default recommendation, `auth`, is a reserved

# subdomain; if you're using this setting, the "Callback URL" should be e.g.:

#   https://auth.zulip.example.com/complete/github/

#

# If you end up using a subdomain other then the default

# recommendation, you must also set the 'ROOT_SUBDOMAIN_ALIASES' list

# to include this subdomain.

#

#SOCIAL_AUTH_SUBDOMAIN = 'auth'

########

# Azure Active Directory OAuth.

#

# To set up Microsoft Azure AD authentication, you'll need to do the following:

#

# (1) Register an OAuth2 application with Microsoft at:

# https://apps.dev.microsoft.com

# Generate a new password under Application Secrets

# Generate a new platform (web) under Platforms. For Redirect URL, enter:

#   https://zulip.example.com/complete/azuread-oauth2/

# Add User.Read permission under Microsoft Graph Permissions

#

# (2) Enter the application ID for the app as SOCIAL_AUTH_AZUREAD_OAUTH2_KEY here

# (3) Put the application password in zulip-secrets.conf as 'azure_oauth2_secret'.

#SOCIAL_AUTH_AZUREAD_OAUTH2_KEY = ''

########

# SSO via REMOTE_USER.

#

# If you are using the ZulipRemoteUserBackend authentication backend,

# set this to your domain (e.g. if REMOTE_USER is "username" and the

# corresponding email address is "username@example.com", set

# SSO_APPEND_DOMAIN = "example.com")

################

# Miscellaneous settings.

# Support for mobile push notifications.  Setting controls whether

# push notifications will be forwarded through a Zulip push

# notification bouncer server to the mobile apps.  See

# https://zulip.readthedocs.io/en/latest/production/mobile-push-notifications.html

# for information on how to sign up for and configure this.

#PUSH_NOTIFICATION_BOUNCER_URL = 'https://push.zulipchat.com'

# Whether to redact the content of push notifications.  This is less

# usable, but avoids sending message content over the wire.  In the

# future, we're likely to replace this with an end-to-end push

# notification encryption feature.

#PUSH_NOTIFICATION_REDACT_CONTENT = False

# Whether to submit basic usage statistics to help the Zulip core team.  Details at

#

#   https://zulip.readthedocs.io/en/latest/production/mobile-push-notifications.html

#

# Defaults to True if and only if the Mobile Push Notifications Service is enabled.

#SUBMIT_USAGE_STATISTICS = True

# Controls whether session cookies expire when the browser closes

# Session cookie expiry in seconds after the last page load

# Password strength requirements; learn about configuration at

# https://zulip.readthedocs.io/en/latest/production/security-model.html.

# PASSWORD_MIN_LENGTH = 6

# PASSWORD_MIN_GUESSES = 10000

# Controls whether Zulip sends "new login" email notifications.

#SEND_LOGIN_EMAILS = True

# Controls whether or not there is a feedback button in the UI.

# Feedback sent by your users will be sent to this email address.

# Controls whether or not error reports (tracebacks) are emailed to the

# server administrators.

#ERROR_REPORTING = True

# For frontend (JavaScript) tracebacks

#BROWSER_ERROR_REPORTING = False

# If True, each log message in the server logs will identify the

# Python module where it came from.  Useful for tracking down a

# mysterious log message, but a little verbose.

#LOGGING_SHOW_MODULE = False

# If True, each log message in the server logs will identify the

# process ID.  Useful for correlating logs with information from

# system-level monitoring tools.

#LOGGING_SHOW_PID = False

# Controls whether or not Zulip will provide inline image preview when

# a link to an image is referenced in a message.  Note: this feature

# can also be disabled in a realm's organization settings.

#INLINE_IMAGE_PREVIEW = True

# Controls whether or not Zulip will provide inline previews of

# websites that are referenced in links in messages.  Note: this feature

# can also be disabled in a realm's organization settings.

#INLINE_URL_EMBED_PREVIEW = False

# Controls whether or not Zulip will parse links starting with

# "file:///" as a hyperlink (useful if you have e.g. an NFS share).

# By default, files uploaded by users and profile pictures are stored

# directly on the Zulip server.  You can configure files being instead

# stored in Amazon S3 or another scalable data store here.  See docs at:

#

#   https://zulip.readthedocs.io/en/latest/production/upload-backends.html

#S3_AUTH_UPLOADS_BUCKET = ""

#S3_AVATAR_BUCKET = ""

#S3_REGION = ""

# Maximum allowed size of uploaded files, in megabytes.  DO NOT SET

# ABOVE 80MB.  The file upload implementation doesn't support chunked

# uploads, so browsers will crash if you try uploading larger files.

# Controls whether name changes are completely disabled for this installation

# This is useful in settings where you're syncing names from an integrated LDAP/Active Directory

# Controls whether users who have not uploaded an avatar will receive an avatar

# from gravatar.com.

# To override the default avatar image if ENABLE_GRAVATAR is False, place your

# custom default avatar image at /home/zulip/local-static/default-avatar.png

# and uncomment the following line.

#DEFAULT_AVATAR_URI = '/local-static/default-avatar.png'

# To access an external postgres database you should define the host name in

# REMOTE_POSTGRES_HOST, you can define the password in the secrets file in the

# property postgres_password, and the SSL connection mode in REMOTE_POSTGRES_SSLMODE

# Valid values for REMOTE_POSTGRES_SSLMODE are documented in the

# "SSL Mode Descriptions" table in

#   https://www.postgresql.org/docs/9.5/static/libpq-ssl.html

#REMOTE_POSTGRES_HOST = 'dbserver.example.com'

#REMOTE_POSTGRES_SSLMODE = 'require'

# If you want to set a Terms of Service for your server, set the path

# to your markdown file, and uncomment the following line.

#TERMS_OF_SERVICE = '/etc/zulip/terms.md'

# Similarly if you want to set a Privacy Policy.

#PRIVACY_POLICY = '/etc/zulip/privacy.md'

################

# Twitter integration.

# Zulip supports showing inline Tweet previews when a tweet is linked

# to in a message.  To support this, Zulip must have access to the

# Twitter API via OAuth.  To obtain the various access tokens needed

# below, you must register a new application under your Twitter

# account by doing the following:

#

# 1. Log in to http://dev.twitter.com.

# 2. In the menu under your username, click My Applications. From this page, create a new application.

# 3. Click on the application you created and click "create my access token".

# 4. Fill in the values for twitter_consumer_key, twitter_consumer_secret, twitter_access_token_key,

#    and twitter_access_token_secret in /etc/zulip/zulip-secrets.conf.

################

# Email gateway integration.

#

# The Email gateway integration supports sending messages into Zulip

# by sending an email.  This is useful for receiving notifications

# from third-party services that only send outgoing notifications via

# email.  Once this integration is configured, each stream will have

# an email address documented on the stream settings page and emails

# sent to that address will be delivered into the stream.

#

# There are two ways to configure email mirroring in Zulip:

#  1. Local delivery: A MTA runs locally and passes mail directly to Zulip

#  2. Polling: Checks an IMAP inbox every minute for new messages.

#

# The local delivery configuration is preferred for production because

# it supports nicer looking email addresses and has no cron delay,

# while the polling mechanism is better for testing/developing this

# feature because it doesn't require a public-facing IP/DNS setup.

#

# The main email mirror setting is the email address pattern, where

# you specify the email address format you'd like the integration to

# use.  It should be one of the following:

#   %s@zulip.example.com (for local delivery)

#   username+%s@example.com (for polling if EMAIL_GATEWAY_LOGIN=username@example.com)

#

# If you are using local delivery, EMAIL_GATEWAY_PATTERN is all you need

# to change in this file.  You will also need to enable the Zulip postfix

# configuration to support local delivery by adding

#   , zulip::postfix_localmail

# to puppet_classes in /etc/zulip/zulip.conf and then running

# `scripts/zulip-puppet-apply -f` to do the installation.

#

# You will also need to setup DNS MX records to ensure emails sent to

# the hostname configured in EMAIL_GATEWAY_PATTERN will be delivered

# to the Zulip postfix server you installed above.

#

# If you are using polling, you will need to setup an IMAP email

# account dedicated to Zulip email gateway messages.  The model is

# that users will send emails to that account via an address of the

# form username+%s@example.com (which is what you will set as

# EMAIL_GATEWAY_PATTERN); your email provider should deliver those

# emails to the username@example.com inbox.  Then you run in a cron

# job `./manage.py email_mirror` (see puppet/zulip/files/cron.d/email-mirror),

# which will check that inbox and batch-process any new messages.

#

# You will need to configure authentication for the email mirror

# command to access the IMAP mailbox below and in zulip-secrets.conf.

#

# The IMAP login; username here and password as email_gateway_password in

# zulip-secrets.conf.

# The IMAP server & port to connect to

# The IMAP folder name to check for emails. All emails sent to EMAIL_GATEWAY_PATTERN above

# must be delivered to this folder

################

# LDAP integration.

#

# Zulip supports retrieving information about users via LDAP, and

# optionally using LDAP as an authentication mechanism.

########

# LDAP integration, part 1: Connecting to the LDAP server.

#

# For detailed instructions, see the Zulip documentation:

#   https://zulip.readthedocs.io/en/latest/production/authentication-methods.html#ldap

# The LDAP server to connect to.  Setting this enables Zulip

# automatically fetching each new user's name from LDAP.

# Example: "ldaps://ldap.example.com"

# The DN of the user to bind as (i.e., authenticate as) in order to

# query LDAP.  If unset, Zulip does an anonymous bind.

# Passwords and secrets are not stored in this file.  The password

# corresponding to AUTH_LDAP_BIND_DN goes in `/etc/zulip/zulip-secrets.conf`.

# In that file, set `auth_ldap_bind_password`.  For example:

#   auth_ldap_bind_password = abcd1234

########

# LDAP integration, part 2: Mapping user info from LDAP to Zulip.

#

# For detailed instructions, see the Zulip documentation:

#   https://zulip.readthedocs.io/en/latest/production/authentication-methods.html#ldap

# The LDAP search query to find a given user.

#

# The arguments to `LDAPSearch` are (base DN, scope, filter).  In the

# filter, the string `%(user)s` is a Python placeholder.  The Zulip

# server will replace this with the user's Zulip username, i.e. the

# name they type into the Zulip login form.

#

# For more details and alternatives, see the documentation linked above.

# Domain to combine with a user's username to figure out their email address.

#

# If users log in as e.g. "sam" when their email address is "sam@example.com",

# set this to "example.com".  If users log in with their full email addresses,

# leave as None; if the username -> email address mapping isn't so simple,

# leave as None and see LDAP_EMAIL_ATTR.

# LDAP attribute to find a user's email address.

#

# Leave as None if users log in with their email addresses,

# or if using LDAP_APPEND_DOMAIN.

# This map defines how to populate attributes of a Zulip user from LDAP.

#

# The format is `zulip_name: ldap_name`; each entry maps a Zulip

# concept (on the left) to the LDAP attribute name (on the right) your

# LDAP database uses for the same concept.

# Whether to automatically deactivate users not found in LDAP. If LDAP

# is the only authentication method, then this setting defaults to

# True.  If other authentication methods are enabled, it defaults to

# False.

#LDAP_DEACTIVATE_NON_MATCHING_USERS = True

################

# Miscellaneous settings.

# The default CAMO_URI of '/external_content/' is served by the camo

# setup in the default Voyager nginx configuration.  Setting CAMO_URI

# to '' will disable the Camo integration.

# RabbitMQ configuration

#

# By default, Zulip connects to rabbitmq running locally on the machine,

# but Zulip also supports connecting to RabbitMQ over the network;

# to use a remote RabbitMQ instance, set RABBITMQ_HOST here.

# RABBITMQ_HOST = "localhost"

# To use another rabbitmq user than the default 'zulip', set RABBITMQ_USERNAME here.

# RABBITMQ_USERNAME = 'zulip'

# Memcached configuration

#

# By default, Zulip connects to memcached running locally on the machine,

# but Zulip also supports connecting to memcached over the network;

# to use a remote Memcached instance, set MEMCACHED_LOCATION here.

# Format HOST:PORT

# MEMCACHED_LOCATION = 127.0.0.1:11211

# Redis configuration

#

# By default, Zulip connects to redis running locally on the machine,

# but Zulip also supports connecting to redis over the network;

# to use a remote Redis instance, set REDIS_HOST here.

# REDIS_HOST = '127.0.0.1'

# For a different redis port set the REDIS_PORT here.

# REDIS_PORT = 6379

# If you set redis_password in zulip-secrets.conf, Zulip will use that password

# to connect to the redis server.

# Controls whether Zulip will rate-limit user requests.

# RATE_LIMITING = True

# By default, Zulip connects to the thumbor (the thumbnailing software

# we use) service running locally on the machine.  If you're running

# thumbor on a different server, you can configure that by setting

# THUMBOR_URL here.  Setting THUMBOR_URL='' will let Zulip server know that

# thumbor is not running or configured.

#THUMBOR_URL = 'http://127.0.0.1:9995'

#

# This setting controls whether images shown in Zulip's inline image

# previews should be thumbnailed by thumbor, which saves bandwidth but

# can modify the image's appearance.

#THUMBNAIL_IMAGES = True

# Controls the Jitsi video call integration.  By default, the

# integration uses the SaaS meet.jit.si server.  You can specify

# your own Jitsi Meet server, or if you'd like to disable the

# integration, set JITSI_SERVER_URL = None.

#JITSI_SERVER_URL = 'jitsi.example.com'

# Django settings for zulip project.

########################################################################

# Here's how settings for the Zulip project work:

#

# * settings.py contains non-site-specific and settings configuration

# for the Zulip Django app.

# * settings.py imports prod_settings.py, and any site-specific configuration

# belongs there.  The template for prod_settings.py is prod_settings_template.py

#

# See https://zulip.readthedocs.io/en/latest/subsystems/settings.html for more information

#

########################################################################

########################################################################

# INITIAL SETTINGS

########################################################################

# Whether this instance of Zulip is running in a production environment.

# Make this unique, and don't share it with anybody.

# A shared secret, used to authenticate different parts of the app to each other.

# We use this salt to hash a user's email into a filename for their user-uploaded

# avatar.  If this salt is discovered, attackers will only be able to determine

# that the owner of an email account has uploaded an avatar to Zulip, which isn't

# the end of the world.  Don't use the salt where there is more security exposure.

# SERVER_GENERATION is used to track whether the server has been

# restarted for triggering browser clients to reload.

# Key to authenticate this server to zulip.org for push notifications, etc.

# Detect whether we're running as a queue worker; this impacts the logging configuration.

# This is overridden in test_settings.py for the test suites

# The new user tutorial is enabled by default, but disabled for client tests.

# This is overridden in test_settings.py for the test suites

# Google Compute Engine has an /etc/boto.cfg that is "nicely

# configured" to work with GCE's storage service.  However, their

# configuration is super aggressive broken, in that it means importing

# boto in a virtualenv that doesn't contain the GCE tools crashes.

#

# By using our own path for BOTO_CONFIG, we can cause boto to not

# process /etc/boto.cfg.

# Import variables like secrets from the prod_settings file

# Import prod_settings after determining the deployment/machine type

########################################################################

# DEFAULT VALUES FOR SETTINGS

########################################################################

# For any settings that are not set in the site-specific configuration file

# (/etc/zulip/settings.py in production, or dev_settings.py or test_settings.py

# in dev and test), we want to initialize them to sane defaults.

# These settings are intended for the server admin to set.  We document them in

# prod_settings_template.py, and in the initial /etc/zulip/settings.py on a new

# install of the Zulip server.

# These settings are not documented in prod_settings_template.py.

# They should either be documented here, or documented there.

#

# Settings that it makes sense to document here instead of in

# prod_settings_template.py are those that

#  * don't make sense to change in production, but rather are intended

#    for dev and test environments; or

#  * don't make sense to change on a typical production server with

#    one or a handful of realms, though they might on an installation

#    like zulipchat.com or to work around a problem on another server.

# These are the settings that we will check that the user has filled in for

# production deployments before starting the app.  It consists of a series

# of pairs of (setting name, default value that it must be changed from)

########################################################################

# STANDARD DJANGO SETTINGS

########################################################################

# Local time zone for this installation. Choices can be found here:

# http://en.wikipedia.org/wiki/List_of_tz_zones_by_name

# although not all choices may be available on all operating systems.

# In a Windows environment this must be set to your system time zone.

# Language code for this installation. All choices can be found here:

# http://www.i18nguy.com/unicode/language-identifiers.html

# If you set this to False, Django will make some optimizations so as not

# to load the internationalization machinery.

# If you set this to False, Django will not format dates, numbers and

# calendars according to the current locale.

# If you set this to False, Django will not use timezone-aware datetimes.

# this directory will be used to store logs for development environment

# Make redirects work properly behind a reverse proxy

# Extend ALLOWED_HOSTS with localhost (needed to RPC to Tornado),

# ... with hosts corresponding to EXTERNAL_HOST,

# ... and with the hosts in REALM_HOSTS.

# Python dotted path to the WSGI application used by Django's runserver.

# A site can include additional installed apps via the

# EXTRA_INSTALLED_APPS setting

# Base URL of the Tornado server

# We set it to None when running backend tests or populate_db.

# We override the port number when running frontend tests.

########################################################################

# DATABASE CONFIGURATION

########################################################################

########################################################################

# RABBITMQ CONFIGURATION

########################################################################

########################################################################

# CACHING CONFIGURATION

########################################################################

# Compress large values being stored in memcached; this is important

# for at least the realm_users cache.

########################################################################

# REDIS-BASED RATE LIMITING CONFIGURATION

########################################################################

########################################################################

# SECURITY SETTINGS

########################################################################

# Tell the browser to never send our cookies without encryption, e.g.

# when executing the initial http -> https redirect.

#

# Turn it off for local testing because we don't have SSL.

# Prevent Javascript from reading the CSRF token from cookies.  Our code gets

# the token from the DOM, which means malicious code could too.  But hiding the

# cookie will slow down some attackers.

########################################################################

# API/BOT SETTINGS

########################################################################

# GCM tokens are IP-whitelisted; if we deploy to additional

# servers you will need to explicitly add their IPs here:

# https://cloud.google.com/console/project/apps~zulip-android/apiui/credential

# Twitter API credentials

# Secrecy not required because its only used for R/O requests.

# Please don't make us go over our rate limit.

# These are the bots that Zulip sends automated messages as.

# Bots that are created for each realm like the reminder-bot goes here.

# These are realm-internal bots that may exist in some organizations,

# so configure power the setting, but should not be auto-created at this time.

# Set the realm-specific bot names

########################################################################

# STATSD CONFIGURATION

########################################################################

# Statsd is not super well supported; if you want to use it you'll need

# to set STATSD_HOST and STATSD_PREFIX.

########################################################################

# CAMO HTTPS CACHE CONFIGURATION

########################################################################

########################################################################

# STATIC CONTENT AND MINIFICATION SETTINGS

########################################################################

# ZulipStorage is a modified version of PipelineCachedStorage,

# and, like that class, it inserts a file hash into filenames

# to prevent the browser from using stale files from cache.

#

# Unlike PipelineStorage, it requires the files to exist in

# STATIC_ROOT even for dev servers.  So we only use

# ZulipStorage when not DEBUG.

# This is the default behavior from Pipeline, but we set it

# here so that urls.py can read it.

# If changing this, you need to also the hack modifications to this in

# our compilemessages management command.

# We want all temporary uploaded files to be stored on disk.

# To use minified files in dev, set PIPELINE_ENABLED = True.  For the full

# cache-busting behavior, you must also set DEBUG = False.

#

# You will need to run update-prod-static after changing

# static files.

#

# Useful reading on how this works is in

# https://zulip.readthedocs.io/en/latest/subsystems/front-end-build-process.html

# Useful reading on how this works is in

# https://zulip.readthedocs.io/en/latest/subsystems/front-end-build-process.html

########################################################################

# TEMPLATES SETTINGS

########################################################################

# List of callables that know how to import templates from various sources.

# django-two-factor uses the default Django template engine (not Jinja2), so we

# need to add config for it here.

# The order here is important; get_template and related/parent functions try

# the template engines in order until one succeeds.

########################################################################

# LOGGING SETTINGS

########################################################################

# The Event log basically logs most significant database changes,

# which can be useful for debugging.

# This is disabled in a few tests.

# Client-side polling timeout for get_events, in milliseconds.

# We configure this here so that the client test suite can override it.

# We already kill the connection server-side with heartbeat events,

# but it's good to have a safety.  This value should be greater than

# (HEARTBEAT_MIN_FREQ_SECS + 10)

# iOS App IDs

########################################################################

# SSO AND LDAP SETTINGS

########################################################################

# Redirect to /devlogin/ by default in dev mode

########################################################################

# SOCIAL AUTHENTICATION SETTINGS

########################################################################

########################################################################

# EMAIL SETTINGS

########################################################################

# Django setting. Not used in the Zulip codebase.

# Set the sender email address for Django traceback error reporting

########################################################################

# MISC SETTINGS

########################################################################

# This is a debugging option only

# test_settings.py works differently from

# dev_settings.py/prod_settings.py; it actually is directly referenced

# by the test suite as DJANGO_SETTINGS_MODULE and imports settings.py

# directly and then hacks up the values that are different for the

# test suite.  As will be explained, this is kinda messy and probably

# we'd be better off switching it to work more like dev_settings.py,

# but for now, this is what we have.

#

# An important downside of the test_settings.py approach is that if we

# want to change any settings that settings.py then computes

# additional settings from (e.g. EXTERNAL_HOST), we need to do a hack

# like the below line(s) before we import from settings, for

# transmitting the value of EXTERNAL_HOST to dev_settings.py so that

# it can be set there, at the right place in the settings.py flow.

# Ick.

# Clear out the REALM_HOSTS set in dev_settings.py

# Used to clone DBs in backend tests.

# Decrease the get_updates timeout to 1 second.

# This allows CasperJS to proceed quickly to the next test step.

# Don't use the real message log for tests

# Stores the messages in `django.core.mail.outbox` rather than sending them.

# The test suite uses EmailAuthBackend

# Configure Google Oauth2

# Makes testing LDAP backend require less mocking

# Don't use rabbitmq from the test suite -- the user_profile_ids for

# any generated queue elements won't match those being used by the

# real app.

# Disable the tutorial because it confuses the client tests.

# Disable use of memcached for caching

# Disable caching on sessions to make query counts consistent

# Use production config from Webpack in tests

# Don't auto-restart Tornado server during automated tests

# Enable file:/// hyperlink support by default in tests

# Test Custom TOS template rendering

# By default will not send emails when login occurs.

# Explicity set this to True within tests that must have this on.

# By default two factor authentication is disabled in tests.

# Explicitly set this to True within tests that must have this on.

# Disable messages from slow queries as they affect backend tests.

# Logging the emails while running the tests adds them

# to /emails page.

# NB: There are several other pieces of code which route requests by URL:

#

#   - legacy_urls.py contains API endpoint written before the redesign

#     and should not be added to.

#

#   - runtornado.py has its own URL list for Tornado views.  See the

#     invocation of web.Application in that file.

#

#   - The Nginx config knows which URLs to route to Django or Tornado.

#

#   - Likewise for the local dev server in tools/run-dev.py.

# These endpoints constitute the currently designed API (V1), which uses:

# * REST verbs

# * Basic auth (username:password is email:apiKey)

# * Take and return json-formatted data

#

# If you're adding a new endpoint to the code that requires authentication,

# please add it here.

# See rest_dispatch in zerver.lib.rest for an explanation of auth methods used

#

# All of these paths are accessed by either a /json or /api/v1 prefix;

# e.g. `PATCH /json/realm` or `PATCH /api/v1/realm`.

# These views serve pages (HTML). As such, their internationalization

# must depend on the url.

#

# If you're adding a new page to the website (as opposed to a new

# endpoint for use by code), you should add it here.

# Make a copy of i18n_urls so that they appear without prefix for english

# Include the dual-use patterns twice

# user_uploads -> zerver.views.upload.serve_file_backend

#

# This url is an exception to the url naming schemes for endpoints. It

# supports both API and session cookie authentication, using a single

# URL for both (not 'api/v1/' or 'json/' prefix). This is required to

# easily support the mobile apps fetching uploaded files without

# having to rewrite URLs, and is implemented using the

# 'override_api_url_scheme' flag passed to rest_dispatch

# This url serves as a way to recieve CSP violation reports from the users.

# We use this endpoint to just log these reports.

# This url serves as a way to provide backward compatibility to messages

# rendered at the time Zulip used camo for doing http -> https conversion for

# such links with images previews. Now thumbor can be used for serving such

# images.

# Incoming webhook URLs

# We don't create urls for particular git integrations here

# because of generic one below

# Desktop-specific authentication URLs

# Mobile-specific authentication URLs

# View for uploading messages from email mirror

# Include URL configuration files for site-specified extra installed

# Django apps

# Tornado views

# Python Social Auth

# User documentation site

# Two Factor urls

# The sequence is important; if i18n urls don't come first then

# reverse url mapping points to i18n urls which causes the frontend

# tests to fail

# Because import_module does not correctly handle safe circular imports we

# need to import zerver.models first before the middleware tries to import it.

# This application object is used by any WSGI server configured to use this

# file. This includes Django's development server, if the WSGI_APPLICATION

# setting points here.

"""
WSGI config for zulip project.

This module contains the WSGI application used by Django's development server
and any production WSGI deployments. It should expose a module-level variable
named ``application``. Django's ``runserver`` and ``runfcgi`` commands discover
this application via the ``WSGI_APPLICATION`` setting.

Usually you will have the standard Django WSGI application here, but it also
might make sense to replace the whole Django WSGI application with a custom one
that later delegates to the Django one. For example, you could introduce WSGI
middleware here, or combine a Django application with an application of another
framework.

"""
"""
`minified_js` is taken from `zerver.templatetags.minified_js.py`
"""
# This file is used by both Python 2.7 (thumbor) and 3 (zulip).

# Piece of code below relating to secrets conf has been duplicated with that of

# django settings in zproject/settings.py

# Whether this instance of Zulip is running in a production environment.

# See https://zulip.readthedocs.io/en/latest/subsystems/thumbnailing.html

